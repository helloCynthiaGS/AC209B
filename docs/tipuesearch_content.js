var tipuesearch = {"pages":[{"title":"GitHub Page","text":"All course content (except Lectures 2-4,12-17) are in: GitHub repo We suggest that you clone this repository.","tags":"pages","url":"pages/github.html"},{"title":"Modules Page","text":"Module description and details go here","tags":"pages","url":"pages/modules.html"},{"title":"Schedule","text":"ï»¿Week Date Lecture (Mon) Date Lecture (Wed) Lab Advanced Section (Wed) Assignment (release and due) 1 28-Jan Lecture 1: Intro + Review of 109A Preview of 109B 30-Jan Lecture 2: Smoothing and Additive 1/3 Lab 1: Setting up enviroment 2 4-Feb Lecture 3: Smoothing and Additive 2/3 6-Feb Lecture 4: Smoothing and GAM 3/3 Lab 2: Smoothing/GAM HW1 (2/3) 3 11-Feb Lecture 5: Feed Forward + Reg + Review from NN fall 13-Feb Lecture 6: Optimization of NN (Solvers) Lab 3: Optimization Advanced Section 1: Optimization/Dropout HW2 (2/10) 4 18-Feb Holiday 20-Feb Lecture 7: AWS scalable systems SQL Lab 4: Setting UP AWS Advanced Section 2: Optimal Transport 5 25-Feb Lecture 8: CNNs-1 27-Feb Lecture 9: CNNs-2 Lab 5: CNNs Advanced Section 3: ConvNets: LeNet, AlexNet, VGG-15, ResNet and Inception HW3 (2/24) 6 4-Mar Lecture 10: RNN 1 6-Mar Lecture 11: RNN 2 Lab 6: RNNS Advanced Section 4: LSTN, GRU in NLP HW4 (3/3) 7 11-Mar Lecture 12: Unsupervised learning/clustering 1 13-Mar Lecture 13: Unsupervised learning/clustering 2 Lab 7: Clusterig Advanced Section 5: Unsup + AE HW5 (3/10) 8 25-Mar Lecture 14: Autoencoders 27-Mar Lecture 15: Bayesian 1/3 Lab 8: Bayes 1 9 1-Apr Lecture 16: Bayesian 2/3 3-Apr Lecture 17: Bayesian 3/3 Lab 9: Bayes 2 Advanced Section 7:LDA and Bayes HW6 (3/30) 10 8-Apr Lecture 18: Generative Models Varational Autoenders 1 8-Apr Lecture 19: Generative Models Varational Autoenders 2 Lab 10: VAE Advanced Section 8:VAE+GANS HW7 (4/7) 11 15-Apr Lecture 20: GANS 1 17-Apr Lecture 21: GANS 2 Lab 11: GANS","tags":"pages","url":"pages/schedule.html"},{"title":"Syllabus","text":"Course description Tentative Course Topics Course Objectives Course Components Lectures Labs In-class Quizzes Advanced Sections Exams Projects Homework Assignments Course Resources Online Materials Recommended Textbooks Getting Help Course Policies and Expectations Grading Collaboration Policy Late or Wrongly Submitted Assignments Re-grade Requests Auditing the Class Academic Integrity Accommodations for students with disabilities Diversity and Inclusion Statement Course description Data Science 2 is the second half of a one-year introduction to data science. Building upon the material in Data Science 1, the course introduces advanced methods for data wrangling, data visualization, and deep neural networks, statistical modeling, and prediction. Topics include big data and database management, multiple deep learning subjects such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models and unsupervised learning. The programming language will be python. Tentative Course Topics Feed Forward Neural Networks Regularization of Neural Network Optimization of Neural Networks Autoencoders Convolutional Neural Networks Recurrent Neural Networks Variational AutoEncoders Generative Adversarial Networks Smoothing and Additive Models Unsupervised Learning Bayesian Inference Models, LDA SQL AWS Course Objectives Upon successful completion of this course, you should feel comfortable with the material mentioned above, plus you will have had experience in working with others on real-world problems. Both the content knowledge, the project, and teamwork, will prepare you for the professional world or further studies. Course Components There will be live video feed available only to distance education students for lectures, labs, and advanced sections. Recordings for all other students will be available within 24 hrs. Lectures The class meets twice a week for lectures. Attending lectures is a crucial component of learning the material presented in this course. Labs Lectures are supplemented by weekly programming labs. Labs are an important aspect of the course, as they supplement material from lectures with examples, discuss programming environments, and teach you important skills. In-class Quizzes At the end of each lecture, we will ask you to take a short graded quiz on the material presented in class. These quizzes will count towards your final grade. Advanced Sections The course will include advanced sections for 209 students and will cover a different topic per week. These are 75 min lectures and they will cover advanced topics like the mathematical underpinnings of the methods seen in lecture and lab and extensions of those methods. The material covered in the advanced sections is required for all ac209 students. Tentative topics are: Earth Mover's Distance Dropout ConvNets: LeNet, AlexNet, VGG-15, ResNet and Inception LSTN, GRU in NLP Neural style transfer learning Deep Reinforcement Learning Variational Inference Exams There are no exams in this course. Projects - For distant students The goal of the project is to have a complete end-to-end data science process encompassing both semesters of subject material while working as a 3-4 person team. We will supply a small set of project choices within the thematic categories. Teams may propose a different project with sufficient notice and will be subject to approval by the course staff. - For campus students During the final four (4) weeks of the course, students will be divided in break-out thematic sections where they will study topics such as medicine, law, astronomy, e-commerce, and government. Each section will include lectures by Harvard faculty, experts on the field, followed by project work also led by that faculty. You will get to present your projects in the SEAS Design Fair at the end of the semester. Homework Assignments There will be seven graded homework assignments. Some of them will be due one week after being assigned and some will be due two weeks after being assigned. For five assignments, you have the option to work and submit in pairs, the two remaining are to be completed individually. Course Resources Online Materials All course materials, including lecture notes, lab notes, and section notes will be published in the class GitHub: https://github.com/Harvard-IACS/2019-CS109B . Assignments will only be posted on Canvas. Working environment You will be working in Jupyter Notebooks which you can run in your own machine or in the SEAS JupyterHub cloud (details on this to come). Recommended Textbooks ISLR: An Introduction to Statistical Learning. by James, Witten, Hastie, Tibshirani (Springer: New York, 2013) DL: Deep Learning by Goodfellow, Bengio and Courville. Free electronic versions are available ( ISLR ), ( DL) or hard copy through Amazon ( ISLR) , ( DL ). Getting Help For questions about homework, course content, package installation, the process is: try to troubleshoot yourself by reading the lecture, lab, and section notes, and looking up online resources. go to office hours this is the best way to get help. post on the class Piazza; we want you and your peers to engage in helping each other. TFs also monitor Piazza and will respond within 24 hours. Note that Piazza questions are visible to everyone. If you are citing homework solution code you want to post privately so that only the staff sees your message. watch for official announcements via Canvas so make sure you have your Canvas notifications turned on. Piazza should always be your first resource for seeking answers to your content questions. send an email to the Helpline ( cs109b2019@gmail.com ) for administrative issues, regrade requests, and non-content specific questions we have this email account. for personal matters that you do not feel comfortable sharing with the TFs, you may send an email to either or both of the instructors. Course Policies and Expectations Grading for CS109b, STAT121b, and CS209b: <<<<<<< HEAD ======= 3aa6558f04b882eacb6af4d0b69db82445ca5329 Paired-option Homeworks 45% (5 homework for which you have the option to work in pairs) Individual Homeworks 25% (2 homework which you must complete individually) Quizzes 10% (you may drop 40% of the quizzes) Project 20% TOTAL 100% Note: Regular homework (for everyone) counts as 5 points. 209b extra homework counts as 1 point. Grading for DCE: Paired-option Homeworks 48% (5 homework for which you have the option to work in pairs) Individual Homeworks 28% (2 homework which you must complete individually) Project 24% TOTAL 100% Collaboration Policy We expect you to adhere to the Harvard Honor Code at all times. Failure to adhere to the honor code and our policies may result in serious penalties, up to and including automatic failure in the course and reference to the ad board. If you work with a partner on an assignment make sure both parties solve all the problems. Do not divide and conquer. You are expected to be intellectually honest and give credit where credit is due. In particular: if you work with a fellow student but decide to submit different papers, include the name of each other in the designated area of the submission paper. if you work with a fellow student and want to submit the same paper you need to form a group prior to the submission. Details in the assignment. Not all assignments will permit group submissions. you need to write your solutions entirely on your own or with your collaborator you are welcome to take ideas from code presented in labs, lecture, or sections but you need to change it, adapt it to your style, and ultimately write your own. We do not want to see code copied verbatim from the above sources. if you use code found on the internet, books, or other sources you need to cite those sources. you should not view any written materials or code created by other students for the same assignment; you may not provide or make available solutions to individuals who take or may take this course in the future. if the assignment allows it you may use third-party libraries and example code, so long as the material is available to all students in the class and you give proper attribution. Do not remove any original copyright notices and headers. Late or Wrongly Submitted Assignments There are no late days in homework submission. We will accept late submissions only for medical reasons and if accompanied by a doctor's note. To submit after Canvas has closed or to ask for an extension , send an email to the Helpline with subject line \"Submit HW1: Reason=the flu\" replacing 'HW1' with the name of the current assignment and \"the flu\" with your reason. You need to attach the note from your medical provider otherwise we will not accept the request. If you forgot to join a Group with your peer and are asking for the same grade we will accept this with no penalty up to HW3. For homeworks beyond that we feel that you should be familiar with the process of joining groups. After that there will be a penalty of -1 point for both members of the group provided the submission was on time. Re-grade Requests Our graders and instructors make every effort in grading accurately and in giving you a lot of feedback. If you discover that your answer to a homework problem was correct but it was marked as incorrect, send an email to the Helpline with a description of the error. Please do not submit regrade requests based on what you perceive is overly harsh grading . The points we take off are based on a grading rubric that is being applied uniformly to all assignments. If you decide to send a regrade request , send an email to the Helpline with subject line \"Regrade HW1: Grader=johnsmith\" replacing 'HW1' with the current assignment and 'johnsmith' with the name of the grader within 48 hours of the grade release . Auditing the Class If you would like to audit the class, please send an email to the Helpline indicating who you are and why you want to audit the class. You need a HUID to be included to Canvas. Academic Integrity Ethical behavior is an important trait of a Data Scientist, from ethically handling data to attribution of code and work of others. Thus, in CS109 we give a strong emphasis to Academic Honesty. As a student your best guidelines are to be reasonable and fair. We encourage teamwork for problem sets, but you should not split the homework and you should work on all the problems together. For more detailed expectations, please refer to the Collaborations section above. Accommodations for students with disabilities Students needing academic adjustments or accommodations because of a documented disability must present their Faculty Letter from the Accessible Education Office (AEO) and speak with the professor by the end of the second week of the term, (fill in specific date). Failure to do so may result in the Course Head's inability to respond in a timely manner. All discussions will remain confidential, although Faculty are invited to contact AEO to discuss appropriate implementation. Diversity and Inclusion Statement Data Science, like many fields of science, has historically only been represented by a small sliver of the population. This is despite some of the early computer scientist pioneers being women (see Ada Lovelace and Grace Hopper for two examples). Recent initiatives have attempted to overcome some barriers to entry: Made w/ Code . We would like to attempt to discuss diversity in data science from time to time where appropriate and possible. Please contact us (in person or electronically) or submit anonymous feedback if you have any suggestions to improve the diversity of the course materials. Furthermore, we would like to create a learning environment for our students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this: If you have a name and/or set of pronouns that differ from those that appear in your official Harvard records, please let us know! If you feel like your performance in the class is being impacted by your experiences outside of class, please don't hesitate to come and talk with us. We want to be a resource for you. Remember that you can also submit anonymous feedback (which will lead to me making a general announcement to the class, if necessary to address your concerns). If you prefer to speak with someone outside of the course, you may find helpful resources at the Harvard Office of Diversity and Inclusion . We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. (Again, anonymous feedback is always an option.) As a participant in course discussions, you should also strive to honor the diversity of your classmates.","tags":"pages","url":"pages/syllabus.html"},{"title":"Advanced Section 2: Optimal Transport","text":"Slides PDF Lecture Notes PDF Intro to optimization notes PDF References for further reading Computation optimal transport Learning with a Wasserstein Loss Optimal Transport for Domain Adaptation","tags":"A-sections","url":"a-sections/a-section2/"},{"title":"Advanced Section 1: Optimization/Dropout","text":"Slides PDF Lecture notes PDF","tags":"A-sections","url":"a-sections/a-section1/"},{"title":"Lecture 6: NN Optimization","text":"Slides Lecture 6 PDF Lecture 6 PPTX Associated Material","tags":"lectures","url":"lectures/lecture6/"},{"title":"Lecture 5: Review of NN from 109A","text":"Slides Lecture 5 PDF Lecture 5 PPTX Associated Material","tags":"lectures","url":"lectures/lecture5/"},{"title":"Lab 2: Smooths and GAMs","text":"Lab 2 Notebooks Lab2 Smooths and GAMs Lab2 Smooths and GAMs with solutions","tags":"labs","url":"labs/lab2/"},{"title":"Lab 2: Smooths and GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models Harvard University Spring 2019 Instructors: Mark Glickman and Pavlos Protopapas Lab Instructors: Will Claybaugh Contributors: Paul Tyklin and Will Claybaugh In [ ]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Learning Goals The main goal of this lab is to get familiar with calling R functions within Python. Along the way, we'll learn about the \"formula\" interface to statsmodels, which gives an intuitive way of specifying regression models, and we'll review the different approaches to fitting curves. Key Skills: Importing (base) R functions Importing R library functions Populating vectors R understands Populating dataframes R understands Populating formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation In [ ]: import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Linear/Polynomial Regression (Python, Review) Hopefully, you remember working with Statsmodels during 109a Reading data and (some) exploring in Pandas: In [ ]: diab = pd . read_csv ( \"data/diabetes.csv\" ) print ( \"\"\" # Variables are: # subject: subject ID number # age: age diagnosed with diabetes # acidity: a measure of acidity called base deficit # y: natural log of serum C-peptide concentration # # Original source is Sockett et al. (1987) # mentioned in Hastie and Tibshirani's book # \"Generalized Additive Models\". \"\"\" ) display ( diab . head ()) display ( diab . dtypes ) display ( diab . describe ()) Plotting with matplotlib: In [ ]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear regression with statsmodels. Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. from PolynomialFeatures). Now, Statsmodels' formula interface can help build the target value and design matrix for you. In [ ]: #Using statsmodels import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Build a data frame to predict values on (sometimes this is just the test or validation set) Very useful for making pretty plots of the model predcitions -- predict for TONS of values, not just whatever's in the training set In [ ]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [ ]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Plot the model and error bars In [ ]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Discussion What are the dark error bars? What are the light error bars? Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars Route1: Build a design df with a column for each of age , age**2 , age**3 Route2: Just edit the formula Answers : 1. In [ ]: # your code here In [ ]: fit2_lm = sm . ols ( formula = \"y ~ age + np.power(age, 2) + np.power(age, 3)\" , data = diab ) . fit () poly_predictions = fit2_lm . get_prediction ( predict_df ) . summary_frame () poly_predictions . head () 2. In [ ]: # your code here In [ ]: ax2 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares cubic fit\" ) ax2 . set_xlabel ( \"Age at Diagnosis\" ) ax2 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean' ], color = \"green\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax2 . plot ( predict_df . age , poly_predictions [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Linear/Polynomial Regression, but make it R This is the meat of the lab. After this section we'll know everything we need to in order to work with R models. The rest of the lab is just applying these concepts to run particular models. This section therefore is your 'cheat sheet' for working in R. What we need to know: Importing (base) R functions Importing R Library functions Populating vectors R understands Populating DataFrames R understands Populating Formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation Importing R functions In [ ]: # if you're on JupyterHub you may need to specify the path to R #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2.robjects as robjects In [ ]: r_lm = robjects . r [ \"lm\" ] r_predict = robjects . r [ \"predict\" ] #r_plot = robjects.r[\"plot\"] # more on plotting later #lm() and predict() are two of the most common functions we'll use Importing R libraries In [ ]: from rpy2.robjects.packages import importr #r_cluster = importr('cluster') #r_cluster.pam; Populating vectors R understands In [ ]: r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) # What happens if we pass the wrong type? # How does r_age display? # How does r_age print? Populating Data Frames R understands In [ ]: diab_r = robjects . DataFrame ({ \"y\" : r_y , \"age\" : r_age }) # How does diab_r display? # How does diab_r print? Populating formulas R understands In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) simple_formula . environment [ \"y\" ] = r_y #populate the formula's .environment, so it knows what 'y' and 'age' refer to simple_formula . environment [ \"age\" ] = r_age Running Models in R In [ ]: diab_lm = r_lm ( formula = simple_formula ) # the formula object is storing all the needed variables In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) # reset the formula diab_lm = r_lm ( formula = simple_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe Getting results back to Python In [ ]: diab_lm #the result is already 'in' python, but it's a special object In [ ]: print ( diab_lm . names ) # view all names In [ ]: diab_lm [ 0 ] #grab the first element In [ ]: diab_lm . rx2 ( \"coefficients\" ) #use rx2 to get elements by name! In [ ]: np . array ( diab_lm . rx2 ( \"coefficients\" )) #r vectors can be converted to numpy (but rarely needed) Getting Predictions In [ ]: # make a df to predict on (might just be the validation or test dataframe) predict_df = robjects . DataFrame ({ \"age\" : robjects . FloatVector ( np . linspace ( 0 , 16 , 100 ))}) # call R's predict() function, passing the model and the data predictions = r_predict ( diab_lm , predict_df ) In [ ]: x_vals = predict_df . rx2 ( \"age\" ) In [ ]: ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); #plt still works with r vectors as input! Plotting in R In [ ]: % load_ext rpy2.ipython The above turns on the %R \"magic\" R's plot() command responds differently based on what you hand to it; Different models get different plots! For any specific model search for plot.modelname. E.g. for a GAM model, search plot.gam for any details of plotting a GAM model The %R \"magic\" runs R code in 'notebook' mode, so figures display nicely Ahead of the plot( ) code we pass in the variables R needs to know about ( -i is for \"input\") In [ ]: % R -i diab_lm plot(diab_lm); Reading R's documentation The documentation for the lm() funciton is here , and a prettier version (same content) is here . When googling, perfer rdocumentation.org when possible. Sections: Usage : gives the function signature, including all optional arguments Arguments : What each function input controls Details : additional info on what the funciton does and how arguments interact. Often the right place to start reading Value : the structure of the object returned by the function Refferences : The relevant academic papers See Also : other functions of interest Exercise 2 Add confidence intervals calculated in R to the linear regression plot above. Use the interval= argument to r_predict() (documentation here ). You will have to work with a matrix returned by R. Fit a 5th degree polynomial to the diabetes data in R. Search the web for an easier method than writing out a formula with all 5 polynomial terms. Answers 1. In [ ]: # your code here In [ ]: CI_matrix = np . array ( r_predict ( diab_lm , predict_df , interval = \"confidence\" )) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , CI_matrix [:, 0 ], label = \"prediction\" ) ax . plot ( x_vals , CI_matrix [:, 1 ], label = \"95% CI\" , c = 'g' ) ax . plot ( x_vals , CI_matrix [:, 2 ], label = \"95% CI\" , c = 'g' ) plt . legend (); 2. In [ ]: # your code here In [ ]: ploy5_formula = robjects . Formula ( \"y~poly(age,5)\" ) # reset the formula diab5_lm = r_lm ( formula = ploy5_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe predictions = r_predict ( diab5_lm , predict_df , interval = \"confidence\" ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); Lowess Smoothing Lowess Smoothing is implemented in both Python and R. We'll use it as another example as we transition languages. Discussion What is lowess smoothing? Which 109a models is it related to? How explainable is lowess? What are the tunable parameters? In Python In [ ]: from statsmodels.nonparametric.smoothers_lowess import lowess as lowess ss1 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.15 ) ss2 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.25 ) ss3 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.7 ) ss4 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 1 ) In [ ]: ss1 [: 10 ,:] # we get back simple a smoothed y value for each x value in the data Notice the clean code to plot different models. We'll see even cleaner code in a minute In [ ]: for cur_model , cur_frac in zip ([ ss1 , ss2 , ss3 , ss4 ],[ 0.15 , 0.25 , 0.7 , 1 ]): ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model [:, 0 ], cur_model [:, 1 ], color = \"blue\" ) plt . show () Discussion Which model has high variance, which has high bias? What makes a model high variance or high bias? In R We need to: Import the loess function Send data over to R Call the function and get results In [ ]: r_loess = robjects . r [ 'loess.smooth' ] #extract R function r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) ss1_r = r_loess ( r_age , r_y , span = 0.15 , degree = 1 ) In [ ]: ss1_r #again, a smoothed y value for each x value in the data Exercise 3 Predict the output of ss1_r[0] ss1_r.rx2(\"y\") 1. your answer here 2. your answer here Varying span Next, some extremely clean code to fit and plot models with various parameter settings. (Though the zip() method seen earlier is great when e.g. the label and the parameter differ) In [ ]: for cur_frac in [ 0.15 , 0.25 , 0.7 , 1 ]: cur_smooth = r_loess ( r_age , r_y , span = cur_frac ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_smooth [ 0 ], cur_smooth [ 1 ], color = \"blue\" ) plt . show () Discussion Mark wasn't kidding; the Python and R results differ for frac=.15. Thoughts? Why isn't the bottom plot a straight line? We're using 100% of the data in each window... Smoothing Splines From this point forward, we're working with R functions; these models aren't (well) supported in Python. For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point Discussion Any idea why the winner is cubic? How interpretable is this model? What are the tunable parameters? In [ ]: r_smooth_spline = robjects . r [ 'smooth.spline' ] #extract R function # run smoothing function spline1 = r_smooth_spline ( r_age , r_y , spar = 0 ) Exercise 4 We actually set the spar parameter, a scale-free value that translates to a $\\lambda$ through a complex expression. Inspect the 'spline1' result and extract the implied value of $\\lambda$ Working from the fitting/plotting loop examples above, produce a plot like the one below for spar = [0,.5,.9,2], including axes labels and title. 1. In [ ]: # your answer here In [ ]: lambda1 = spline1 . rx2 ( \"lambda\" ) 2. In [ ]: # your answer here In [ ]: for cur_spar in [ 0 , 0.5 , 0.9 , 2 ]: cur_model = r_smooth_spline ( r_age , r_y , spar = cur_spar ) cur_lambda = cur_model . rx2 ( \"lambda\" )[ 0 ] ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"$\\lambda=$\" + str ( cur_lambda )) #can use TeX style in labels ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model . rx2 ( \"x\" ), cur_model . rx2 ( \"y\" ), color = \"darkgreen\" ) plt . show () CV R's smooth_spline funciton has built-in CV to find a good lambda. See package docs . In [ ]: spline_cv = r_smooth_spline ( r_age , r_y , cv = True ) lambda_cv = spline_cv . rx2 ( \"lambda\" )[ 0 ] ax19 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"smoothing spline with $\\lambda=$\" + str ( np . round ( lambda_cv , 4 )) + \", chosen by cross-validation\" ) ax19 . set_xlabel ( \"Age at Diagnosis\" ) ax19 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax19 . plot ( spline_cv . rx2 ( \"x\" ), spline_cv . rx2 ( \"y\" ), color = \"darkgreen\" ); Discussion Does the selected model look reasonable? How would you describe the effect of age at diagnosis on C_peptide concentration? What are the costs/benefits of the (fancy) spline model, relative to the linear regression we fit above? Natural & Basis Splines Here, we take a step backward on model complexity, but a step forward in coding complexity. We'll be working with R's formula interface again, so we will need to populate Formulas and DataFrames. Discussion In what way are Natural and Basis splines less complex than the splines we were just working with? What makes a spline 'natural'? What makes a spline 'basis'? What are the tuning parameters? In [ ]: #We will now work with a new dataset, called GAGurine. #The dataset description (from the R package MASS) is below: #Data were collected on the concentration of a chemical GAG # in the urine of 314 children aged from zero to seventeen years. # The aim of the study was to produce a chart to help a paediatrican # to assess if a child's GAG concentration is ânormal'. #The variables are: # Age: age of child in years. # GAG: concentration of GAG (the units have been lost). In [ ]: GAGurine = pd . read_csv ( \"data/GAGurine.csv\" ) display ( GAGurine . head ()) ax31 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'black' , title = \"GAG in urine of children\" ) ax31 . set_xlabel ( \"Age\" ); ax31 . set_ylabel ( \"GAG\" ); Standard stuff: import function, convert variables to R format, call function In [ ]: from rpy2.robjects.packages import importr r_splines = importr ( 'splines' ) # populate R variables r_gag = robjects . FloatVector ( GAGurine [ 'GAG' ] . values ) r_age = robjects . FloatVector ( GAGurine [ 'Age' ] . values ) r_quarts = robjects . FloatVector ( np . quantile ( r_age ,[ . 25 , . 5 , . 75 ])) #woah, numpy functions run on R objects! What happens when we call the ns or bs functions from r_splines? In [ ]: ns_design = r_splines . ns ( r_age , knots = r_quarts ) bs_design = r_splines . bs ( r_age , knots = r_quarts ) In [ ]: print ( ns_design ) ns and bs return design matrices, not model objects! That's because they're meant to work with lm 's formula interface. To get a model object we populate a formula including ns( , ) and fit to data In [ ]: r_lm = robjects . r [ 'lm' ] r_predict = robjects . r [ 'predict' ] # populate the formula ns_formula = robjects . Formula ( \"Gag ~ ns(Age, knots=r_quarts)\" ) ns_formula . environment [ 'Gag' ] = r_gag ns_formula . environment [ 'Age' ] = r_age ns_formula . environment [ 'r_quarts' ] = r_quarts # fit the model ns_model = r_lm ( ns_formula ) Predict like usual: build a dataframe to predict on and call predict() In [ ]: # predict predict_frame = robjects . DataFrame ({ \"Age\" : robjects . FloatVector ( np . linspace ( 0 , 20 , 100 ))}) ns_out = r_predict ( ns_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" ]); Exercise 5 Fit a basis spline model with the same knots, and add it to the plot above Fit a basis spline with 8 knots placed at [2,4,6...14,16] and add it to the plot above Answers: 1. In [ ]: # your answer here In [ ]: bs_formula = robjects . Formula ( \"Gag ~ bs(Age, knots=r_quarts)\" ) bs_formula . environment [ 'Gag' ] = r_gag bs_formula . environment [ 'Age' ] = r_age bs_formula . environment [ 'r_quarts' ] = r_quarts bs_model = r_lm ( bs_formula ) bs_out = r_predict ( bs_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), bs_out , color = 'blue' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" , \"B-spline, knots at quartiles\" ]); 2. In [ ]: # your answer here In [ ]: overfit_formula = robjects . Formula ( \"Gag ~ bs(Age, knots=r_quarts)\" ) overfit_formula . environment [ 'Gag' ] = r_gag overfit_formula . environment [ 'Age' ] = r_age overfit_formula . environment [ 'r_quarts' ] = robjects . FloatVector ( np . array ([ 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 ])) overfit_model = r_lm ( overfit_formula ) overfit_out = r_predict ( overfit_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), bs_out , color = 'blue' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), overfit_out , color = 'green' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" , \"B-spline, knots at quartiles\" , \"B-spline, lots of knots\" ]); In [ ]: #%R -i overfit_model plot(overfit_model) # we'd get the same diagnostic plot we get from an lm model GAMs We come, at last, to our most advanced model. The coding here isn't any more complex than we've done before, though the behind-the-scenes is awesome. First, let's get our (multivariate!) data In [ ]: kyphosis = pd . read_csv ( \"data/kyphosis.csv\" ) print ( \"\"\" # kyphosis - wherther a particular deformation was present post-operation # age - patient's age in months # number - the number of vertebrae involved in the operation # start - the number of the topmost vertebrae operated on \"\"\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) In [ ]: #If there are errors about missing R packages, run the code below: #r_utils = importr('utils') #r_utils.install_packages('codetools') #r_utils.install_packages('gam') To fit a GAM, we Import the gam library Populate a formula including s( ) on variables we want to fit smooths for Call gam(formula, family= ) where family is a string naming a probability distribution, chosen based on how the response variable is thought to occur. Rough family guidelines: Response is binary or \"N occurances out of M tries\", e.g. number of lab rats (out of 10) developing disease: chooose \"binomial\" Response is a count with no logical upper bound, e.g. number of ice creams sold: choose \"poisson\" Response is real, with normally-distributed noise, e.g. person's height: choose \"gaussian\" (the default) In [ ]: #There is a Python library in development for using GAMs (https://github.com/dswah/pyGAM) # but it is not yet as comprehensive as the R GAM library, which we will use here instead. # R also has the mgcv library, which implements some more advanced/flexible fitting methods r_gam_lib = importr ( 'gam' ) r_gam = r_gam_lib . gam r_kyph = robjects . FactorVector ( kyphosis [[ \"Kyphosis\" ]] . values ) r_Age = robjects . FloatVector ( kyphosis [[ \"Age\" ]] . values ) r_Number = robjects . FloatVector ( kyphosis [[ \"Number\" ]] . values ) r_Start = robjects . FloatVector ( kyphosis [[ \"Start\" ]] . values ) kyph1_fmla = robjects . Formula ( \"Kyphosis ~ s(Age) + s(Number) + s(Start)\" ) kyph1_fmla . environment [ 'Kyphosis' ] = r_kyph kyph1_fmla . environment [ 'Age' ] = r_Age kyph1_fmla . environment [ 'Number' ] = r_Number kyph1_fmla . environment [ 'Start' ] = r_Start kyph1_gam = r_gam ( kyph1_fmla , family = \"binomial\" ) The fitted gam model has a lot of interesting data within it In [ ]: print ( kyph1_gam . names ) Remember plotting? Calling R's plot() on a gam model is the easiest way to view the fitted splines In [ ]: % R -i kyph1_gam plot(kyph1_gam, residuals=TRUE,se=TRUE, scale=20); Prediction works like normal (build a data frame to predict on, if you don't already have one, and call predict() ). However, predict always reports the sum of the individual variable effects. If family is non-default this can be different from the actual prediction for that point. For instance, we're doing a 'logistic regression' so the raw prediction is log odds, but we can get probability by using in predict(..., type=\"response\") In [ ]: kyph_new = robjects . DataFrame ({ 'Age' : robjects . IntVector (( 84 , 85 , 86 )), 'Start' : robjects . IntVector (( 5 , 3 , 1 )), 'Number' : robjects . IntVector (( 1 , 6 , 10 ))}) print ( \"Raw response (so, Log odds):\" ) display ( r_predict ( kyph1_gam , kyph_new )) print ( \"Scaled response (so, probabilty of kyphosis):\" ) display ( r_predict ( kyph1_gam , kyph_new , type = \"response\" )) Discussion Exercise 6 What lambda did we use? What is the model telling us about the effects of age, starting vertebrae, and number of vertebae operated on If we fit a logistic regression instead, which variables might want quadratic terms. What is the cost and benefit of a logistic regression model versus a GAM? Critique the model: What is it assuming? Are the assumptions reasonable Are we using the right data? Does the model's story about the world make sense? Appendix GAMs and smoothing splines support hypothesis tets to compare models. (We can always compare models via out-of-sample prediction quality (i.e. performance on a validation set), but statistical ideas like hypothesis tests yet information criteria allow us to use all data for training and still compare the quality of model A to model B) In [ ]: r_anova = robjects . r [ \"anova\" ] kyph0_fmla = robjects . Formula ( \"Kyphosis~1\" ) kyph0_fmla . environment [ 'Kyphosis' ] = r_kyph kyph0_gam = r_gam ( kyph0_fmla , family = \"binomial\" ) print ( r_anova ( kyph0_gam , kyph1_gam , test = \"Chi\" )) Explicitly joining spline functions In [ ]: def h ( x , xi , pow_arg ): #pow is a reserved keyword in Python if ( x > xi ): return pow (( x - xi ), pow_arg ) else : return 0 h = np . vectorize ( h , otypes = [ np . float ]) #default behavior is to return ints, which gives incorrect answer #also, vectorize does not play nicely with default arguments, so better to set directly (e.g., pow_arg=1) In [ ]: xvals = np . arange ( 0 , 10.1 , 0.1 ) ax20 = plt . plot ( xvals , h ( xvals , 4 , 1 ), color = \"red\" ) _ = plt . title ( \"Truncated linear basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+$\" ) #note the use of TeX in the label In [ ]: ax21 = plt . plot ( xvals , h ( xvals , 4 , 3 ), color = \"red\" ) _ = plt . title ( \"Truncated cubic basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+&#94;3$\" ) In [ ]: ax22 = plt . plot ( xvals , 2 + xvals + 3 * h ( xvals , 2 , 1 ) - 4 * h ( xvals , 5 , 1 ) + 0.5 * h ( xvals , 8 , 1 ), color = \"red\" ) _ = plt . title ( \"Piecewise linear spline with knots at x=2, 5, and 8\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) Comparing splines to the (noisy) model that generated them. In [ ]: x = np . arange ( 0.1 , 10 , 9.9 / 100 ) from scipy.stats import norm #ppf (percent point function) is the rather unusual name for #the quantile or inverse CDF function in SciPy y = norm . ppf ( x / 10 ) + np . random . normal ( 0 , 0.4 , 100 ) ax23 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,2,1)+h(x,5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax24 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3.5,1)+h(x,5,1)+h(x,6.5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax25 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3,1)+h(x,4,1)+h(x,5,1)+h(x,6,1)+h(x,7,1)+h(x,8,1)+h(x,9,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr = 'y~x+' for i in range ( 1 , 26 ): regstr += 'h(x,' + str ( i / 26 * 10 ) + ',1)+' regstr = regstr [: - 1 ] #drop last + ax26 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) Exercise: Try generating random data from different distributions and fitting polynomials of different degrees to it. What do you observe? In [ ]: # try it here In [ ]: #So, we see that increasing the number of knots results in a more polynomial-like fit In [ ]: #Next, we look at cubic splines with increasing numbers of knots ax27 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,2,3)+h(x,5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax28 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3.5,3)+h(x,5,3)+h(x,6.5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax29 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3,3)+h(x,4,3)+h(x,5,3)+h(x,6,3)+h(x,7,3)+h(x,8,3)+h(x,9,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr2 = 'y~x+np.power(x,2)+np.power(x,3)+' for i in range ( 1 , 26 ): regstr2 += 'h(x,' + str ( i / 26 * 10 ) + ',3)+' regstr2 = regstr2 [: - 1 ] #drop last + ax30 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr2 , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab2/solutions/"},{"title":"Lab 2: Smooths and GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models Harvard University Spring 2019 Instructors: Mark Glickman and Pavlos Protopapas Lab Instructors: Will Claybaugh Contributors: Paul Tyklin and Will Claybaugh In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals The main goal of this lab is to get familiar with calling R functions within Python. Along the way, we'll learn about the \"formula\" interface to statsmodels, which gives an intuitive way of specifying regression models, and we'll review the different approaches to fitting curves. Key Skills: Importing (base) R functions Importing R library functions Populating vectors R understands Populating dataframes R understands Populating formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation In [ ]: import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Linear/Polynomial Regression (Python, Review) Hopefully, you remember working with Statsmodels during 109a Reading data and (some) exploring in Pandas: In [ ]: diab = pd . read_csv ( \"data/diabetes.csv\" ) print ( \"\"\" # Variables are: # subject: subject ID number # age: age diagnosed with diabetes # acidity: a measure of acidity called base deficit # y: natural log of serum C-peptide concentration # # Original source is Sockett et al. (1987) # mentioned in Hastie and Tibshirani's book # \"Generalized Additive Models\". \"\"\" ) display ( diab . head ()) display ( diab . dtypes ) display ( diab . describe ()) Plotting with matplotlib: In [ ]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear regression with statsmodels. Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. from PolynomialFeatures). Now, Statsmodels' formula interface can help build the target value and design matrix for you. In [ ]: #Using statsmodels import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Build a data frame to predict values on (sometimes this is just the test or validation set) Very useful for making pretty plots of the model predcitions -- predict for TONS of values, not just whatever's in the training set In [ ]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [ ]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Plot the model and error bars In [ ]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Discussion What are the dark error bars? What are the light error bars? Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars Route1: Build a design df with a column for each of age , age**2 , age**3 Route2: Just edit the formula Answers : 1. In [ ]: # your code here 2. In [ ]: # your code here Linear/Polynomial Regression, but make it R This is the meat of the lab. After this section we'll know everything we need to in order to work with R models. The rest of the lab is just applying these concepts to run particular models. This section therefore is your 'cheat sheet' for working in R. What we need to know: Importing (base) R functions Importing R Library functions Populating vectors R understands Populating DataFrames R understands Populating Formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation Importing R functions In [ ]: # if you're on JupyterHub you may need to specify the path to R #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2.robjects as robjects In [ ]: r_lm = robjects . r [ \"lm\" ] r_predict = robjects . r [ \"predict\" ] #r_plot = robjects.r[\"plot\"] # more on plotting later #lm() and predict() are two of the most common functions we'll use Importing R libraries In [ ]: from rpy2.robjects.packages import importr #r_cluster = importr('cluster') #r_cluster.pam; Populating vectors R understands In [ ]: r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) # What happens if we pass the wrong type? # How does r_age display? # How does r_age print? Populating Data Frames R understands In [ ]: diab_r = robjects . DataFrame ({ \"y\" : r_y , \"age\" : r_age }) # How does diab_r display? # How does diab_r print? Populating formulas R understands In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) simple_formula . environment [ \"y\" ] = r_y #populate the formula's .environment, so it knows what 'y' and 'age' refer to simple_formula . environment [ \"age\" ] = r_age Running Models in R In [ ]: diab_lm = r_lm ( formula = simple_formula ) # the formula object is storing all the needed variables In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) # reset the formula diab_lm = r_lm ( formula = simple_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe Getting results back to Python In [ ]: diab_lm #the result is already 'in' python, but it's a special object In [ ]: print ( diab_lm . names ) # view all names In [ ]: diab_lm [ 0 ] #grab the first element In [ ]: diab_lm . rx2 ( \"coefficients\" ) #use rx2 to get elements by name! In [ ]: np . array ( diab_lm . rx2 ( \"coefficients\" )) #r vectors can be converted to numpy (but rarely needed) Getting Predictions In [ ]: # make a df to predict on (might just be the validation or test dataframe) predict_df = robjects . DataFrame ({ \"age\" : robjects . FloatVector ( np . linspace ( 0 , 16 , 100 ))}) # call R's predict() function, passing the model and the data predictions = r_predict ( diab_lm , predict_df ) In [ ]: x_vals = predict_df . rx2 ( \"age\" ) In [ ]: ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); #plt still works with r vectors as input! Plotting in R In [ ]: % load_ext rpy2.ipython The above turns on the %R \"magic\" R's plot() command responds differently based on what you hand to it; Different models get different plots! For any specific model search for plot.modelname. E.g. for a GAM model, search plot.gam for any details of plotting a GAM model The %R \"magic\" runs R code in 'notebook' mode, so figures display nicely Ahead of the plot( ) code we pass in the variables R needs to know about ( -i is for \"input\") In [ ]: % R -i diab_lm plot(diab_lm); Reading R's documentation The documentation for the lm() funciton is here , and a prettier version (same content) is here . When googling, perfer rdocumentation.org when possible. Sections: Usage : gives the function signature, including all optional arguments Arguments : What each function input controls Details : additional info on what the funciton does and how arguments interact. Often the right place to start reading Value : the structure of the object returned by the function Refferences : The relevant academic papers See Also : other functions of interest Exercise 2 Add confidence intervals calculated in R to the linear regression plot above. Use the interval= argument to r_predict() (documentation here ). You will have to work with a matrix returned by R. Fit a 5th degree polynomial to the diabetes data in R. Search the web for an easier method than writing out a formula with all 5 polynomial terms. Answers 1. In [ ]: # your code here 2. In [ ]: # your code here Lowess Smoothing Lowess Smoothing is implemented in both Python and R. We'll use it as another example as we transition languages. Discussion What is lowess smoothing? Which 109a models is it related to? How explainable is lowess? What are the tunable parameters? In Python In [ ]: from statsmodels.nonparametric.smoothers_lowess import lowess as lowess ss1 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.15 ) ss2 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.25 ) ss3 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.7 ) ss4 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 1 ) In [ ]: ss1 [: 10 ,:] # we get back simple a smoothed y value for each x value in the data Notice the clean code to plot different models. We'll see even cleaner code in a minute In [ ]: for cur_model , cur_frac in zip ([ ss1 , ss2 , ss3 , ss4 ],[ 0.15 , 0.25 , 0.7 , 1 ]): ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model [:, 0 ], cur_model [:, 1 ], color = \"blue\" ) plt . show () Discussion Which model has high variance, which has high bias? What makes a model high variance or high bias? In R We need to: Import the loess function Send data over to R Call the function and get results In [ ]: r_loess = robjects . r [ 'loess.smooth' ] #extract R function r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) ss1_r = r_loess ( r_age , r_y , span = 0.15 , degree = 1 ) In [ ]: ss1_r #again, a smoothed y value for each x value in the data Exercise 3 Predict the output of ss1_r[0] ss1_r.rx2(\"y\") 1. your answer here 2. your answer here Varying span Next, some extremely clean code to fit and plot models with various parameter settings. (Though the zip() method seen earlier is great when e.g. the label and the parameter differ) In [ ]: for cur_frac in [ 0.15 , 0.25 , 0.7 , 1 ]: cur_smooth = r_loess ( r_age , r_y , span = cur_frac ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_smooth [ 0 ], cur_smooth [ 1 ], color = \"blue\" ) plt . show () Discussion Mark wasn't kidding; the Python and R results differ for frac=.15. Thoughts? Why isn't the bottom plot a straight line? We're using 100% of the data in each window... Smoothing Splines From this point forward, we're working with R functions; these models aren't (well) supported in Python. For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point Discussion Any idea why the winner is cubic? How interpretable is this model? What are the tunable parameters? In [ ]: r_smooth_spline = robjects . r [ 'smooth.spline' ] #extract R function # run smoothing function spline1 = r_smooth_spline ( r_age , r_y , spar = 0 ) Exercise 4 We actually set the spar parameter, a scale-free value that translates to a $\\lambda$ through a complex expression. Inspect the 'spline1' result and extract the implied value of $\\lambda$ Working from the fitting/plotting loop examples above, produce a plot like the one below for spar = [0,.5,.9,2], including axes labels and title. 1. In [ ]: # your answer here 2. In [ ]: # your answer here CV R's smooth_spline funciton has built-in CV to find a good lambda. See package docs . In [ ]: spline_cv = r_smooth_spline ( r_age , r_y , cv = True ) lambda_cv = spline_cv . rx2 ( \"lambda\" )[ 0 ] ax19 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"smoothing spline with $\\lambda=$\" + str ( np . round ( lambda_cv , 4 )) + \", chosen by cross-validation\" ) ax19 . set_xlabel ( \"Age at Diagnosis\" ) ax19 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax19 . plot ( spline_cv . rx2 ( \"x\" ), spline_cv . rx2 ( \"y\" ), color = \"darkgreen\" ); Discussion Does the selected model look reasonable? How would you describe the effect of age at diagnosis on C_peptide concentration? What are the costs/benefits of the (fancy) spline model, relative to the linear regression we fit above? Natural & Basis Splines Here, we take a step backward on model complexity, but a step forward in coding complexity. We'll be working with R's formula interface again, so we will need to populate Formulas and DataFrames. Discussion In what way are Natural and Basis splines less complex than the splines we were just working with? What makes a spline 'natural'? What makes a spline 'basis'? What are the tuning parameters? In [ ]: #We will now work with a new dataset, called GAGurine. #The dataset description (from the R package MASS) is below: #Data were collected on the concentration of a chemical GAG # in the urine of 314 children aged from zero to seventeen years. # The aim of the study was to produce a chart to help a paediatrican # to assess if a child's GAG concentration is ânormal'. #The variables are: # Age: age of child in years. # GAG: concentration of GAG (the units have been lost). In [ ]: GAGurine = pd . read_csv ( \"data/GAGurine.csv\" ) display ( GAGurine . head ()) ax31 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'black' , title = \"GAG in urine of children\" ) ax31 . set_xlabel ( \"Age\" ); ax31 . set_ylabel ( \"GAG\" ); Standard stuff: import function, convert variables to R format, call function In [ ]: from rpy2.robjects.packages import importr r_splines = importr ( 'splines' ) # populate R variables r_gag = robjects . FloatVector ( GAGurine [ 'GAG' ] . values ) r_age = robjects . FloatVector ( GAGurine [ 'Age' ] . values ) r_quarts = robjects . FloatVector ( np . quantile ( r_age ,[ . 25 , . 5 , . 75 ])) #woah, numpy functions run on R objects! What happens when we call the ns or bs functions from r_splines? In [ ]: ns_design = r_splines . ns ( r_age , knots = r_quarts ) bs_design = r_splines . bs ( r_age , knots = r_quarts ) In [ ]: print ( ns_design ) ns and bs return design matrices, not model objects! That's because they're meant to work with lm 's formula interface. To get a model object we populate a formula including ns( , ) and fit to data In [ ]: r_lm = robjects . r [ 'lm' ] r_predict = robjects . r [ 'predict' ] # populate the formula ns_formula = robjects . Formula ( \"Gag ~ ns(Age, knots=r_quarts)\" ) ns_formula . environment [ 'Gag' ] = r_gag ns_formula . environment [ 'Age' ] = r_age ns_formula . environment [ 'r_quarts' ] = r_quarts # fit the model ns_model = r_lm ( ns_formula ) Predict like usual: build a dataframe to predict on and call predict() In [ ]: # predict predict_frame = robjects . DataFrame ({ \"Age\" : robjects . FloatVector ( np . linspace ( 0 , 20 , 100 ))}) ns_out = r_predict ( ns_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" ]); Exercise 5 Fit a basis spline model with the same knots, and add it to the plot above Fit a basis spline with 8 knots placed at [2,4,6...14,16] and add it to the plot above Answers: 1. In [ ]: # your answer here 2. In [ ]: # your answer here In [ ]: #%R -i overfit_model plot(overfit_model) # we'd get the same diagnostic plot we get from an lm model GAMs We come, at last, to our most advanced model. The coding here isn't any more complex than we've done before, though the behind-the-scenes is awesome. First, let's get our (multivariate!) data In [ ]: kyphosis = pd . read_csv ( \"data/kyphosis.csv\" ) print ( \"\"\" # kyphosis - wherther a particular deformation was present post-operation # age - patient's age in months # number - the number of vertebrae involved in the operation # start - the number of the topmost vertebrae operated on \"\"\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) In [ ]: #If there are errors about missing R packages, run the code below: #r_utils = importr('utils') #r_utils.install_packages('codetools') #r_utils.install_packages('gam') To fit a GAM, we Import the gam library Populate a formula including s( ) on variables we want to fit smooths for Call gam(formula, family= ) where family is a string naming a probability distribution, chosen based on how the response variable is thought to occur. Rough family guidelines: Response is binary or \"N occurances out of M tries\", e.g. number of lab rats (out of 10) developing disease: chooose \"binomial\" Response is a count with no logical upper bound, e.g. number of ice creams sold: choose \"poisson\" Response is real, with normally-distributed noise, e.g. person's height: choose \"gaussian\" (the default) In [ ]: #There is a Python library in development for using GAMs (https://github.com/dswah/pyGAM) # but it is not yet as comprehensive as the R GAM library, which we will use here instead. # R also has the mgcv library, which implements some more advanced/flexible fitting methods r_gam_lib = importr ( 'gam' ) r_gam = r_gam_lib . gam r_kyph = robjects . FactorVector ( kyphosis [[ \"Kyphosis\" ]] . values ) r_Age = robjects . FloatVector ( kyphosis [[ \"Age\" ]] . values ) r_Number = robjects . FloatVector ( kyphosis [[ \"Number\" ]] . values ) r_Start = robjects . FloatVector ( kyphosis [[ \"Start\" ]] . values ) kyph1_fmla = robjects . Formula ( \"Kyphosis ~ s(Age) + s(Number) + s(Start)\" ) kyph1_fmla . environment [ 'Kyphosis' ] = r_kyph kyph1_fmla . environment [ 'Age' ] = r_Age kyph1_fmla . environment [ 'Number' ] = r_Number kyph1_fmla . environment [ 'Start' ] = r_Start kyph1_gam = r_gam ( kyph1_fmla , family = \"binomial\" ) The fitted gam model has a lot of interesting data within it In [ ]: print ( kyph1_gam . names ) Remember plotting? Calling R's plot() on a gam model is the easiest way to view the fitted splines In [ ]: % R -i kyph1_gam plot(kyph1_gam, residuals=TRUE,se=TRUE, scale=20); Prediction works like normal (build a data frame to predict on, if you don't already have one, and call predict() ). However, predict always reports the sum of the individual variable effects. If family is non-default this can be different from the actual prediction for that point. For instance, we're doing a 'logistic regression' so the raw prediction is log odds, but we can get probability by using in predict(..., type=\"response\") In [ ]: kyph_new = robjects . DataFrame ({ 'Age' : robjects . IntVector (( 84 , 85 , 86 )), 'Start' : robjects . IntVector (( 5 , 3 , 1 )), 'Number' : robjects . IntVector (( 1 , 6 , 10 ))}) print ( \"Raw response (so, Log odds):\" ) display ( r_predict ( kyph1_gam , kyph_new )) print ( \"Scaled response (so, probabilty of kyphosis):\" ) display ( r_predict ( kyph1_gam , kyph_new , type = \"response\" )) Discussion Exercise 6 What lambda did we use? What is the model telling us about the effects of age, starting vertebrae, and number of vertebae operated on If we fit a logistic regression instead, which variables might want quadratic terms. What is the cost and benefit of a logistic regression model versus a GAM? Critique the model: What is it assuming? Are the assumptions reasonable Are we using the right data? Does the model's story about the world make sense? Appendix GAMs and smoothing splines support hypothesis tets to compare models. (We can always compare models via out-of-sample prediction quality (i.e. performance on a validation set), but statistical ideas like hypothesis tests yet information criteria allow us to use all data for training and still compare the quality of model A to model B) In [ ]: r_anova = robjects . r [ \"anova\" ] kyph0_fmla = robjects . Formula ( \"Kyphosis~1\" ) kyph0_fmla . environment [ 'Kyphosis' ] = r_kyph kyph0_gam = r_gam ( kyph0_fmla , family = \"binomial\" ) print ( r_anova ( kyph0_gam , kyph1_gam , test = \"Chi\" )) Explicitly joining spline functions In [ ]: def h ( x , xi , pow_arg ): #pow is a reserved keyword in Python if ( x > xi ): return pow (( x - xi ), pow_arg ) else : return 0 h = np . vectorize ( h , otypes = [ np . float ]) #default behavior is to return ints, which gives incorrect answer #also, vectorize does not play nicely with default arguments, so better to set directly (e.g., pow_arg=1) In [ ]: xvals = np . arange ( 0 , 10.1 , 0.1 ) ax20 = plt . plot ( xvals , h ( xvals , 4 , 1 ), color = \"red\" ) _ = plt . title ( \"Truncated linear basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+$\" ) #note the use of TeX in the label In [ ]: ax21 = plt . plot ( xvals , h ( xvals , 4 , 3 ), color = \"red\" ) _ = plt . title ( \"Truncated cubic basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+&#94;3$\" ) In [ ]: ax22 = plt . plot ( xvals , 2 + xvals + 3 * h ( xvals , 2 , 1 ) - 4 * h ( xvals , 5 , 1 ) + 0.5 * h ( xvals , 8 , 1 ), color = \"red\" ) _ = plt . title ( \"Piecewise linear spline with knots at x=2, 5, and 8\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) Comparing splines to the (noisy) model that generated them. In [ ]: x = np . arange ( 0.1 , 10 , 9.9 / 100 ) from scipy.stats import norm #ppf (percent point function) is the rather unusual name for #the quantile or inverse CDF function in SciPy y = norm . ppf ( x / 10 ) + np . random . normal ( 0 , 0.4 , 100 ) ax23 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,2,1)+h(x,5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax24 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3.5,1)+h(x,5,1)+h(x,6.5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax25 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3,1)+h(x,4,1)+h(x,5,1)+h(x,6,1)+h(x,7,1)+h(x,8,1)+h(x,9,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr = 'y~x+' for i in range ( 1 , 26 ): regstr += 'h(x,' + str ( i / 26 * 10 ) + ',1)+' regstr = regstr [: - 1 ] #drop last + ax26 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) Exercise: Try generating random data from different distributions and fitting polynomials of different degrees to it. What do you observe? In [ ]: # try it here In [ ]: #So, we see that increasing the number of knots results in a more polynomial-like fit In [ ]: #Next, we look at cubic splines with increasing numbers of knots ax27 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,2,3)+h(x,5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax28 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3.5,3)+h(x,5,3)+h(x,6.5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax29 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3,3)+h(x,4,3)+h(x,5,3)+h(x,6,3)+h(x,7,3)+h(x,8,3)+h(x,9,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr2 = 'y~x+np.power(x,2)+np.power(x,3)+' for i in range ( 1 , 26 ): regstr2 += 'h(x,' + str ( i / 26 * 10 ) + ',3)+' regstr2 = regstr2 [: - 1 ] #drop last + ax30 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr2 , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab2/students/"},{"title":"Lecture 4: Smoothing and Additive 3/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture4/"},{"title":"Lecture 2: Smoothing and Additive 1/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture2/"},{"title":"Lecture 3: Smoothing and Additive 2/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture3/"},{"title":"Lab 1: Setting up environment","text":"Slides PDF PPTX Notebooks R_setup Notes Installation Instructions for JupyterHub","tags":"labs","url":"labs/lab1/"},{"title":"Lab 1: R set up","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } In [ ]: #---------Test Imports------------- import numpy as np import keras import gensim import nltk keras . layers . Dense ( 20 ) In [ ]: #-------Download R packages--------- ## these two lines for JupyterHub only #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2 from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) package_list = [ 'aplpack' , 'cluster' , 'codetools' , 'dbscan' , 'factoextra' , 'gam' , 'ggplot2' , 'splines' , 'TeachingDemos' ] for name in package_list : r_utils . install_packages ( name ) import rpy2 from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) package_list = [ 'aplpack' , 'cluster' , 'codetools' , 'dbscan' , 'factoextra' , 'gam' , 'ggplot2' , 'splines' , 'TeachingDemos' ] for name in package_list : r_utils . install_packages ( name ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab1/Rset/"},{"title":"Lecture 1:  Introduction, Review of 109A and preview of 109B","text":"Slides PDF PPTX","tags":"lectures","url":"lectures/lecture1/"},{"title":"Advance Sections 3","text":"Advance Sections 3","tags":"pages","url":"pages/a-section3/"},{"title":"Advance Sections 4","text":"Advance Sections 4","tags":"pages","url":"pages/a-section4/"},{"title":"Advance Sections 5","text":"Advance Sections 5","tags":"pages","url":"pages/a-section5/"},{"title":"Advance Sections 6","text":"Advance Sections 6","tags":"pages","url":"pages/a-section6/"},{"title":"Advance Sections 7","text":"Advance Sections 7","tags":"pages","url":"pages/a-section7/"},{"title":"Lecture 24","text":"Lecture 24","tags":"pages","url":"pages/lecture24/"},{"title":"Lecture 25","text":"Lecture 25","tags":"pages","url":"pages/lecture25/"},{"title":"CS 109B: Advanced Topics in Data","text":"Spring 2019 Pavlos Protopapas and Mark Glickman pavlos@seas.harvard.edu glickman@fas.harvard.edu Pavlos: Mondays 3-4pm at MD G108 Mark: By appointment Head TFs: Eleni Kaxiras eleni@seas.harvard.edu Head TF for DCE: Sol Girouard solgirouard@g.harvard.edu Lectures: Mon and Wed 1:30â2:45pm in Maxwell-Dworkin G-115 Labs: Thur 4:30-6:00pm in Pierce 301 Advanced Sections: Wed. 3:00pm-4:15pm, location TBD (starting 2/13) Prerequisites: CS 109a, AC 209a, Stat 121a, CSCI E-109a or equivalent. Data Science 2 is the second half of a one-year introduction to data science. Building upon the material in Data Science 1, the course introduces advanced methods for data wrangling, data visualization, and deep neural networks, statistical modeling, and prediction. Topics include big data and database management, multiple deep learning subjects such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models and unsupervised learning. Announcements: Video-recorded Lectures from CS109A Fall '18 Advanced Sections start tomorrow Wed. Feb 13th at NW B-103 Pierce Hall is at 29 Oxford St in Cambridge. Maxwell Dworkin (MD) is at 33 Oxford St, Cambridge. Northwest Building (NW) is at 52 Oxford St, Cambridge. HELPLINE: cs109b2019@gmail.com Office Hours : Weekly Schedule For enrollment issues including cross-registration: contact the FAS Registrar's Office either in person at the Smith Campus Center (1350 Massachusetts Avenue, Suite 450) or by sending an email to registrar@fas.harvard.ed Previous Material: 2018 pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } .contentA { flex: 1; flex-direction:column; } .contentB { flex: 3; }","tags":"pages","url":"pages/cs-109b-advanced-topics-in-data/"}]}