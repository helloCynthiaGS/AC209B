var tipuesearch = {"pages":[{"title":"GitHub Page","text":"All course content (except Lectures 2-4, 12-13, and 15-17) is in: GitHub repo We suggest that you clone this repository.","tags":"pages","url":"pages/github.html"},{"title":"Modules Page","text":"Module description and details go here","tags":"pages","url":"pages/modules.html"},{"title":"Schedule","text":"Week Date Lecture (Mon) Date Lecture (Wed) Lab Advanced Section (Wed) Assignment (release and due) 1 28-Jan Lecture 1: Intro + Review of 109A Preview of 109B 30-Jan Lecture 2: Smoothing and Additive 1/3 Lab 1: Setting up enviroment 2 4-Feb Lecture 3: Smoothing and Additive 2/3 6-Feb Lecture 4: Smoothing and GAM 3/3 Lab 2: Smoothing/GAM HW1 (2/3) 3 11-Feb Lecture 5: Feed Forward + Reg + Review from NN fall 13-Feb Lecture 6: Optimization of NN (Solvers) Lab 3: Optimization Advanced Section 1: Optimization/Dropout HW2 (2/10) 4 18-Feb Holiday 20-Feb Lecture 7: AWS scalable systems SQL Lab 4: Setting UP AWS Advanced Section 2: Optimal Transport 5 25-Feb Lecture 8: CNNs-1 27-Feb Lecture 9: CNNs-2 Lab 5: CNNs Advanced Section 3: CNNs and Object Detection HW3 (2/24) 6 4-Mar Lecture 10: RNN 1 6-Mar Lecture 11: RNN 2 Lab 6: RNNS Advanced Section 4: RNNs HW4 (3/3) 7 11-Mar Lecture 12: Unsupervised learning/clustering 1 13-Mar Lecture 13: Unsupervised learning/clustering 2 Lab 7: Clusterig Advanced Section 5: Neural Style Transfer HW5 (3/10) 8 25-Mar Lecture 14: Reinforcement Learning 27-Mar Lecture 15: Bayesian 1/3 Lab 8: Bayes 1 9 1-Apr Lecture 16: Bayesian 2/3 3-Apr Lecture 17: Bayesian 3/3 Lab 9: Bayes 2 Advanced Section 7:LDA and Bayes HW6 (3/30) 10 8-Apr Lecture 18: Generative Models Varational Autoenders 1 8-Apr Lecture 19: Generative Models Varational Autoenders 2 Lab 10: VAE Advanced Section 8:VAE+GANS HW7 (4/7) 11 15-Apr Lecture 20: GANS 1 17-Apr Lecture 21: GANS 2 Lab 11: GANS","tags":"pages","url":"pages/schedule.html"},{"title":"Syllabus","text":"Course description Tentative Course Topics Course Objectives Course Components Lectures Labs In-class Quizzes Advanced Sections Exams Projects Homework Assignments Course Resources Online Materials Recommended Textbooks Getting Help Course Policies and Expectations Grading Collaboration Policy Late or Wrongly Submitted Assignments Re-grade Requests Auditing the Class Academic Integrity Accommodations for students with disabilities Diversity and Inclusion Statement Course description Data Science 2 is the second half of a one-year introduction to data science. Building upon the material in Data Science 1, the course introduces advanced methods for data wrangling, data visualization, and deep neural networks, statistical modeling, and prediction. Topics include big data and database management, multiple deep learning subjects such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models and unsupervised learning. The programming language will be python. Tentative Course Topics Feed Forward Neural Networks Regularization of Neural Network Optimization of Neural Networks Autoencoders Convolutional Neural Networks Recurrent Neural Networks Variational AutoEncoders Generative Adversarial Networks Smoothing and Additive Models Unsupervised Learning Bayesian Inference Models, LDA SQL AWS Course Objectives Upon successful completion of this course, you should feel comfortable with the material mentioned above, plus you will have had experience in working with others on real-world problems. Both the content knowledge, the project, and teamwork, will prepare you for the professional world or further studies. Course Components There will be live video feed available only to distance education students for lectures, labs, and advanced sections. Recordings for all other students will be available within 24 hrs. Lectures The class meets twice a week for lectures. Attending lectures is a crucial component of learning the material presented in this course. Labs Lectures are supplemented by weekly programming labs. Labs are an important aspect of the course, as they supplement material from lectures with examples, discuss programming environments, and teach you important skills. In-class Quizzes At the end of each lecture, we will ask you to take a short graded quiz on the material presented in class. These quizzes will count towards your final grade. Advanced Sections The course will include advanced sections for 209 students and will cover a different topic per week. These are 75 min lectures and they will cover advanced topics like the mathematical underpinnings of the methods seen in lecture and lab and extensions of those methods. The material covered in the advanced sections is required for all ac209 students. Tentative topics are: Earth Mover's Distance Dropout ConvNets: LeNet, AlexNet, VGG-15, ResNet and Inception LSTN, GRU in NLP Neural style transfer learning Deep Reinforcement Learning Variational Inference Exams There are no exams in this course. Projects - For distant students The goal of the project is to have a complete end-to-end data science process encompassing both semesters of subject material while working as a 3-4 person team. We will supply a small set of project choices within the thematic categories. Teams may propose a different project with sufficient notice and will be subject to approval by the course staff. - For campus students During the final four (4) weeks of the course, students will be divided in break-out thematic sections where they will study topics such as medicine, law, astronomy, e-commerce, and government. Each section will include lectures by Harvard faculty, experts on the field, followed by project work also led by that faculty. You will get to present your projects in the SEAS Design Fair at the end of the semester. Homework Assignments There will be seven graded homework assignments. Some of them will be due one week after being assigned and some will be due two weeks after being assigned. For five assignments, you have the option to work and submit in pairs, the two remaining are to be completed individually. Course Resources Online Materials All course materials, including lecture notes, lab notes, and section notes will be published in the class GitHub: https://github.com/Harvard-IACS/2019-CS109B . Assignments will only be posted on Canvas. Working environment You will be working in Jupyter Notebooks which you can run in your own machine or in the SEAS JupyterHub cloud (details on this to come). Recommended Textbooks ISLR: An Introduction to Statistical Learning. by James, Witten, Hastie, Tibshirani (Springer: New York, 2013) DL: Deep Learning by Goodfellow, Bengio and Courville. Free electronic versions are available ( ISLR ), ( DL) or hard copy through Amazon ( ISLR) , ( DL ). Getting Help For questions about homework, course content, package installation, the process is: try to troubleshoot yourself by reading the lecture, lab, and section notes, and looking up online resources. go to office hours this is the best way to get help. post on the class Piazza; we want you and your peers to engage in helping each other. TFs also monitor Piazza and will respond within 24 hours. Note that Piazza questions are visible to everyone. If you are citing homework solution code you want to post privately so that only the staff sees your message. watch for official announcements via Canvas so make sure you have your Canvas notifications turned on. Piazza should always be your first resource for seeking answers to your content questions. send an email to the Helpline ( cs109b2019@gmail.com ) for administrative issues, regrade requests, and non-content specific questions we have this email account. for personal matters that you do not feel comfortable sharing with the TFs, you may send an email to either or both of the instructors. Course Policies and Expectations Grading for CS109b, STAT121b, and CS209b: <<<<<<< HEAD ======= 3aa6558f04b882eacb6af4d0b69db82445ca5329 Paired-option Homeworks 45% (5 homework for which you have the option to work in pairs) Individual Homeworks 25% (2 homework which you must complete individually) Quizzes 10% (you may drop 40% of the quizzes) Project 20% TOTAL 100% Note: Regular homework (for everyone) counts as 5 points. 209b extra homework counts as 1 point. Grading for DCE: Paired-option Homeworks 48% (5 homework for which you have the option to work in pairs) Individual Homeworks 28% (2 homework which you must complete individually) Project 24% TOTAL 100% Collaboration Policy We expect you to adhere to the Harvard Honor Code at all times. Failure to adhere to the honor code and our policies may result in serious penalties, up to and including automatic failure in the course and reference to the ad board. If you work with a partner on an assignment make sure both parties solve all the problems. Do not divide and conquer. You are expected to be intellectually honest and give credit where credit is due. In particular: if you work with a fellow student but decide to submit different papers, include the name of each other in the designated area of the submission paper. if you work with a fellow student and want to submit the same paper you need to form a group prior to the submission. Details in the assignment. Not all assignments will permit group submissions. you need to write your solutions entirely on your own or with your collaborator you are welcome to take ideas from code presented in labs, lecture, or sections but you need to change it, adapt it to your style, and ultimately write your own. We do not want to see code copied verbatim from the above sources. if you use code found on the internet, books, or other sources you need to cite those sources. you should not view any written materials or code created by other students for the same assignment; you may not provide or make available solutions to individuals who take or may take this course in the future. if the assignment allows it you may use third-party libraries and example code, so long as the material is available to all students in the class and you give proper attribution. Do not remove any original copyright notices and headers. Late or Wrongly Submitted Assignments There are no late days in homework submission. We will accept late submissions only for medical reasons and if accompanied by a doctor's note. To submit after Canvas has closed or to ask for an extension , send an email to the Helpline with subject line \"Submit HW1: Reason=the flu\" replacing 'HW1' with the name of the current assignment and \"the flu\" with your reason. You need to attach the note from your medical provider otherwise we will not accept the request. If you forgot to join a Group with your peer and are asking for the same grade we will accept this with no penalty up to HW3. For homeworks beyond that we feel that you should be familiar with the process of joining groups. After that there will be a penalty of -1 point for both members of the group provided the submission was on time. Re-grade Requests Our graders and instructors make every effort in grading accurately and in giving you a lot of feedback. If you discover that your answer to a homework problem was correct but it was marked as incorrect, send an email to the Helpline with a description of the error. Please do not submit regrade requests based on what you perceive is overly harsh grading . The points we take off are based on a grading rubric that is being applied uniformly to all assignments. If you decide to send a regrade request , send an email to the Helpline with subject line \"Regrade HW1: Grader=johnsmith\" replacing 'HW1' with the current assignment and 'johnsmith' with the name of the grader within 48 hours of the grade release . Auditing the Class If you would like to audit the class, please send an email to the Helpline indicating who you are and why you want to audit the class. You need a HUID to be included to Canvas. Academic Integrity Ethical behavior is an important trait of a Data Scientist, from ethically handling data to attribution of code and work of others. Thus, in CS109 we give a strong emphasis to Academic Honesty. As a student your best guidelines are to be reasonable and fair. We encourage teamwork for problem sets, but you should not split the homework and you should work on all the problems together. For more detailed expectations, please refer to the Collaborations section above. Accommodations for students with disabilities Students needing academic adjustments or accommodations because of a documented disability must present their Faculty Letter from the Accessible Education Office (AEO) and speak with the professor by the end of the second week of the term, (fill in specific date). Failure to do so may result in the Course Head's inability to respond in a timely manner. All discussions will remain confidential, although Faculty are invited to contact AEO to discuss appropriate implementation. Diversity and Inclusion Statement Data Science, like many fields of science, has historically only been represented by a small sliver of the population. This is despite some of the early computer scientist pioneers being women (see Ada Lovelace and Grace Hopper for two examples). Recent initiatives have attempted to overcome some barriers to entry: Made w/ Code . We would like to attempt to discuss diversity in data science from time to time where appropriate and possible. Please contact us (in person or electronically) or submit anonymous feedback if you have any suggestions to improve the diversity of the course materials. Furthermore, we would like to create a learning environment for our students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this: If you have a name and/or set of pronouns that differ from those that appear in your official Harvard records, please let us know! If you feel like your performance in the class is being impacted by your experiences outside of class, please don't hesitate to come and talk with us. We want to be a resource for you. Remember that you can also submit anonymous feedback (which will lead to me making a general announcement to the class, if necessary to address your concerns). If you prefer to speak with someone outside of the course, you may find helpful resources at the Harvard Office of Diversity and Inclusion . We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. (Again, anonymous feedback is always an option.) As a participant in course discussions, you should also strive to honor the diversity of your classmates.","tags":"pages","url":"pages/syllabus.html"},{"title":"Lab 8: Bayesian Analysis using pyjags (+ Reinforcement Learning with gym)","text":"Lab 8 Slides PDF Notebooks Lab 8 Notebook","tags":"labs","url":"labs/lab8/"},{"title":"Lab 8: Bayesian Analysis using pyjags (+Reinforcement Learning using gym)","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 8 - Bayesian Analysis, Part 1 - JAGS (+RL setup) Harvard University Spring 2019 Instructors : Mark Glickman and Pavlos Protopapas Note that this lab has been tested with pandas version 0.22.0 rpy2 version 2.9.4 The latest libraries may have changed somewhat since these versions; if you are having problems, try using these versions. In this lab, we are working with JAGS, so make sure that it is installed on your system. In [ ]: import os os . environ [ 'R_HOME' ] = \"/usr/share/anaconda3/lib/R\" In [ ]: import pyjags import numpy as np import matplotlib.pyplot as plt % matplotlib inline import pandas as pd import rpy2 from rpy2.robjects.packages import importr #If there are errors about missing R packages, run the code below: # r_utils = importr(\"utils\") # r_utils.install_packages('coda') r_coda = importr ( \"coda\" ) from rpy2.robjects import pandas2ri pandas2ri . activate () Example 1: A Bayesian Coin Flip The idea here is to use JAGS to estimate how fair a coin is, based on 100 coin flips. In [ ]: coinflip_code = ''' model { for (i in 1:N){ x[i] ~ dbern(theta) } theta ~ dunif(0,1) } ''' In [ ]: #generate some data for our coin coinflip_N = 100 true_theta = 0.6 coinflip_x = np . random . binomial ( 1 , true_theta , coinflip_N ) In [ ]: init_theta = 0.5 #prior is that coin is fair n_chains = 3 coinflip_model = pyjags . Model ( coinflip_code , data = dict ( x = coinflip_x , N = coinflip_N ), init = dict ( theta = init_theta ), chains = n_chains ) In [ ]: coinflip_burnin = coinflip_model . sample ( 500 , vars = [ 'theta' ]) #warmup/burn-in coinflip_samples = coinflip_model . sample ( 2500 , vars = [ 'theta' ]) In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), coinflip_burnin [ 'theta' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), coinflip_burnin [ 'theta' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), coinflip_burnin [ 'theta' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"theta\" ) _ = plt . title ( \"Traceplot for coinflip data: theta\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), coinflip_samples [ 'theta' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), coinflip_samples [ 'theta' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), coinflip_samples [ 'theta' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"theta\" ) _ = plt . title ( \"Traceplot for coinflip data: theta\" ) _ = plt . legend () In [ ]: #chain 1 coinflip_chain1 = coinflip_samples [ 'theta' ][ 0 ][:, 0 ] coinflip_chain1_df = pd . DataFrame ({ 'theta' : coinflip_chain1 }) coinflip_chain1_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( coinflip_chain1_df )) #chain 2 coinflip_chain2 = coinflip_samples [ 'theta' ][ 0 ][:, 1 ] coinflip_chain2_df = pd . DataFrame ({ 'theta' : coinflip_chain2 }) coinflip_chain2_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( coinflip_chain2_df )) #chain 3 coinflip_chain3 = coinflip_samples [ 'theta' ][ 0 ][:, 2 ] coinflip_chain3_df = pd . DataFrame ({ 'theta' : coinflip_chain3 }) coinflip_chain3_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( coinflip_chain3_df )) #convert to mcmc_list object coinflip_chains = r_coda . mcmc_list ( coinflip_chain1_mcmc , coinflip_chain2_mcmc , coinflip_chain3_mcmc ) #get n_eff and Rhat coinflip_n_eff = np . round ( np . array ( r_coda . effectiveSize ( coinflip_chains ))) #round because must be an integer coinflip_rhat = np . array ( r_coda . gelman_diag ( coinflip_chains ) . rx2 ( \"psrf\" )) coinflip_rhat = coinflip_rhat [ 0 ][ 0 ] #extract point estimates #calculate summary coinflip_theta_summary = [ np . mean ( coinflip_samples [ 'theta' ]), np . std ( coinflip_samples [ 'theta' ])] for i in [ 0.025 , 0.25 , 0.5 , 0.75 , 0.975 ]: coinflip_theta_summary . append ( np . quantile ( coinflip_samples [ 'theta' ], i )) coinflip_theta_summary . append ( coinflip_n_eff [ 0 ]) coinflip_theta_summary . append ( coinflip_rhat ) coinflip_summary = pd . DataFrame ([ coinflip_theta_summary ], columns = [ \"mean\" , \"sd\" , \"2.5%\" , \"25%\" , \"50%\" , \"75%\" , \"97.5%\" , \"n_eff\" , \"Rhat\" ], index = [ \"theta\" ]) coinflip_summary . round ( 3 ) Exercise: Try running the analysis above with different values of $p$ (the probability of the coin), as well as with different values for N (number of coin flips in the data). What do you observe? In [ ]: #try it here Example 2: Mean and Standard Deviation of the Normal Given samples from a normal distribution, we want to estimate its mean and standard deviation. In [ ]: normal_code = ''' model { for (i in 1:N){ x[i] ~ dnorm(mu, tau) } mu ~ dnorm(0,.0001) tau = pow(sigma, -2) sigma ~ dunif(0,100) } ''' In [ ]: #generate some data for our normal distribution normal_N = 1000 true_mu = - 5 true_sigma = 5 normal_x = np . random . normal ( true_mu , true_sigma , 1000 ) #true data: mean = -5, standard deviation = 5 #prior is that this is a standard normal init_mu = 0 init_sigma = 1 In [ ]: normal_model = pyjags . Model ( normal_code , data = dict ( x = normal_x , N = normal_N ), init = dict ( mu = init_mu , sigma = init_sigma ), chains = 3 ) normal_burnin = normal_model . sample ( 500 , vars = [ 'mu' , 'sigma' ]) #warmup/burn-in normal_samples = normal_model . sample ( 2500 , vars = [ 'mu' , 'sigma' ]) In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), normal_burnin [ 'mu' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'mu' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'mu' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"mu\" ) _ = plt . title ( \"Traceplot for normal data: mu\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'mu' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'mu' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'mu' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"mu\" ) _ = plt . title ( \"Traceplot for normal data: mu\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), normal_burnin [ 'sigma' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'sigma' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'sigma' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"sigma\" ) _ = plt . title ( \"Traceplot for normal data: sigma\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'sigma' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'sigma' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'sigma' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"sigma\" ) _ = plt . title ( \"Traceplot for normal data: sigma\" ) _ = plt . legend () In [ ]: #chain 1 normal_chain1 = np . column_stack (( normal_samples [ 'mu' ][ 0 ][:, 0 ], normal_samples [ 'sigma' ][ 0 ][:, 0 ])) normal_chain1_df = pd . DataFrame ({ 'mu' : normal_chain1 [:, 0 ], 'sigma' : normal_chain1 [:, 1 ]}) normal_chain1_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( normal_chain1_df )) #chain 2 normal_chain2 = np . column_stack (( normal_samples [ 'mu' ][ 0 ][:, 1 ], normal_samples [ 'sigma' ][ 0 ][:, 1 ])) normal_chain2_df = pd . DataFrame ({ 'mu' : normal_chain2 [:, 0 ], 'sigma' : normal_chain2 [:, 1 ]}) normal_chain2_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( normal_chain2_df )) #chain 3 normal_chain3 = np . column_stack (( normal_samples [ 'mu' ][ 0 ][:, 2 ], normal_samples [ 'sigma' ][ 0 ][:, 2 ])) normal_chain3_df = pd . DataFrame ({ 'mu' : normal_chain3 [:, 0 ], 'sigma' : normal_chain3 [:, 1 ]}) normal_chain3_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( normal_chain3_df )) #convert to mcmc_list object normal_chains = r_coda . mcmc_list ( normal_chain1_mcmc , normal_chain2_mcmc , normal_chain3_mcmc ) #get n_eff and Rhat normal_n_eff = np . round ( np . array ( r_coda . effectiveSize ( normal_chains ))) #round because must be an integer normal_rhat = np . array ( r_coda . gelman_diag ( normal_chains ) . rx2 ( \"psrf\" )) normal_rhat = np . array ([ normal_rhat [ 0 ][ 0 ], normal_rhat [ 1 ][ 0 ]]) #extract point estimates #calculate summary normal_mu_summary = [ np . mean ( normal_samples [ 'mu' ]), np . std ( normal_samples [ 'mu' ])] normal_sigma_summary = [ np . mean ( normal_samples [ 'sigma' ]), np . std ( normal_samples [ 'sigma' ])] for i in [ 0.025 , 0.25 , 0.5 , 0.75 , 0.975 ]: normal_mu_summary . append ( np . quantile ( normal_samples [ 'mu' ], i )) normal_sigma_summary . append ( np . quantile ( normal_samples [ 'sigma' ], i )) normal_mu_summary . append ( normal_n_eff [ 0 ]) normal_mu_summary . append ( normal_rhat [ 0 ]) normal_sigma_summary . append ( normal_n_eff [ 1 ]) normal_sigma_summary . append ( normal_rhat [ 1 ]) normal_summary = pd . DataFrame ([ normal_mu_summary , normal_sigma_summary ], columns = [ \"mean\" , \"sd\" , \"2.5%\" , \"25%\" , \"50%\" , \"75%\" , \"97.5%\" , \"n_eff\" , \"Rhat\" ], index = [ \"mu\" , \"sigma\" ]) normal_summary . round ( 3 ) Exercise: Try varying the length of the burn-in period and number of iterations in the chains. What do you observe? In [ ]: #try it here Example 3: Linear Regression We will run a simple linear regression using JAGS. In [ ]: regression_code = ''' model { for (i in 1:N){ y[i] ~ dnorm(mu[i], tau) mu[i] = a + b * x[i] } a ~ dnorm(0, .0001) b ~ dnorm(0, .0001) tau = pow(sigma, -2) sigma ~ dunif(0, 100) } ''' In [ ]: regression_N = 1000 true_b = 5 true_a = 70 regression_x = np . arange ( 1 , 1001 ) regression_epsilon = np . random . normal ( true_a , 100 , 1000 ) regression_y = true_b * regression_x + regression_epsilon #prior is that y = x (i.e., a = 0, b = 1) prior_a = 0 prior_b = 1 In [ ]: regression_model = pyjags . Model ( regression_code , data = dict ( x = regression_x , y = regression_y , N = regression_N ), init = dict ( a = prior_a , b = prior_b ), chains = 3 ) regression_burnin = regression_model . sample ( 500 , vars = [ 'a' , 'b' ]) #warmup/burn-in regression_samples = regression_model . sample ( 2500 , vars = [ 'a' , 'b' ]) In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), regression_burnin [ 'a' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'a' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'a' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"a\" ) _ = plt . title ( \"Traceplot for regression data: a\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'a' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'a' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'a' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"a\" ) _ = plt . title ( \"Traceplot for regression data: a\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), regression_burnin [ 'b' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'b' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'b' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"b\" ) _ = plt . title ( \"Traceplot for regression data: b\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'b' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'b' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'b' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"b\" ) _ = plt . title ( \"Traceplot for regression data: b\" ) _ = plt . legend () In [ ]: #chain 1 regression_chain1 = np . column_stack (( regression_samples [ 'a' ][ 0 ][:, 0 ], regression_samples [ 'b' ][ 0 ][:, 0 ])) regression_chain1_df = pd . DataFrame ({ 'a' : regression_chain1 [:, 0 ], 'b' : regression_chain1 [:, 1 ]}) regression_chain1_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( regression_chain1_df )) #chain 2 regression_chain2 = np . column_stack (( regression_samples [ 'a' ][ 0 ][:, 1 ], regression_samples [ 'b' ][ 0 ][:, 1 ])) regression_chain2_df = pd . DataFrame ({ 'a' : regression_chain2 [:, 0 ], 'b' : regression_chain2 [:, 1 ]}) regression_chain2_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( regression_chain2_df )) #chain 3 regression_chain3 = np . column_stack (( regression_samples [ 'a' ][ 0 ][:, 2 ], regression_samples [ 'b' ][ 0 ][:, 2 ])) regression_chain3_df = pd . DataFrame ({ 'a' : regression_chain3 [:, 0 ], 'b' : regression_chain3 [:, 1 ]}) regression_chain3_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( regression_chain3_df )) #convert to mcmc_list object regression_chains = r_coda . mcmc_list ( regression_chain1_mcmc , regression_chain2_mcmc , regression_chain3_mcmc ) #get n_eff and Rhat regression_n_eff = np . round ( np . array ( r_coda . effectiveSize ( regression_chains ))) #round because must be an integer regression_rhat = np . array ( r_coda . gelman_diag ( regression_chains ) . rx2 ( \"psrf\" )) regression_rhat = np . array ([ regression_rhat [ 0 ][ 0 ], regression_rhat [ 1 ][ 0 ]]) #extract point estimates #calculate summary regression_a_summary = [ np . mean ( regression_samples [ 'a' ]), np . std ( regression_samples [ 'a' ])] regression_b_summary = [ np . mean ( regression_samples [ 'b' ]), np . std ( regression_samples [ 'b' ])] for i in [ 0.025 , 0.25 , 0.5 , 0.75 , 0.975 ]: regression_a_summary . append ( np . quantile ( regression_samples [ 'a' ], i )) regression_b_summary . append ( np . quantile ( regression_samples [ 'b' ], i )) regression_a_summary . append ( regression_n_eff [ 0 ]) regression_a_summary . append ( regression_rhat [ 0 ]) regression_b_summary . append ( regression_n_eff [ 1 ]) regression_b_summary . append ( regression_rhat [ 1 ]) regression_summary = pd . DataFrame ([ regression_a_summary , regression_b_summary ], columns = [ \"mean\" , \"sd\" , \"2.5%\" , \"25%\" , \"50%\" , \"75%\" , \"97.5%\" , \"n_eff\" , \"Rhat\" ], index = [ \"a\" , \"b\" ]) regression_summary . round ( 3 ) Exercise: Compare the results of performing a linear regression with this method and a non-Bayesian approach (say, using the sklearn LinearRegression function). What do you observe? In [ ]: #try it here Example 4: Reinforcement Learning with Open AI Gym In this lab we are going to work with OpenAIgym's FrozenLake environment. The details of the environment can be found in the link https://gym.openai.com/envs/FrozenLake-v0/ . Winter is here. You and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc. The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile. The surface is described using a grid like the following: [PP: WOULD IT BETTER TO INCLUDE A DIAGRAM] S: starting point, safe F: frozen surface, safe H: hole, fall to your doom G: goal, where the frisbee is located SFFF FHFH FFFH HFFG Expected actions are Left(0), Right(1), Down(2), Up(3). The episode ends when you reach the goal or fall in a hole. You receive a reward of 1 if you reach the goal, and zero otherwise. In [ ]: import gym from gym.envs.registration import register register ( id = 'FrozenLakeNotSlippery-v0' , entry_point = 'gym.envs.toy_text:FrozenLakeEnv' , kwargs = { 'map_name' : '4x4' , 'is_slippery' : False }, max_episode_steps = 100 , reward_threshold = 0.8196 , # optimum = .8196 ) In [ ]: from gym.envs.registration import register register ( id = 'FrozenLake8x8NotSlippery-v0' , entry_point = 'gym.envs.toy_text:FrozenLakeEnv' , kwargs = { 'map_name' : '8x8' , 'is_slippery' : False }, max_episode_steps = 100 , reward_threshold = 0.8196 , # optimum = .8196 ) hint: If you receive an error message while registering the above env the second time you run this cell again, ignore the error message or restart the kernel. Throughout the assignment, use only the environments we registered in the previous cells: FrozenLake8x8NotSlippery-v0 FrozenLakeNotSlippery-v0 Even though the original problem description has slippery environment, we are working in a non-slippery environment. In our environment, if you go right, you only go right whereas in the original environment, if you intend to go right, you can go right, up or down with 1/3 probability. In [ ]: import gym import numpy as np #Change environment to FrozenLake8x8 to see grid. env = gym . make ( 'FrozenLake-v0' ) # env = gym.make('FrozenLake8x8NotSlippery-v0') print ( env . observation_space . n ) #Both the grids look like as follows. ''' \"4x4\": [ \"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\" ], \"8x8\": [ \"SFFFFFFF\", \"FFFFFFFF\", \"FFFHFFFF\", \"FFFFFHFF\", \"FFFHFFFF\", \"FHHFFFHF\", \"FHFFHFHF\", \"FFFHFFFG\" ]''' #env.render() prints the frozenlake with an indicator showing where the agent is. You can use it for debugging. env . render () In [ ]: print ( env . observation_space . n ) print ( env . action_space . n ) In [ ]: Q = np . zeros ([ env . observation_space . n , env . action_space . n ]) def choose_action ( state ): return np . random . choice ( np . array ([ 0 , 1 , 2 , 3 ])) def learn ( s , s1 , r , a ): return In [ ]: # Set learning parameters ################ # num_episodes = 2000 # epsilon = 0.0 # max_steps = 100 # lr_rate = 0.0 # gamma = 0.0 # rList = [] num_episodes = 10 max_iter_per_episode = 20 for i in range ( num_episodes ): iter = 0 #Reset environment and get an initial state - should be done at start of each episode. s = env . reset () rAll = 0 d = False j = 0 while iter < max_iter_per_episode : iter += 1 #Choose an action a = choose_action ( s ) # env.step() gives you next state, reward, done(whether the episode is over) # s1 - new state, r-reward, d-whether you are done or not s1 , r , d , _ = env . step ( a ) print ( 'State : ' , s , ' Action : ' , a , ' State 1 : ' , s1 , ' Reward : ' , r , 'Done : ' , d ) learn ( s , s1 , r , a ) if d : print ( 'Episode Over' ) if r != 1 : print ( 'Fell into hole with reward ' , r ) break s = s1 if r == 1 : print ( i ) break if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab8/Bayes/"},{"title":"Lecture 14: Reinforcement Learning","text":"Slides Lecture 14 PDF Lecture 14 PPTX","tags":"lectures","url":"lectures/lecture14/"},{"title":"Lecture 13: Unsupervised Learning, Cluster Analysis","text":"Slides This lecture is only available to registered students Lecture 12-13 PDF Associated Material Lab 7 Lab 7 solutions","tags":"pages","url":"pages/lecture13/"},{"title":"Lecture 12: Unsupervised Learning, Cluster Analysis","text":"Slides This lecture is only available to registered students Lecture 12-13 PDF Associated Material Lab 7 Lab 7 solutions","tags":"pages","url":"pages/lecture12/"},{"title":"Lab 6: Recurrent Neural Networks","text":"Lab 6 Notebooks Lab6 RNNs Lab6 RNNs with solutions Installation Instructions OpenAIgym","tags":"pages","url":"pages/lab6/"},{"title":"Installation instructions","text":"Please install the OpenAIgym package on JupyterHub (similar to what you did with viz package last lab). You will need for the HW next week. pip install gym https://gym.openai.com/docs/","tags":"lab","url":"lab/lab6/inst/"},{"title":"Lab 6: Recurrent Neural Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Advanced Data Science Lab 6: Recurrent Neural Networks Harvard University Spring 2019 Lab instructor: Srivatsan Srinivasan Instructors: Pavlos Protopapas and Mark Glickman Authors: Srivatsan Srinivasan, Pavlos Protopapas In [1]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab we will look at Recurrent Neural Networks (RNNs), LSTMs and their building blocks. By the end of this lab, you should: know how to put together the building blocks used in RNNs and its variants (GRU, LSTM) in keras with an example. have a good undertanding on how sequences - any dataset that has some temporal semantics (time series, natural language, images etc.) fit into and benefit from a recurrent architecture be familiar with preprocessing text, dynamic embeddings be familiar with gradient issues on RNNs processing longer sentence lengths understand different kinds of LSTM architectures - classifier, sequence to sequence models and their far-reaching applications 1. IMDB Review Classification Battlefield - Contestants : Feedforward, CNN, RNN, LSTM In this task, we are going to do sentiment classification on a movie review dataset. We are going to build a feedforward net, a convolutional neural net, a recurrent net and combine one or more of them to understand performance of each of them. A sentence can be thought of as a sequence of words which have semantic connections across time. By semantic connection, we mean that the words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence. There are also semantic connections backwards in a sentence, in an ideal case (in which we use RNNs from both directions and combine their outputs). But for the purpose of this tutorial, we are going to restrict ourselves to only uni-directional RNNs. In [2]: import numpy from keras.datasets import imdb from keras.models import Sequential from keras.layers import Dense from keras.layers import LSTM , SimpleRNN from keras.layers.embeddings import Embedding from keras.layers import Flatten from keras.preprocessing import sequence from keras.layers.convolutional import Conv1D from keras.layers.convolutional import MaxPooling1D from keras.layers.embeddings import Embedding import numpy as np # fix random seed for reproducibility numpy . random . seed ( 1 ) Using TensorFlow backend. In [3]: # We want to have a finite vocabulary to make sure that our word matrices are not arbitrarily small vocabulary_size = 10000 #We also want to have a finite length of reviews and not have to process really long sentences. max_review_length = 500 TOKENIZATION For practical data science applications, we need to convert text into tokens since the machine understands only numbers and not really English words like humans can. As a simple example of tokenization, we can see a small example. Assume we have 5 sentences. This is how we tokenize them into numbers once we create a dictionary. i have books - [1, 4, 7] interesting books are useful [10,2,9,8] i have computers [1,4,6] computers are interesting and useful [6,9,11,10,8] books and computers are both valuable. [2,10,2,9,13,12] Bye Bye [7,7] Create tokens for vocabulary based on frequency of occurrence. Hence, we assign the following tokens I-1, books-2, computers-3, have-4, are-5, computers-6,bye-7, useful-8, are-9, and-10,interesting-11, valuable-12, both-13 Thankfully, in our dataset it is internally handled and each sentence is represented in such tokenized form. Load data In [ ]: ( X_train , y_train ), ( X_test , y_test ) = imdb . load_data ( num_words = vocabulary_size ) print ( 'Number of reviews' , len ( X_train )) print ( 'Length of first and fifth review before padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) print ( 'First review' , X_train [ 0 ]) print ( 'First label' , y_train [ 0 ]) Preprocess data Pad sequences in order to ensure that all inputs have same sentence length and dimensions. In [ ]: X_train = sequence . pad_sequences ( X_train , maxlen = max_review_length ) X_test = sequence . pad_sequences ( X_test , maxlen = max_review_length ) print ( 'Length of first and fifth review after padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) MODEL 1(a) : FEEDFORWARD NETWORKS WITHOUT EMBEDDINGS Let us build a single layer feedforward net with 250 nodes. Each input would be a 500-dim vector of tokens since we padded all our sequences to size 500. EXERCISE : Calculate the number of parameters involved in this network and implement a feedforward net to do classification without looking at cells below. In [ ]: #### YOUR CODE HERE #### Discussion : Why was the performance bad ? What was wrong with tokenization ? MODEL 1(b) : FEEDFORWARD NETWORKS WITH EMBEDDINGS What is an embedding layer ? An embedding is a linear projection from one vector space to another. We usually use embeddings to project the one-hot encodings of words on to a lower-dimensional continuous space so that the input surface is dense and possibly smooth. According to the model, an embedding layer is just a transformation from $\\mathbb{R}&#94;{inp}$ to $\\mathbb{R}&#94;{emb}$ In [ ]: embedding_dim = 100 In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) #inputs will be converted from batch_size * sentence_length to batch_size*sentence_length*embedding _dim model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) In [ ]: # Fit the model model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) MODEL 2 : CONVOLUTIONAL NEURAL NETWORKS Text can be thought of as 1-dimensional sequence and we can apply 1-D Convolutions over a set of words. Let us walk through convolutions on text data with this blog. http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/ Fit a 1D convolution with 200 filters, kernel size 3 followed by a feedforward layer of 250 nodes and ReLU, sigmoid activations as appropriate. In [ ]: #### YOUR CODE HERE #### MODEL 3 : SIMPLE RNN Two of the best blogs that help understand the workings of a RNN and LSTM are http://karpathy.github.io/2015/05/21/rnn-effectiveness/ http://colah.github.io/posts/2015-08-Understanding-LSTMs/ Mathematically speaking, a simple RNN does the following. It constructs a set of hidden states using the state variable from the previous timestep and the input at current time. Mathematically, a simpleRNN can be defined by the following relation. $h_t = \\sigma(W([h_{t-1},x_{t}])+b)$ If we extend this recurrence relation to the length of sequences we have in hand, we have our RNN network constructed. In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( SimpleRNN ( 100 )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) RNNs and vanishing/exploding gradients Let us use sigmoid activations as example. Derivative of a sigmoid can be written as $\\sigma'(x) = \\sigma(x) \\cdot \\sigma(1-x)$. Remember RNN is a \"really deep\" feedforward network (when unrolled in time). Hence, backpropagation happens from $h_t$ all the way to $h_1$. Also realize that sigmoid gradients are multiplicatively dependent on the value of sigmoid. Hence, if the non-activated output of any layer $h_l$ is < 0, then $\\sigma$ tends to 0, effectively \"vanishing\" gradient. Any layer that the current layer backprops to $H_{1:L-1}$ do not learn anything useful out of the gradients. LSTMs and GRU LSTM and GRU are two sophisticated implementations of RNN which essentially are built on what we call as gates. A gate is a probability number between 0 and 1. For instance, LSTM is built on these state updates Note : L is just a linear transformation L(x) = W*x + b. $f_t = \\sigma(L([h_{t-1},x_t))$ $i_t = \\sigma(L([h_{t-1},x_t))$ $o_t = \\sigma(L([h_{t-1},x_t))$ $\\hat{C}_t = \\tanh(L([h_{t-1},x_t))$ $C_t = f_t * C_{t-1}+i_t*\\hat{C}_t$ (Using the forget gate, the neural network can learn to control how much information it has to retain or forget) $h_t = o_t * \\tanh(c_t)$ MODEL 4 : LSTM In the next step, we will implement a LSTM model to do classification. Use the same architecture as before. Try experimenting with increasing the number of nodes, stacking multiple layers, applyong dropouts etc. Check the number of parameters that this model entails. In [ ]: #### YOUR CODE HERE #### MODEL 5 : CNN + LSTM CNNs are good at learning spatial features and sentences can be thought of as 1-D spatial vectors (dimension being connotated by the sequence ordering among the words in the sentence.). We apply a LSTM over the features learned by the CNN (after a maxpooling layer). This leverages the power of CNNs and LSTMs combined. We expect the CNN to be able to pick out invariant features across the 1-D spatial structure(i.e. sentence) that characterize good and bad sentiment. This learned spatial features may then be learned as sequences by an LSTM layer followed by a feedforward for classification. In [ ]: #### YOUR CODE HERE #### CONCLUSION We saw the power of sequence models and how they are useful in text classification. They give a solid performance, low memory footprint (thanks to shared parameters) and are able to understand and leverage the temporally connected information contained in the inputs. There is still an open debate about the performance vs memory benefits of CNNs vs RNNs in the research community. 2. 231+432 = 665.... It's not ? Let's ask our LSTM In this exercise, we are going to teach addition to our model. Given two numbers (<999), the model outputs their sum (<9999). The input is provided as a string '231+432' and the model will provide its output as ' 663' (Here the empty space is the padding character). We are not going to use any external dataset and are going to construct our own dataset for this exercise. The exercise we attempt to do effectively \"translates\" a sequence of characters '231+432' to another sequence of characters ' 663' and hence, this class of models are called sequence-to-sequence models. Such architectures have profound applications in several real-life tasks such as machine translation, summarization, image captioning etc. In [ ]: from __future__ import print_function from keras.models import Sequential from keras import layers from keras.layers import Dense , RepeatVector , TimeDistributed import numpy as np from six.moves import range The less interesting data generation and preprocessing In [ ]: class CharacterTable ( object ): def __init__ ( self , chars ): self . chars = sorted ( set ( chars )) self . char_indices = dict (( c , i ) for i , c in enumerate ( self . chars )) self . indices_char = dict (( i , c ) for i , c in enumerate ( self . chars )) #One-hot encodes def encode ( self , C , num_rows ): x = np . zeros (( num_rows , len ( self . chars ))) for i , c in enumerate ( C ): x [ i , self . char_indices [ c ]] = 1 return x #Decodes a one-hot encoding def decode ( self , x , calc_argmax = True ): if calc_argmax : x = x . argmax ( axis =- 1 ) return '' . join ( self . indices_char [ x ] for x in x ) In [ ]: TRAINING_SIZE = 50000 DIGITS = 3 MAXOUTPUTLEN = DIGITS + 1 MAXLEN = DIGITS + 1 + DIGITS chars = '0123456789+ ' ctable = CharacterTable ( chars ) In [ ]: def return_random_digit (): return np . random . choice ( list ( '0123456789' )) def generate_number (): num_digits = np . random . randint ( 1 , DIGITS + 1 ) return int ( '' . join ( return_random_digit () for i in range ( num_digits ))) def data_generate ( num_examples ): questions = [] expected = [] seen = set () print ( 'Generating data...' ) while len ( questions ) < TRAINING_SIZE : a , b = generate_number (), generate_number () #Remove already seen elements key = tuple ( sorted (( a , b ))) if key in seen : continue seen . add ( key ) # Pad the data with spaces such that it is always MAXLEN. q = ' {} + {} ' . format ( a , b ) query = q + ' ' * ( MAXLEN - len ( q )) ans = str ( a + b ) # Answers can be of maximum size DIGITS + 1. ans += ' ' * ( MAXOUTPUTLEN - len ( ans )) questions . append ( query ) expected . append ( ans ) print ( 'Total addition questions:' , len ( questions )) return questions , expected def encode_examples ( questions , answers ): x = np . zeros (( len ( questions ), MAXLEN , len ( chars )), dtype = np . bool ) y = np . zeros (( len ( questions ), DIGITS + 1 , len ( chars )), dtype = np . bool ) for i , sentence in enumerate ( questions ): x [ i ] = ctable . encode ( sentence , MAXLEN ) for i , sentence in enumerate ( answers ): y [ i ] = ctable . encode ( sentence , DIGITS + 1 ) indices = np . arange ( len ( y )) np . random . shuffle ( indices ) return x [ indices ], y [ indices ] In [ ]: q , a = data_generate ( TRAINING_SIZE ) x , y = encode_examples ( q , a ) split_at = len ( x ) - len ( x ) // 10 x_train , x_val , y_train , y_val = x [: split_at ], x [ split_at :], y [: split_at ], y [ split_at :] print ( 'Training Data shape:' ) print ( 'X : ' , x_train . shape ) print ( 'Y : ' , y_train . shape ) print ( 'Sample Question(in encoded form) : ' , x_train [ 0 ], y_train [ 0 ]) print ( 'Sample Question(in decoded form) : ' , ctable . decode ( x_train [ 0 ]), 'Sample Output : ' , ctable . decode ( y_train [ 0 ])) Let's learn two wrapper functions in Keras - TimeDistributed and RepeatVector with some dummy examples. TimeDistributed is a wrapper function call that applies an input operation on all the timesteps of an input data. For instance I have a feedforward network which converts a 10-dim vector to a 5-dim vector, then wrapping this timedistributed layer on that feedforward operation would convert a batch_size * sentence_len * vector_len(=10) to batch_size * sentence_len * output_len(=5) In [ ]: model = Sequential () #Inputs to it will be batch_size*time_steps*input_vector_dim(to Dense) . Output will be batch_size*time_steps* output_vector_dim #Here dense converts a 5-dim input vector to a 8-dim vector. model . add ( TimeDistributed ( Dense ( 8 ), input_shape = ( 3 , 5 ))) input_array = np . random . randint ( 10 , size = ( 1 , 3 , 5 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) print ( \"Shape of output : \" , output_array . shape ) RepeatVector repeats the vector a specified number of times. Dimension changes from batch_size number of elements to batch_size number of repetitions * number of elements. In [ ]: model = Sequential () #converts from 1*10 to 1 * 6 model . add ( Dense ( 6 , input_dim = 10 )) print ( model . output_shape ) #converts from 1*6 to 1*3*6 model . add ( RepeatVector ( 3 )) print ( model . output_shape ) input_array = np . random . randint ( 1000 , size = ( 1 , 10 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) print ( \"Shape of output : \" , output_array . shape ) # note: `None` is the batch dimension print ( 'Input : ' , input_array [ 0 ]) print ( 'Output : ' , output_array [ 0 ]) MODEL ARCHITECTURE Note : Whenever you are initializing a LSTM in Keras, by the default the option return_sequences = False. This means that at the end of the step the next component will only get to see the final hidden layer's values. On the other hand, if you set return_sequences = True, the LSTM component will return the hidden layer at each time step. It means that the next component should be able to consume inputs in that form. Think how this statement is relevant in terms of this model architecture and the TimeDistributed module we just learned. Build an encoder and decoder both single layer 128 nodes and an appropriate dense layer as needed by the model. In [ ]: #### YOUR CODE HERE #### Let's check how well our model trained. In [ ]: for iteration in range ( 1 , 2 ): print () model . fit ( x_train , y_train , batch_size = BATCH_SIZE , epochs = 20 , validation_data = ( x_val , y_val )) # Select 10 samples from the validation set at random so we can visualize # errors. print ( 'Finished iteration ' , iteration ) numcorrect = 0 numtotal = 20 for i in range ( numtotal ): ind = np . random . randint ( 0 , len ( x_val )) rowx , rowy = x_val [ np . array ([ ind ])], y_val [ np . array ([ ind ])] preds = model . predict_classes ( rowx , verbose = 0 ) q = ctable . decode ( rowx [ 0 ]) correct = ctable . decode ( rowy [ 0 ]) guess = ctable . decode ( preds [ 0 ], calc_argmax = False ) print ( 'Question' , q , end = ' ' ) print ( 'True' , correct , end = ' ' ) print ( 'Guess' , guess , end = ' ' ) if guess == correct : print ( 'Good job' ) numcorrect += 1 else : print ( 'Fail' ) print ( 'The model scored ' , numcorrect * 100 / numtotal , ' % i n its test.' ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab6/students/"},{"title":"Advanced Section 4: RNNs","text":"Slides PDF PPTX Lecture notes PDF","tags":"A-sections","url":"a-sections/a-section4/"},{"title":"Lecture 11: RNN-2","text":"Slides Lecture 11 PDF Lecture 11 PPTX Associated Materials Advanced Sections Advanced Section 4 PDF Labs Lab6 Notebook","tags":"lectures","url":"lectures/lecture11/"},{"title":"Lecture 10: RNN-1","text":"Slides Lecture 10 PDF Lecture 10 PPTX Associated Materials Advanced Sections Advanced Section 4 PDF Labs Lab6 Notebook","tags":"lectures","url":"lectures/lecture10/"},{"title":"Lab 5: Convolutional Neural Networks","text":"Lab 5 Notebooks Lab5 CNNs Lab5 CNNs with solutions","tags":"pages","url":"pages/lab5/"},{"title":"Lab 5: CNNs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 5: Convolutional Neural Networks Harvard University Spring 2019 Lab instructor: Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman Authors: Eleni Kaxiras, Pavlos Protopapas, Patrick Ohiomoba, and Davis Sontag In [1]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab we will look at Convolutional Neural Networks (CNNs), and their building blocks. By the end of this lab, you should: know how to put together the building blocks used in CNNs - such as convolutional layers and pooling layers - in keras with an example. have a good undertanding on how images, a common type of data for a CNN, are represented in the computer and how to think of them as arrays of numbers. be familiar with preprocessing images with keras and sckit-learn . use keras-viz to produce Saliency maps. learn best practices for configuring the hyperparameters of a CNN. run your first CNN and see the error rate. In [2]: import matplotlib.pyplot as plt plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) import numpy as np from scipy.optimize import minimize import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras.preprocessing.image import ImageDataGenerator from keras.callbacks import LearningRateScheduler from keras.callbacks import History from keras import losses from keras.datasets import mnist from keras.utils import to_categorical from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) % matplotlib inline 1.12.0 2.1.6-tf Using TensorFlow backend. Prologue: keras-viz Visualization Toolkit keras-vis is a high-level toolkit for visualizing and debugging your trained keras neural net models. Currently supported visualizations include: Activation maximization Saliency maps Class activation maps All visualizations by default support N-dimensional image inputs. i.e., it generalizes to N-dim image inputs to your model. Compatible with both theano and tensorflow backends with 'channels_first', 'channels_last' data format. Read the documentation at https://raghakot.github.io/keras-vis.https://github.com/raghakot/keras-vis To install use pip install git+https://github.com/raghakot/keras-vis.git --upgrade SEAS JupyterHub Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class (accessible from the 'Jupyter' menu link in Canvas). These are AWS p2 instances with a GPU, 10GB of disk space, and 61 GB of RAM, for faster training for your networks. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE : The AWS platform is funded by SEAS and FAS for the purposes of the class. It is not running against your individual credit. You are not allowed to use it for purposes not related to this course. Help us keep this service: Make sure you stop your instance as soon as you do not need it. Part 1: Parts of a Convolutional Neural Net There are three types of layers in a Convolutional Neural Network: Convolutional Layers Pooling Layers. Dropout Layers. Fully Connected Layers. a. Convolutional Layers. Convolutional layers are comprised of filters and feature maps . The filters are essentially the neurons of the layer. They have the weights and produce the input for the next layer. The feature map is the output of one filter applied to the previous layer. The fundamental difference between a densely connected layer and a convolution layer is that dense layers learn global patterns in their input feature space (for example, for an MNIST digit, patterns involving all pixels), whereas convolution layers learn local patterns: in the case of images, patterns found in small 2D windows of the inputs called receptive fields . This key characteristic gives convnets two interesting properties: The patterns they learn are translation invariant . After learning a certain pattern in the lower-right corner of a picture, a convnet can recognize it anywhere: for example, in the upper-left corner. A densely connected network would have to learn the pattern anew if it appeared at a new location. This makes convnets data efficient when processing images (because the visual world is fundamentally translation invariant): they need fewer training samples to learn representations that have generalization power. They can learn spatial hierarchies of patterns . A first convolution layer will learn small local patterns such as edges, a second convolution layer will learn larger patterns made of the features of the first layers, and so on. This allows convnets to efficiently learn increasingly complex and abstract visual concepts (because the visual world is fundamentally spatially hierarchical). Convolutions operate over 3D tensors, called feature maps, with two spatial axes (height and width) as well as a depth axis (also called the channels axis). For an RGB image, the dimension of the depth axis is 3, because the image has three color channels: red, green, and blue. For a black-and-white picture, like the MNIST digits, the depth is 1 (levels of gray). The convolution operation extracts patches from its input feature map and applies the same transformation to all of these patches, producing an output feature map. This output feature map is still a 3D tensor: it has a width and a height. Its depth can be arbitrary, because the output depth is a parameter of the layer, and the different channels in that depth axis no longer stand for specific colors as in RGB input; rather, they stand for filters. Filters encode specific aspects of the input data: at a high level, a single filter could encode the concept \"presence of a face in the input,\" for instance. In the MNIST example that we will see, the first convolution layer takes a feature map of size (28, 28, 1) and outputs a feature map of size (26, 26, 32): it computes 32 filters over its input. Each of these 32 output channels contains a 26×26 grid of values, which is a response map of the filter over the input, indicating the response of that filter pattern at different locations in the input. Convolutions are defined by two key parameters: Size of the patches extracted from the inputs. These are typically 3×3 or 5×5 The number of filters computed by the convolution. Padding : One of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, In keras see convolutional layers keras.layers.Conv2D (filters, kernel_size, strides=(1, 1), padding='valid', activation=None, use_bias=True, kernel_initializer='glorot_uniform', data_format='channels_last', bias_initializer='zeros') How are the values in feature maps calculated? Exercise 1: Compute the operations by hand (assuming zero padding and same arrays for all channels) to produce the first element of the 4x4 feature map. How did we get the 4x4 output size? Write this Conv layer in keras -- your answer here b. Pooling Layers. Pooling layers are also comprised of filters and feature maps. Let's say the pooling layer has a 2x2 receptive field and a stride of 2. This stride results in feature maps that are one half the size of the input feature maps. We can use a max() operation for each receptive field. In keras see pooling layers keras.layers.MaxPooling2D (pool_size=(2, 2), strides=None, padding='valid', data_format=None) c. Dropout Layers. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. In keras see Dropout layers keras.layers.Dropout(rate, seed=None) rate: float between 0 and 1. Fraction of the input units to drop. seed: A Python integer to use as random seed. References Dropout: A Simple Way to Prevent Neural Networks from Overfitting d. Fully Connected Layers. A fully connected layer flattens the square feature map into a vector. Then we can use a sigmoid or softmax activation function to output probabilities of classes. In keras see FC layers keras.layers.Dense (units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros') IT'S ALL ABOUT THE HYPERPARAMETERS! stride size of filter number of filters poolsize Part 2: Preprocessing the data Taking a look at how images are represented in a computer using a photo of a Picasso sculpture In [3]: img = plt . imread ( 'data/picasso.png' ) img . shape Out[3]: (150, 200, 4) In [4]: img [ 1 ,:, 1 ] Out[4]: array([0.5411765 , 0.5372549 , 0.53333336, 0.5372549 , 0.5372549 , 0.5372549 , 0.54509807, 0.4509804 , 0.41568628, 0.4392157 , 0.4509804 , 0.5372549 , 0.54901963, 0.54901963, 0.54509807, 0.54901963, 0.5411765 , 0.54509807, 0.54509807, 0.56078434, 0.56078434, 0.56078434, 0.5568628 , 0.56078434, 0.5647059 , 0.5647059 , 0.5647059 , 0.56078434, 0.5411765 , 0.53333336, 0.5372549 , 0.53333336, 0.5294118 , 0.53333336, 0.53333336, 0.5294118 , 0.53333336, 0.5372549 , 0.5411765 , 0.53333336, 0.5176471 , 0.5176471 , 0.5254902 , 0.5176471 , 0.50980395, 0.5176471 , 0.5294118 , 0.5254902 , 0.5254902 , 0.5176471 , 0.5176471 , 0.5254902 , 0.53333336, 0.53333336, 0.54509807, 0.5568628 , 0.56078434, 0.5686275 , 0.5764706 , 0.5686275 , 0.5686275 , 0.5764706 , 0.57254905, 0.5686275 , 0.5647059 , 0.56078434, 0.5529412 , 0.56078434, 0.5568628 , 0.5529412 , 0.5568628 , 0.56078434, 0.5568628 , 0.56078434, 0.5568628 , 0.54901963, 0.5411765 , 0.53333336, 0.5372549 , 0.5372549 , 0.53333336, 0.5294118 , 0.5372549 , 0.5411765 , 0.5411765 , 0.54509807, 0.5411765 , 0.54509807, 0.54509807, 0.53333336, 0.5294118 , 0.5294118 , 0.5294118 , 0.5294118 , 0.5411765 , 0.5372549 , 0.5411765 , 0.54901963, 0.5411765 , 0.5254902 , 0.5294118 , 0.5294118 , 0.5294118 , 0.52156866, 0.5137255 , 0.52156866, 0.5372549 , 0.5411765 , 0.5411765 , 0.5254902 , 0.52156866, 0.5294118 , 0.52156866, 0.5176471 , 0.5254902 , 0.5294118 , 0.5294118 , 0.52156866, 0.52156866, 0.5254902 , 0.5294118 , 0.53333336, 0.5294118 , 0.53333336, 0.5372549 , 0.53333336, 0.54509807, 0.54509807, 0.5411765 , 0.54901963, 0.5529412 , 0.5529412 , 0.54901963, 0.54509807, 0.5529412 , 0.54509807, 0.54901963, 0.54509807, 0.54509807, 0.54509807, 0.5411765 , 0.54509807, 0.54901963, 0.5529412 , 0.54509807, 0.54509807, 0.54901963, 0.5411765 , 0.54509807, 0.54901963, 0.54901963, 0.54901963, 0.54509807, 0.54509807, 0.54509807, 0.5372549 , 0.5411765 , 0.5411765 , 0.5372549 , 0.5372549 , 0.5372549 , 0.5372549 , 0.5411765 , 0.5294118 , 0.53333336, 0.5372549 , 0.54509807, 0.5372549 , 0.53333336, 0.5294118 , 0.52156866, 0.5254902 , 0.50980395, 0.5176471 , 0.5176471 , 0.5176471 , 0.5254902 , 0.52156866, 0.5176471 , 0.5254902 , 0.53333336, 0.53333336, 0.5176471 , 0.50980395, 0.5176471 , 0.50980395, 0.5176471 , 0.5137255 , 0.5137255 , 0.5137255 , 0.5058824 , 0.5019608 , 0.5137255 , 0.5058824 , 0.49803922, 0.5058824 , 0.48235294, 0.48235294, 0.47058824, 0.48235294], dtype=float32) In [5]: print ( type ( img [ 50 ][ 0 ][ 0 ])) In [6]: # let's see the image imgplot = plt . imshow ( img ) Visualizing the channels In [7]: R_img = img [:,:, 0 ] G_img = img [:,:, 1 ] B_img = img [:,:, 2 ] plt . subplot ( 221 ) plt . imshow ( R_img , cmap = plt . cm . Reds ) plt . subplot ( 222 ) plt . imshow ( G_img , cmap = plt . cm . Greens ) plt . subplot ( 223 ) plt . imshow ( B_img , cmap = plt . cm . Blues ) plt . subplot ( 224 ) plt . imshow ( img ) plt . show () More on preprocessing data below! If you want to learn more: Image Processing with Python and Scipy Part 3: Putting the Parts together to make a small ConvNet Model Let's put all the parts together to make a convnet for classifying our good old MNIST digits. In [8]: # Load data and preprocess ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # load MNIST data train_images . shape Out[8]: (60000, 28, 28) In [9]: train_images . max (), train_images . min () Out[9]: (255, 0) In [10]: train_images = train_images . reshape (( 60000 , 28 , 28 , 1 )) # Reshape to get third dimension train_images = train_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 test_images = test_images . reshape (( 10000 , 28 , 28 , 1 )) # Reshape to get third dimension test_images = test_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 # Convert labels to categorical data train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) In [11]: mnist_cnn_model = models . Sequential () # Create sequential model # Add network layers mnist_cnn_model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 28 , 28 , 1 ))) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely connected classifier network like those you're already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers on top. In [12]: mnist_cnn_model . add ( layers . Flatten ()) mnist_cnn_model . add ( layers . Dense ( 64 , activation = 'relu' )) mnist_cnn_model . add ( layers . Dense ( 10 , activation = 'softmax' )) mnist_cnn_model . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 3, 3, 64) 36928 _________________________________________________________________ flatten_1 (Flatten) (None, 576) 0 _________________________________________________________________ dense_1 (Dense) (None, 64) 36928 _________________________________________________________________ dense_2 (Dense) (None, 10) 650 ================================================================= Total params: 93,322 Trainable params: 93,322 Non-trainable params: 0 _________________________________________________________________ In [13]: # Compile model mnist_cnn_model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # Fit the model mnist_cnn_model . fit ( train_images , train_labels , epochs = 5 , batch_size = 64 ) # Evaluate the model on the test data: test_loss , test_acc = mnist_cnn_model . evaluate ( test_images , test_labels ) test_acc Epoch 1/5 60000/60000 [==============================] - 21s 343us/step - loss: 0.1780 - acc: 0.9456 Epoch 2/5 60000/60000 [==============================] - 21s 352us/step - loss: 0.0479 - acc: 0.9854 Epoch 3/5 60000/60000 [==============================] - 25s 419us/step - loss: 0.0341 - acc: 0.9896 Epoch 4/5 60000/60000 [==============================] - 21s 349us/step - loss: 0.0254 - acc: 0.9922 Epoch 5/5 60000/60000 [==============================] - 21s 347us/step - loss: 0.0200 - acc: 0.9941 10000/10000 [==============================] - 1s 124us/step Out[13]: 0.9902 A densely connected network (MLP) running MNIST usually has a test accuracy of 97.8%, whereas our basic convnet has a test accuracy of 99.03%: we decreased the error rate by 68% (relative) with only 5 epochs. Not bad! But why does this simple convnet work so well, compared to a densely connected model? The answer is above on how convolutional layers work! Data Preprocessing : Meet the ImageDataGenerator class in keras (docs) The MNIST and other pre-loaded dataset are formatted in a way that is almost ready for feeding into the model. What about plain images? They should be formatted into appropriately preprocessed floating-point tensors before being fed into the network. The Dogs vs. Cats dataset that you'll use isn't packaged with Keras. It was made available by Kaggle as part of a computer-vision competition in late 2013, back when convnets weren't mainstream. The data has been downloaded for you from https://www.kaggle.com/c/dogs-vs-cats/data The pictures are medium-resolution color JPEGs. In [14]: # TODO: set your base dir to your correct local location base_dir = 'data/cats_and_dogs_small' import os , shutil # Set up directory information train_dir = os . path . join ( base_dir , 'train' ) validation_dir = os . path . join ( base_dir , 'validation' ) test_dir = os . path . join ( base_dir , 'test' ) train_cats_dir = os . path . join ( train_dir , 'cats' ) train_dogs_dir = os . path . join ( train_dir , 'dogs' ) validation_cats_dir = os . path . join ( validation_dir , 'cats' ) validation_dogs_dir = os . path . join ( validation_dir , 'dogs' ) test_cats_dir = os . path . join ( test_dir , 'cats' ) test_dogs_dir = os . path . join ( test_dir , 'dogs' ) print ( 'total training cat images:' , len ( os . listdir ( train_cats_dir ))) print ( 'total training dog images:' , len ( os . listdir ( train_dogs_dir ))) print ( 'total validation cat images:' , len ( os . listdir ( validation_cats_dir ))) print ( 'total validation dog images:' , len ( os . listdir ( validation_dogs_dir ))) print ( 'total test cat images:' , len ( os . listdir ( test_cats_dir ))) print ( 'total test dog images:' , len ( os . listdir ( test_dogs_dir ))) total training cat images: 1000 total training dog images: 1000 total validation cat images: 500 total validation dog images: 500 total test cat images: 500 total test dog images: 500 So you do indeed have 2,000 training images, 1,000 validation images, and 1,000 test images. Each split contains the same number of samples from each class: this is a balanced binary-classification problem, which means classification accuracy will be an appropriate measure of success. Building the network In [15]: from keras import layers from keras import models model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_4 (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_5 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_6 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_5 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_7 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_6 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ flatten_2 (Flatten) (None, 6272) 0 _________________________________________________________________ dense_3 (Dense) (None, 512) 3211776 _________________________________________________________________ dense_4 (Dense) (None, 1) 513 ================================================================= Total params: 3,453,121 Trainable params: 3,453,121 Non-trainable params: 0 _________________________________________________________________ For the compilation step, you'll go with the RMSprop optimizer. Because you ended the network with a single sigmoid unit, you'll use binary crossentropy as the loss. In [16]: from keras import optimizers model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) The steps for getting it into the network are roughly as follows: Read the picture files. Decode the JPEG content to RGB grids of pixels. Convert these into floating-point tensors. Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values). It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically with the class ImageDataGenerator , which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors. This is what you'll use here. In [17]: from keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator ( rescale = 1. / 255 ) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) Found 2000 images belonging to 2 classes. Found 1000 images belonging to 2 classes. Let's look at the output of one of these generators: it yields batches of 150×150 RGB images (shape (20, 150, 150, 3)) and binary labels (shape (20,)). There are 20 samples in each batch (the batch size). Note that the generator yields these batches indefinitely: it loops endlessly over the images in the target folder. For this reason, you need to break the iteration loop at some point: In [18]: for data_batch , labels_batch in train_generator : print ( 'data batch shape:' , data_batch . shape ) print ( 'labels batch shape:' , labels_batch . shape ) break data batch shape: (20, 150, 150, 3) labels batch shape: (20,) Let's fit the model to the data using the generator. You do so using the .fit_generator method, the equivalent of .fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely, like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring an epoch over. This is the role of the steps_per_epoch argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps - the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples. When using fit_generator, you can pass a validation_data argument, much as with the fit method. It's important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation In [19]: history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 30 validation_data = validation_generator , validation_steps = 50 ) # It's good practice to always save your models after training. model . save ( 'cats_and_dogs_small_1.h5' ) Epoch 1/5 100/100 [==============================] - 55s 549ms/step - loss: 0.6885 - acc: 0.5320 - val_loss: 0.6711 - val_acc: 0.6220 Epoch 2/5 100/100 [==============================] - 56s 558ms/step - loss: 0.6620 - acc: 0.5950 - val_loss: 0.6500 - val_acc: 0.6170 Epoch 3/5 100/100 [==============================] - 56s 562ms/step - loss: 0.6198 - acc: 0.6510 - val_loss: 0.6771 - val_acc: 0.5790 Epoch 4/5 100/100 [==============================] - 57s 567ms/step - loss: 0.5733 - acc: 0.6955 - val_loss: 0.5993 - val_acc: 0.6740 Epoch 5/5 100/100 [==============================] - 57s 566ms/step - loss: 0.5350 - acc: 0.7305 - val_loss: 0.6140 - val_acc: 0.6520 Let's plot the loss and accuracy of the model over the training and validation data during training: In [20]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Let's try data augmentation In [21]: datagen = ImageDataGenerator ( rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True , fill_mode = 'nearest' ) These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over this code: rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures. width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally. shear_range is for randomly applying shearing transformations. zoom_range is for randomly zooming inside pictures. horizontal_flip is for randomly flipping half the images horizontally—relevant when there are no assumptions of - horizontal asymmetry (for example, real-world pictures). fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift. Let's look at the augmented images In [22]: from keras.preprocessing import image fnames = [ os . path . join ( train_dogs_dir , fname ) for fname in os . listdir ( train_dogs_dir )] img_path = fnames [ 3 ] # Chooses one image to augment img = image . load_img ( img_path , target_size = ( 150 , 150 )) # Reads the image and resizes it x = image . img_to_array ( img ) # Converts it to a Numpy array with shape (150, 150, 3) x = x . reshape (( 1 ,) + x . shape ) # Reshapes it to (1, 150, 150, 3) i = 0 for batch in datagen . flow ( x , batch_size = 1 ): plt . figure ( i ) imgplot = plt . imshow ( image . array_to_img ( batch [ 0 ])) i += 1 if i % 4 == 0 : break plt . show () If you train a new network using this data-augmentation configuration, the network will never see the same input twice. But the inputs it sees are still heavily intercorrelated, because they come from a small number of original images—you can't produce new information, you can only remix existing information. As such, this may not be enough to completely get rid of overfitting. To further fight overfitting, you'll also add a Dropout layer to your model right before the densely connected classifier. In [23]: model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) In [24]: # Let's train the network using data augmentation and dropout. train_datagen = ImageDataGenerator ( rescale = 1. / 255 , rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ,) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) # Note that the validation data shouldn't be augmented! train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 100 validation_data = validation_generator , validation_steps = 50 ) model . save ( 'cats_and_dogs_small_2.h5' ) Found 2000 images belonging to 2 classes. Found 1000 images belonging to 2 classes. Epoch 1/5 100/100 [==============================] - 94s 935ms/step - loss: 0.6902 - acc: 0.5294 - val_loss: 0.7003 - val_acc: 0.4924 Epoch 2/5 100/100 [==============================] - 88s 882ms/step - loss: 0.6763 - acc: 0.5703 - val_loss: 0.7350 - val_acc: 0.5090 Epoch 3/5 100/100 [==============================] - 90s 899ms/step - loss: 0.6681 - acc: 0.5816 - val_loss: 0.6458 - val_acc: 0.6098 Epoch 4/5 100/100 [==============================] - 88s 877ms/step - loss: 0.6496 - acc: 0.6241 - val_loss: 0.6431 - val_acc: 0.6192 Epoch 5/5 100/100 [==============================] - 89s 886ms/step - loss: 0.6298 - acc: 0.6369 - val_loss: 0.5897 - val_acc: 0.6580 And let's plot the results again. Thanks to data augmentation and dropout, you're no longer overfitting: the training curves are closely tracking the validation curves. You now reach an accuracy of 82%, a 15% relative improvement over the non-regularized model. (Note: these numbers are for 100 epochs..) In [25]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) By using regularization techniques even further, and by tuning the network's parameters (such as the number of filters per convolution layer, or the number of layers in the network), you may be able to get an even better accuracy, likely up to 86% or 87%. But it would prove difficult to go any higher just by training your own convnet from scratch, because you have so little data to work with. As a next step to improve your accuracy on this problem, you'll have to use a pretrained model. Part 4: keras viz toolkit https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb In [10]: class_idx = 0 indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] # pick some random input from here. idx = indices [ 0 ] # Lets sanity check the picked image. from matplotlib import pyplot as plt % matplotlib inline plt . rcParams [ 'figure.figsize' ] = ( 18 , 6 ) plt . imshow ( test_images [ idx ][ ... , 0 ]) Out[10]: In [11]: input_shape = ( 28 , 28 , 1 ) num_classes = 10 batch_size = 128 epochs = 5 model = Sequential () model . add ( layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ), activation = 'relu' , input_shape = input_shape )) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D ( pool_size = ( 2 , 2 ))) model . add ( layers . Dropout ( 0.25 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 128 , activation = 'relu' )) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( num_classes , activation = 'softmax' , name = 'preds' )) model . compile ( loss = keras . losses . categorical_crossentropy , optimizer = keras . optimizers . Adam (), metrics = [ 'accuracy' ]) model . fit ( train_images , train_labels , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( test_images , test_labels )) score = model . evaluate ( test_images , test_labels , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 81s 1ms/step - loss: 0.2462 - acc: 0.9248 - val_loss: 0.0524 - val_acc: 0.9828 Epoch 2/5 60000/60000 [==============================] - 86s 1ms/step - loss: 0.0905 - acc: 0.9726 - val_loss: 0.0391 - val_acc: 0.9857 Epoch 3/5 60000/60000 [==============================] - 83s 1ms/step - loss: 0.0691 - acc: 0.9788 - val_loss: 0.0376 - val_acc: 0.9876 Epoch 4/5 60000/60000 [==============================] - 81s 1ms/step - loss: 0.0544 - acc: 0.9832 - val_loss: 0.0307 - val_acc: 0.9896 Epoch 5/5 60000/60000 [==============================] - 84s 1ms/step - loss: 0.0467 - acc: 0.9854 - val_loss: 0.0305 - val_acc: 0.9904 Test loss: 0.030515316201592212 Test accuracy: 0.9904 In [12]: from vis.visualization import visualize_saliency from vis.utils import utils from keras import activations # Utility to search for layer index by name. # Alternatively we can specify this as -1 since it corresponds to the last layer. layer_idx = utils . find_layer_idx ( model , 'preds' ) In [13]: plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) from vis.visualization import visualize_cam import warnings warnings . filterwarnings ( 'ignore' ) # This corresponds to the Dense linear layer. for class_idx in np . arange ( 10 ): indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] idx = indices [ 0 ] f , ax = plt . subplots ( 1 , 4 ) ax [ 0 ] . imshow ( test_images [ idx ][ ... , 0 ]) for i , modifier in enumerate ([ None , 'guided' , 'relu' ]): grads = visualize_cam ( model , layer_idx , filter_indices = class_idx , seed_input = test_images [ idx ], backprop_modifier = modifier ) if modifier is None : modifier = 'vanilla' ax [ i + 1 ] . set_title ( modifier ) ax [ i + 1 ] . imshow ( grads , cmap = 'jet' ) References and Acknowledgements The cats and dogs part of this lab is based on the book Deep Learning with Python, Chapter 5 written by the Francois Chollet, the author of Keras. It is a very practical introduction to Deep Learning. It is appropriate for those with some Python knowledge who want to start with machine learning. The saliency maps are from https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab5/solutions/"},{"title":"Advanced Section 3: CNNs and Object Detection","text":"Slides PDF Lecture notes on ConvNets and architectures PDF External resources on object recognition What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)? What do we learn from single shot object detectors (SSD, YOLOv3), FPN & Focal loss (RetinaNet)? Image segmentation with Mask R-CNN Face recognition references FaceNet: A Unified Embedding for Face Recognition and Clustering DeepFace: Face Generation using Deep Learning Deep Face Recognition: A Survey","tags":"A-sections","url":"a-sections/a-section3/"},{"title":"Lecture 9: CNN-2","text":"Slides Lecture 9 PDF Lecture 9 PPTX Associated Materials Advanced Sections Advanced Section 3 PDF Labs Lab5 Notebook with Solutions","tags":"lectures","url":"lectures/lecture9/"},{"title":"Lecture 9 Notebook","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lecture 9: NLP example with CNN Harvard University Spring 2019 Instructors: Pavlos Protopapas and Mark Glickman In [1]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In this example, we will try to implement a CNN for text. We will use the task of IMDB movie review classification. Response variable is positive/negative review. A sentence can be thought of as a sequence of words which have semantic connections across time. By semantic connection, we mean that the words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence. Note: There are also semantic connections backwards in a sentence (we will revisit this idea when we do RNNs from both directions and combine their outputs which we will see in the next few lectures). In [30]: import numpy from keras.datasets import imdb from keras.models import Sequential from keras.layers import Dense from keras.layers import LSTM , SimpleRNN from keras.layers.embeddings import Embedding from keras.layers import Flatten from keras.preprocessing import sequence from keras.layers.convolutional import Conv1D from keras.layers.convolutional import MaxPooling1D from keras.layers.embeddings import Embedding import numpy as np # fix random seed for reproducibility numpy . random . seed ( 1 ) SEEDING - Important thing to do in many machine learning tasks which involve stochastic sampling (where random numbers are generated for different samples) is to do seeding so that the results are fairly reproducible. WHY SEEDING ? Most random number generators in computers are pseudo-random number generators i.e. they generate random numbers starting from a seed, but internally have a deterministic formula to calculate the next random number it generates and thus, if you fix your seed, the set of random numbers produced are the same in every run. STEP 1 : Load and visualize the data In [43]: # We want to have a finite vocabulary (9,999 most frequent words, one for everything else) vocabulary_size = 10000 #We also want to have a finite length of reviews and not have to process really long sentences. # Anything longer will be chopped! max_review_length = 500 For practical data science applications, we need to convert text into tokens since the machine understands only numbers and not really English words like humans can. As a simple example of tokenization, we can see a small example. Assume we have 5 sentences. This is how we tokenize them into numbers once we create a dictionary. I have books - [1, 4, 7] Interesting books are useful [10,2,9,8] I have computers [1,4,6] Computers are interesting and useful [6,9,11,10,8] Books and computers are both valuable. [7,10,2,9,13,12] Create tokens for vocabulary based on frequency of occurrence. Hence, we assign the following tokens I-1, books-2, computers-3, have-4, are-5, computers-6,books-7, useful-8, are-9, and-10,interesting-11, valuable-12, both-13 Thankfully, in our dataset it is internally handled and each sentence is represented in such tokenized form. In [32]: ( X_train , y_train ), ( X_test , y_test ) = imdb . load_data ( num_words = vocabulary_size ) In [33]: print ( 'Number of reviews' , len ( X_train )) print ( 'Length of first and fifth review before padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) print ( 'First review' , X_train [ 0 ]) print ( 'First label' , y_train [ 0 ]) Number of reviews 25000 Length of first and fifth review before padding 218 147 First review [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] First label 1 Pad sequences in order to ensure that all inputs have same sentence length and dimensions. DISCUSSION : Why are we padding here? In [34]: X_train = sequence . pad_sequences ( X_train , maxlen = max_review_length ) X_test = sequence . pad_sequences ( X_test , maxlen = max_review_length ) print ( 'Length of first and fifth review after padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) Length of first and fifth review after padding 500 500 Is Accuracy the right metric to look at ? Discuss : In what cases is accuracy a good metric to measure classification models ? What other metrics are useful incase accuracy proves to be incompetent metric for our dataset ? https://towardsdatascience.com/understanding-data-science-classification-metrics-in-scikit-learn-in-python-3bc336865019 In [35]: from collections import Counter counts = dict ( Counter ( y_train )) print ( 'Number of zeroes : ' , counts [ 0 ], ' and Number of ones : ' , counts [ 1 ]) Number of zeroes : 12500 and Number of ones : 12500 MODEL 1(a) : FEEDFORWARD NETWORKS WITHOUT EMBEDDINGS Let us build a single layer feedforward net with 250 nodes. GOAL : Calculate the number of parameters involved in this network and implement a feedforward net to do classification. In [36]: model = Sequential () model . add ( Dense ( 250 , activation = 'relu' , input_dim = max_review_length )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 3 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_16 (Dense) (None, 250) 125250 _________________________________________________________________ dense_17 (Dense) (None, 1) 251 ================================================================= Total params: 125,501 Trainable params: 125,501 Non-trainable params: 0 _________________________________________________________________ None Train on 25000 samples, validate on 25000 samples Epoch 1/3 - 1s - loss: 8.0534 - acc: 0.4990 - val_loss: 7.9612 - val_acc: 0.5053 Epoch 2/3 - 1s - loss: 8.0372 - acc: 0.5012 - val_loss: 8.0608 - val_acc: 0.4998 Epoch 3/3 - 1s - loss: 8.0574 - acc: 0.5001 - val_loss: 8.0603 - val_acc: 0.4999 Accuracy: 49.99% Any idea why the performance is terrible ? Hint : Tokenization. Obvious Workaround : One-Hot Encodings EMBEDDINGS - Sparse to Dense Transformations We use embeddings to reduce dimensions of our data since the tokens we assign based on our word frequency are discrete and do not have a continuous structure. What are embeddings ? Embeddings are functional transformations from a sparse discrete vector representation of text (either as tokens or as one-hot encodings) into a dense vector representation of a fixed size(usually of much lower dimensions than the vocabulary length of the text). The dense representations allow the neural network to generalize better. Here we are training our own embedding while training our neural network. To transfer \"knowledge\" from other sources, in more complicated projects we can also use pre-trained embeddings such as word-2-vec, GloVE, Fastext etc. https://nlpforhackers.io/word-embeddings/ Example Embeddings Transformation Let us first understand how Keras embedding layer works through a dummy example to see how the dimensions are transformed. In this example, each input is mapped to a 64 dimensional vector (via the embedding layer). EXERCISE : Manually calculate the number of parameters needed in the embedding layer before executing the code. In [37]: model = Sequential () #input - Number of categorical inputs, embedding dimension, input length. model . add ( Embedding ( 1000 , 64 , input_length = 10 )) print ( model . summary ()) # the model will take as input an integer matrix of size (batch, input_length). # the largest integer (i.e. word index) in the input should be # no larger than 999 (vocabulary size). # now model.output_shape == (None, 10, 64), where None is the batch dimension. input_array = np . random . randint ( 1000 , size = ( 32 , 10 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) assert output_array . shape == ( 32 , 10 , 64 ) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_8 (Embedding) (None, 10, 64) 64000 ================================================================= Total params: 64,000 Trainable params: 64,000 Non-trainable params: 0 _________________________________________________________________ None Shape of input : (32, 10) In [44]: print ( input_array [ 0 ]) print ( output_array [ 0 ] . shape ) [905 644 12 451 965 181 64 621 703 214] (10, 64) MODEL 1(b) : FEEDFORWARD NETWORKS WITH EMBEDDINGS EXERCISE : Implement the feedforward net combining the embedding layer and the feedforward layer(one layer, 250 nodes) without looking at cells below. Manually calculate the number of parameters needed in the feedforward network before executing the code. In [39]: embedding_dim = 100 In [40]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_9 (Embedding) (None, 500, 100) 1000000 _________________________________________________________________ flatten_4 (Flatten) (None, 50000) 0 _________________________________________________________________ dense_18 (Dense) (None, 250) 12500250 _________________________________________________________________ dense_19 (Dense) (None, 1) 251 ================================================================= Total params: 13,500,501 Trainable params: 13,500,501 Non-trainable params: 0 _________________________________________________________________ None In [41]: # Fit the model model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) Train on 25000 samples, validate on 25000 samples Epoch 1/2 - 89s - loss: 0.5811 - acc: 0.6663 - val_loss: 0.3381 - val_acc: 0.8514 Epoch 2/2 - 84s - loss: 0.2002 - acc: 0.9222 - val_loss: 0.3017 - val_acc: 0.8726 Accuracy: 87.26% MODEL 2 : Convolutional Nets Text can be thought of as 1-dimensional sequence and we can apply 1-D Convolutions over a set of words. Let us walk through convolutions on text data with this blog. http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/ EXERCISE : Manually calculate the number of parameters needed in the feedforward network before executing the code. In [20]: # create the model model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( Conv1D ( filters = embedding_dim , kernel_size = 3 , padding = 'same' , activation = 'relu' )) model . add ( MaxPooling1D ( pool_size = 2 )) model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_4 (Embedding) (None, 500, 100) 1000000 _________________________________________________________________ conv1d_1 (Conv1D) (None, 500, 100) 30100 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 250, 100) 0 _________________________________________________________________ flatten_2 (Flatten) (None, 25000) 0 _________________________________________________________________ dense_11 (Dense) (None, 250) 6250250 _________________________________________________________________ dense_12 (Dense) (None, 1) 251 ================================================================= Total params: 7,280,601 Trainable params: 7,280,601 Non-trainable params: 0 _________________________________________________________________ None In [21]: # Fit the model model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) Train on 25000 samples, validate on 25000 samples Epoch 1/2 - 314s - loss: 0.4952 - acc: 0.7055 - val_loss: 0.2996 - val_acc: 0.8768 Epoch 2/2 - 147s - loss: 0.2043 - acc: 0.9216 - val_loss: 0.2849 - val_acc: 0.8819 Accuracy: 88.19% EXERCISE Try other CNNs with Different kernel sizes Different pooling operations(AveragePooling1D) DISCUSSION : What does max and average pooling mean in terms of processing text sequences ? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"lectures","url":"lectures/lecture9/notebook/"},{"title":"Lecture 8: CNN-1","text":"Slides Lecture 8 PDF Lecture 8 PPTX Associated Materials Advanced Sections Advanced Section 3 PDF Labs Lab5 Notebook with Solutions","tags":"lectures","url":"lectures/lecture8/"},{"title":"Lecture 7: Scaling","text":"Slides Lecture 7 PDF Associated Materials Labs","tags":"lectures","url":"lectures/lecture7/"},{"title":"Advanced Section 2: Optimal Transport","text":"Slides PDF Lecture Notes PDF Intro to optimization notes PDF References for further reading Computation optimal transport Learning with a Wasserstein Loss Optimal Transport for Domain Adaptation","tags":"A-sections","url":"a-sections/a-section2/"},{"title":"Lab 3: Optimization of Neural Networks","text":"Lab 3 Notebooks Lab3 Optimization in NNs Lab3 Optimization with solutions","tags":"lab","url":"lab/lab3/"},{"title":"Lab 3: Optimization of Neural Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 3: Optimization in Artificial Neural Networks Harvard University Spring 2019 Lab instructor : Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab, we'll explore ways to optimize the loss function of a Multilayer Learning Perceptor (MLP) by tuning the model hyperparameters. We'll also explore the use of cross-validation as a technique for checking potential values for these hyperparameters. By the end of this lab, you should: Be familiar with the use of sklearn 's optimize function. Be able to identify the hyperparameters that go into the training of a MLP. Be familiar with the implementation in keras of various optimization techniques. Know how to use callbacks Apply cross-validation to check for multiple values of hyperparameters. In [2]: import matplotlib.pyplot as plt import numpy as np from scipy.optimize import minimize % matplotlib inline Part 1: Beale's function First let's look at function optimization in scipy.optimize , using Beale's function as an example Optimizing a function $f: A\\rightarrow R$, from some set A to the real numbers is finding an element $x_0\\,\\epsilon\\, A$ such that $f(x_0)\\leq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the minimum) or such that $f(x_0)\\geq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the maximum). To illustrate our point we will use a function of two parameters. Our goal is to optimize over these 2 parameters. We can extend to higher dimensions by plotting pairs of parameters against each other. The Wikipedia article on Test functions for optimization has a few functions that are useful for evaluating optimization algorithms. Here is Beale's function: $f(x,y)$ = $(1.5−x+xy)&#94;2+(2.25−x+xy&#94;2)&#94;2+(2.625−x+xy&#94;3)&#94;2$ We already know that this function has a minimum at [3.0, 0.5]. Let's see if scipy will find it. source: https://en.wikipedia.org/wiki/Test_functions_for_optimization In [3]: # define Beale's function which we want to minimize def objective ( X ): x = X [ 0 ]; y = X [ 1 ] return ( 1.5 - x + x * y ) ** 2 + ( 2.25 - x + x * y ** 2 ) ** 2 + ( 2.625 - x + x * y ** 3 ) ** 2 In [4]: # function boundaries xmin , xmax , xstep = - 4.5 , 4.5 , . 9 ymin , ymax , ystep = - 4.5 , 4.5 , . 9 In [5]: # Let's create some points x1 , y1 = np . meshgrid ( np . arange ( xmin , xmax + xstep , xstep ), np . arange ( ymin , ymax + ystep , ystep )) Let's make an initial guess In [6]: # initial guess x0 = [ 4. , 4. ] f0 = objective ( x0 ) print ( f0 ) 68891.203125 In [7]: bnds = (( xmin , xmax ), ( ymin , ymax )) minimum = minimize ( objective , x0 , bounds = bnds ) In [8]: print ( minimum ) fun: 2.068025638865627e-12 hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64> jac: array([-1.55969780e-06, 9.89837957e-06]) message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL' nfev: 60 nit: 14 status: 0 success: True x: array([3.00000257, 0.50000085]) In [9]: real_min = [ 3.0 , 0.5 ] print ( f 'The answer, {minimum.x} , is very close to the optimum as we know it, which is {real_min} ' ) print ( f 'The value of the objective for {real_min} is {objective(real_min)}' ) The answer, [3.00000257 0.50000085], is very close to the optimum as we know it, which is [3.0, 0.5] The value of the objective for [3.0, 0.5] is 0.0 Part 2: Optimization in neural networks In general: Learning Representation --> Objective function --> Optimization algorithm A neural network can be defined as a framework that combines inputs and tries to guess the output. If we are lucky enough to have some results, called \"the ground truth\", to compare the outputs produced by the network, we can calculate the error . So the network guesses, calculates some error function, guesses again, trying to minimize this error, guesses again, until the error does not go down any more. This is optimization. In neural networks the most common used optimization algorithms, are flavors of GD (gradient descent) . The objective function used in gradient descent is the loss function which we want to minimize . A keras Refresher Keras is a Python library for deep learning that can run on top of both Theano or TensorFlow, two powerful Python libraries for fast numerical computing created and released by Facebook and Google, respectevely. Keras was developed to make developing deep learning models as fast and easy as possible for research and practical applications. It runs on Python 2.7 or 3.5 and can seamlessly execute on GPUs and CPUs. Keras is built on the idea of a model. At its core we have a sequence of layers called the Sequential model which is a linear stack of layers. Keras also provides the functional API , a way to define complex models, such as multi-output models, directed acyclic graphs, or models with shared layers. We can summarize the construction of deep learning models in Keras using the Sequential model as follows: Define your model : create a Sequential model and add layers. Compile your model : specify loss function and optimizers and call the .compile() function. Fit your model : train the model on data by calling the .fit() function. Make predictions : use the model to generate predictions on new data by calling functions such as .evaluate() or .predict() . Callbacks: taking a peek into our model while it's training You can look at what is happening in various stages of your model by using callbacks . A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training. A callback function you are already familiar with is keras.callbacks.History() . This is automatically included in .fit() . Another very useful one is keras.callbacks.ModelCheckpoint which saves the model with its weights at a certain point in the training. This can prove useful if your model is running for a long time and a system failure happens. Not all is lost then. It's a good practice to save the model weights only when an improvement is observed as measured by the acc , for example. keras.callbacks.EarlyStopping stops the training when a monitored quantity has stopped improving. keras.callbacks.LearningRateScheduler will change the learning rate during training. We will apply some callbacks later. For full documentation on callbacks see https://keras.io/callbacks/ What are the steps to optimizing our network? In [10]: import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras.callbacks import LearningRateScheduler from keras.callbacks import History from keras import losses from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) 1.12.0 2.1.6-tf Using TensorFlow backend. In [11]: # fix random seed for reproducibility np . random . seed ( 5 ) Step 1 - Deciding on the network topology (not really considered optimization but is obviously very important) We will use the MNIST dataset which consists of grayscale images of handwritten digits (0-9) whose dimension is 28x28 pixels. Each pixel is 8 bits so its value ranges from 0 to 255. In [12]: #mnist = tf.keras.datasets.mnist mnist = keras . datasets . mnist ( x_train , y_train ),( x_test , y_test ) = mnist . load_data () x_train . shape , y_train . shape Out[12]: ((60000, 28, 28), (60000,)) Each label is a number between 0 and 9 In [13]: print ( y_train ) [5 0 4 ... 5 6 8] Let's look at some 10 of the images In [14]: plt . figure ( figsize = ( 10 , 10 )) for i in range ( 10 ): plt . subplot ( 5 , 5 , i + 1 ) plt . xticks ([]) plt . yticks ([]) plt . grid ( False ) plt . imshow ( x_train [ i ], cmap = plt . cm . binary ) plt . xlabel ( y_train [ i ]) In [15]: x_train [ 45 ] . shape x_train [ 45 , 15 : 20 , 15 : 20 ] Out[15]: array([[ 11, 198, 231, 41, 0], [ 82, 252, 204, 0, 0], [253, 253, 141, 0, 0], [252, 220, 36, 0, 0], [252, 96, 0, 0, 0]], dtype=uint8) In [17]: print ( f 'We have {x_train.shape[0]} train samples' ) print ( f 'We have {x_test.shape[0]} test samples' ) We have 60000 train samples We have 10000 test samples Preprocessing the data To run our NN we need to pre-process the data First we need to make the 2D image arrays into 1D (flatten them). We can either perform this by using array reshaping with numpy.reshape() or the keras ' method for this: a layer called tf.keras.layers.Flatten which transforms the format of the images from a 2d-array (of 28 by 28 pixels), to a 1D-array of 28 * 28 = 784 pixels. Then we need to normalize the pixel values (give them values between 0 and 1) using the following transformation: \\begin{align} x := \\dfrac{x - x_{min}}{x_{max} - x_{min}} \\textrm{} \\end{align} In our case $x_{min} = 0$ and $x_{max} = 255$ so the formula becomes simply $x := {x}/255$ In [18]: # normalize the data x_train , x_test = x_train / 255.0 , x_test / 255.0 In [19]: # reshape the data into 1D vectors x_train = x_train . reshape ( 60000 , 784 ) x_test = x_test . reshape ( 10000 , 784 ) num_classes = 10 In [20]: x_train . shape [ 1 ] Out[20]: 784 Now let's prepare our class vector (y) to a binary class matrix, e.g. for use with categorical_crossentropy. In [21]: # Convert class vectors to binary class matrices y_train = keras . utils . to_categorical ( y_train , num_classes ) y_test = keras . utils . to_categorical ( y_test , num_classes ) In [22]: y_train [ 0 ] Out[22]: array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32) Now we are ready to build the model! Step 2 - Adjusting the learning rate One of the most common optimization algorithm is Stochastic Gradient Descent (SGD). The hyperparameters that can be optimized in SGD are learning rate , momentum , decay and nesterov . Learning rate controls the weight at the end of each batch, and momentum controls how much to let the previous update influence the current weight update. Decay indicates the learning rate decay over each update, and nesterov takes the value True or False depending on if we want to apply Nesterov momentum. Typical values for those hyperparameters are lr=0.01, decay=1e-6, momentum=0.9, and nesterov=True. The learning rate hyperparameter goes into the optimizer function which we will see below. Keras has a default learning rate scheduler in the SGD optimizer that decreases the learning rate during the stochastic gradient descent optimization algorithm. The learning rate is decreased according to this formula: \\begin{align} lr = lr * 1./(1. + decay * epoch) \\textrm{} \\end{align} source: http://cs231n.github.io/neural-networks-3 Let's implement a learning rate adaptation schedule in Keras . We'll start with SGD and a learning rate value of 0.1. We will then train the model for 60 epochs and set the decay argument to 0.0016 (0.1/60). We also include a momentum value of 0.8 since that seems to work well when using an adaptive learning rate. In [23]: epochs = 60 learning_rate = 0.1 decay_rate = learning_rate / epochs momentum = 0.8 sgd = SGD ( lr = learning_rate , momentum = momentum , decay = decay_rate , nesterov = False ) In [24]: # build the model input_dim = x_train . shape [ 1 ] lr_model = Sequential () lr_model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) lr_model . add ( Dropout ( 0.1 )) lr_model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) lr_model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) # compile the model lr_model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'acc' ]) In [25]: %%time # Fit the model batch_size = int ( input_dim / 100 ) lr_model_history = lr_model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 9s 145us/step - loss: 0.3158 - acc: 0.9043 - val_loss: 0.1467 - val_acc: 0.9550 Epoch 2/60 60000/60000 [==============================] - 8s 136us/step - loss: 0.1478 - acc: 0.9555 - val_loss: 0.1194 - val_acc: 0.9617 Epoch 3/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.1248 - acc: 0.9620 - val_loss: 0.1122 - val_acc: 0.9646 Epoch 4/60 60000/60000 [==============================] - 8s 136us/step - loss: 0.1167 - acc: 0.9638 - val_loss: 0.1075 - val_acc: 0.9681 Epoch 5/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.1103 - acc: 0.9666 - val_loss: 0.1039 - val_acc: 0.9691 Epoch 6/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.1051 - acc: 0.9677 - val_loss: 0.1015 - val_acc: 0.9694 Epoch 7/60 60000/60000 [==============================] - 8s 136us/step - loss: 0.1003 - acc: 0.9691 - val_loss: 0.1002 - val_acc: 0.9694 Epoch 8/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0961 - acc: 0.9707 - val_loss: 0.0998 - val_acc: 0.9694 Epoch 9/60 60000/60000 [==============================] - 9s 154us/step - loss: 0.0951 - acc: 0.9707 - val_loss: 0.0989 - val_acc: 0.9699 Epoch 10/60 60000/60000 [==============================] - 9s 150us/step - loss: 0.0919 - acc: 0.9721 - val_loss: 0.0978 - val_acc: 0.9696 Epoch 11/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0930 - acc: 0.9720 - val_loss: 0.0964 - val_acc: 0.9702 Epoch 12/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0899 - acc: 0.9728 - val_loss: 0.0965 - val_acc: 0.9703 Epoch 13/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0883 - acc: 0.9732 - val_loss: 0.0951 - val_acc: 0.9713 Epoch 14/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0871 - acc: 0.9733 - val_loss: 0.0958 - val_acc: 0.9705 Epoch 15/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0888 - acc: 0.9731 - val_loss: 0.0952 - val_acc: 0.9709 Epoch 16/60 60000/60000 [==============================] - 9s 145us/step - loss: 0.0857 - acc: 0.9743 - val_loss: 0.0950 - val_acc: 0.9713 Epoch 17/60 60000/60000 [==============================] - 9s 157us/step - loss: 0.0843 - acc: 0.9742 - val_loss: 0.0957 - val_acc: 0.9709 Epoch 18/60 60000/60000 [==============================] - 8s 142us/step - loss: 0.0842 - acc: 0.9749 - val_loss: 0.0942 - val_acc: 0.9719 Epoch 19/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0839 - acc: 0.9750 - val_loss: 0.0936 - val_acc: 0.9723 Epoch 20/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0824 - acc: 0.9748 - val_loss: 0.0942 - val_acc: 0.9723 Epoch 21/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0824 - acc: 0.9749 - val_loss: 0.0940 - val_acc: 0.9725 Epoch 22/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0829 - acc: 0.9752 - val_loss: 0.0938 - val_acc: 0.9718 Epoch 23/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0939 - val_acc: 0.9718 Epoch 24/60 60000/60000 [==============================] - 9s 149us/step - loss: 0.0796 - acc: 0.9763 - val_loss: 0.0936 - val_acc: 0.9722 Epoch 25/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0783 - acc: 0.9759 - val_loss: 0.0935 - val_acc: 0.9724 Epoch 26/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0805 - acc: 0.9755 - val_loss: 0.0937 - val_acc: 0.9721 Epoch 27/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0795 - acc: 0.9759 - val_loss: 0.0930 - val_acc: 0.9721 Epoch 28/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0931 - val_acc: 0.9721 Epoch 29/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0780 - acc: 0.9764 - val_loss: 0.0926 - val_acc: 0.9726 Epoch 30/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0759 - acc: 0.9768 - val_loss: 0.0925 - val_acc: 0.9726 Epoch 31/60 60000/60000 [==============================] - 9s 147us/step - loss: 0.0780 - acc: 0.9768 - val_loss: 0.0931 - val_acc: 0.9727 Epoch 32/60 60000/60000 [==============================] - 9s 155us/step - loss: 0.0768 - acc: 0.9765 - val_loss: 0.0925 - val_acc: 0.9726 Epoch 33/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0762 - acc: 0.9770 - val_loss: 0.0927 - val_acc: 0.9723 Epoch 34/60 60000/60000 [==============================] - 9s 149us/step - loss: 0.0765 - acc: 0.9770 - val_loss: 0.0928 - val_acc: 0.9723 Epoch 35/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0751 - acc: 0.9778 - val_loss: 0.0928 - val_acc: 0.9721 Epoch 36/60 60000/60000 [==============================] - 8s 138us/step - loss: 0.0756 - acc: 0.9772 - val_loss: 0.0919 - val_acc: 0.9721 Epoch 37/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0760 - acc: 0.9769 - val_loss: 0.0923 - val_acc: 0.9723 Epoch 38/60 60000/60000 [==============================] - 8s 138us/step - loss: 0.0751 - acc: 0.9772 - val_loss: 0.0921 - val_acc: 0.9726 Epoch 39/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0756 - acc: 0.9774 - val_loss: 0.0924 - val_acc: 0.9728 Epoch 40/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0750 - acc: 0.9774 - val_loss: 0.0924 - val_acc: 0.9728 Epoch 41/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0760 - acc: 0.9774 - val_loss: 0.0926 - val_acc: 0.9724 Epoch 42/60 60000/60000 [==============================] - 8s 142us/step - loss: 0.0719 - acc: 0.9783 - val_loss: 0.0920 - val_acc: 0.9730 Epoch 43/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0730 - acc: 0.9779 - val_loss: 0.0919 - val_acc: 0.9726 Epoch 44/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0722 - acc: 0.9785 - val_loss: 0.0920 - val_acc: 0.9728 Epoch 45/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0746 - acc: 0.9774 - val_loss: 0.0923 - val_acc: 0.9730 Epoch 46/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0736 - acc: 0.9778 - val_loss: 0.0920 - val_acc: 0.9729 Epoch 47/60 60000/60000 [==============================] - 9s 156us/step - loss: 0.0739 - acc: 0.9777 - val_loss: 0.0920 - val_acc: 0.9725 Epoch 48/60 60000/60000 [==============================] - 9s 151us/step - loss: 0.0720 - acc: 0.9783 - val_loss: 0.0917 - val_acc: 0.9731 Epoch 49/60 60000/60000 [==============================] - 9s 146us/step - loss: 0.0735 - acc: 0.9780 - val_loss: 0.0917 - val_acc: 0.9729 Epoch 50/60 60000/60000 [==============================] - 9s 152us/step - loss: 0.0729 - acc: 0.9780 - val_loss: 0.0923 - val_acc: 0.9723 Epoch 51/60 60000/60000 [==============================] - 9s 151us/step - loss: 0.0716 - acc: 0.9777 - val_loss: 0.0919 - val_acc: 0.9727 Epoch 52/60 60000/60000 [==============================] - 9s 145us/step - loss: 0.0716 - acc: 0.9784 - val_loss: 0.0915 - val_acc: 0.9726 Epoch 53/60 60000/60000 [==============================] - 9s 149us/step - loss: 0.0715 - acc: 0.9782 - val_loss: 0.0912 - val_acc: 0.9722 Epoch 54/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0704 - acc: 0.9786 - val_loss: 0.0911 - val_acc: 0.9720 Epoch 55/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0721 - acc: 0.9782 - val_loss: 0.0917 - val_acc: 0.9727 Epoch 56/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0717 - acc: 0.9784 - val_loss: 0.0918 - val_acc: 0.9725 Epoch 57/60 60000/60000 [==============================] - 9s 151us/step - loss: 0.0717 - acc: 0.9783 - val_loss: 0.0918 - val_acc: 0.9726 Epoch 58/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0708 - acc: 0.9783 - val_loss: 0.0916 - val_acc: 0.9725 Epoch 59/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.0703 - acc: 0.9782 - val_loss: 0.0916 - val_acc: 0.9731 Epoch 60/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.0703 - acc: 0.9785 - val_loss: 0.0918 - val_acc: 0.9727 CPU times: user 15min 16s, sys: 3min 41s, total: 18min 57s Wall time: 8min 37s In [26]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [27]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Exercise 1: Apply a custon learning rate change using LearningRateScheduler Write a function that performs the exponential learning rate decay as indicated by the following formula: \\begin{align} lr = lr0 * e&#94;{(-kt)} \\textrm{} \\end{align} In [28]: # your code here In [29]: # solution epochs = 60 learning_rate = 0.1 # initial learning rate decay_rate = 0.1 momentum = 0.8 # define the optimizer function sgd = SGD ( lr = learning_rate , momentum = momentum , decay = decay_rate , nesterov = False ) In [30]: input_dim = x_train . shape [ 1 ] num_classes = 10 batch_size = 196 # build the model exponential_decay_model = Sequential () exponential_decay_model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) exponential_decay_model . add ( Dropout ( 0.1 )) exponential_decay_model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) exponential_decay_model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) # compile the model exponential_decay_model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'acc' ]) In [31]: # define the learning rate change def exp_decay ( epoch ): lrate = learning_rate * np . exp ( - decay_rate * epoch ) return lrate In [32]: # learning schedule callback loss_history = History () lr_rate = LearningRateScheduler ( exp_decay ) callbacks_list = [ loss_history , lr_rate ] # you invoke the LearningRateScheduler during the .fit() phase exponential_decay_model_history = exponential_decay_model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , callbacks = callbacks_list , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 1s 16us/step - loss: 1.9924 - acc: 0.3865 - val_loss: 1.4953 - val_acc: 0.5841 Epoch 2/60 60000/60000 [==============================] - 1s 11us/step - loss: 1.2430 - acc: 0.6362 - val_loss: 1.0153 - val_acc: 0.7164 Epoch 3/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.9789 - acc: 0.7141 - val_loss: 0.8601 - val_acc: 0.7617 Epoch 4/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.8710 - acc: 0.7452 - val_loss: 0.7811 - val_acc: 0.7865 Epoch 5/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.8115 - acc: 0.7609 - val_loss: 0.7336 - val_acc: 0.7968 Epoch 6/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7749 - acc: 0.7678 - val_loss: 0.7030 - val_acc: 0.8035 Epoch 7/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7524 - acc: 0.7742 - val_loss: 0.6822 - val_acc: 0.8095 Epoch 8/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7342 - acc: 0.7788 - val_loss: 0.6673 - val_acc: 0.8122 Epoch 9/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7218 - acc: 0.7840 - val_loss: 0.6562 - val_acc: 0.8148 Epoch 10/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7144 - acc: 0.7836 - val_loss: 0.6475 - val_acc: 0.8168 Epoch 11/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7054 - acc: 0.7857 - val_loss: 0.6408 - val_acc: 0.8175 Epoch 12/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7008 - acc: 0.7896 - val_loss: 0.6354 - val_acc: 0.8185 Epoch 13/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6950 - acc: 0.7885 - val_loss: 0.6311 - val_acc: 0.8197 Epoch 14/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6921 - acc: 0.7895 - val_loss: 0.6274 - val_acc: 0.8199 Epoch 15/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6888 - acc: 0.7913 - val_loss: 0.6244 - val_acc: 0.8204 Epoch 16/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6833 - acc: 0.7932 - val_loss: 0.6219 - val_acc: 0.8206 Epoch 17/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6831 - acc: 0.7942 - val_loss: 0.6199 - val_acc: 0.8208 Epoch 18/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6822 - acc: 0.7937 - val_loss: 0.6182 - val_acc: 0.8212 Epoch 19/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6790 - acc: 0.7955 - val_loss: 0.6167 - val_acc: 0.8215 Epoch 20/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6797 - acc: 0.7935 - val_loss: 0.6155 - val_acc: 0.8218 Epoch 21/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6773 - acc: 0.7953 - val_loss: 0.6144 - val_acc: 0.8222 Epoch 22/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6742 - acc: 0.7960 - val_loss: 0.6135 - val_acc: 0.8227 Epoch 23/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6746 - acc: 0.7958 - val_loss: 0.6127 - val_acc: 0.8236 Epoch 24/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6729 - acc: 0.7973 - val_loss: 0.6120 - val_acc: 0.8237 Epoch 25/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6749 - acc: 0.7963 - val_loss: 0.6114 - val_acc: 0.8238 Epoch 26/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6715 - acc: 0.7967 - val_loss: 0.6109 - val_acc: 0.8241 Epoch 27/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6728 - acc: 0.7975 - val_loss: 0.6105 - val_acc: 0.8241 Epoch 28/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6721 - acc: 0.7964 - val_loss: 0.6101 - val_acc: 0.8246 Epoch 29/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6707 - acc: 0.7972 - val_loss: 0.6098 - val_acc: 0.8247 Epoch 30/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6711 - acc: 0.7980 - val_loss: 0.6095 - val_acc: 0.8247 Epoch 31/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6721 - acc: 0.7960 - val_loss: 0.6092 - val_acc: 0.8248 Epoch 32/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6708 - acc: 0.7981 - val_loss: 0.6090 - val_acc: 0.8249 Epoch 33/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6720 - acc: 0.7968 - val_loss: 0.6088 - val_acc: 0.8249 Epoch 34/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6700 - acc: 0.7973 - val_loss: 0.6086 - val_acc: 0.8250 Epoch 35/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6714 - acc: 0.7979 - val_loss: 0.6084 - val_acc: 0.8250 Epoch 36/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6687 - acc: 0.7980 - val_loss: 0.6083 - val_acc: 0.8250 Epoch 37/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6700 - acc: 0.7963 - val_loss: 0.6082 - val_acc: 0.8250 Epoch 38/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6702 - acc: 0.7964 - val_loss: 0.6081 - val_acc: 0.8252 Epoch 39/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6711 - acc: 0.7963 - val_loss: 0.6080 - val_acc: 0.8250 Epoch 40/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6698 - acc: 0.7971 - val_loss: 0.6079 - val_acc: 0.8251 Epoch 41/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6696 - acc: 0.7967 - val_loss: 0.6079 - val_acc: 0.8252 Epoch 42/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6699 - acc: 0.7989 - val_loss: 0.6078 - val_acc: 0.8252 Epoch 43/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6701 - acc: 0.7952 - val_loss: 0.6077 - val_acc: 0.8252 Epoch 44/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6704 - acc: 0.7973 - val_loss: 0.6077 - val_acc: 0.8252 Epoch 45/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6697 - acc: 0.7971 - val_loss: 0.6076 - val_acc: 0.8252 Epoch 46/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6718 - acc: 0.7969 - val_loss: 0.6076 - val_acc: 0.8252 Epoch 47/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6708 - acc: 0.7965 - val_loss: 0.6076 - val_acc: 0.8252 Epoch 48/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6690 - acc: 0.7968 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 49/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6700 - acc: 0.7959 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 50/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6722 - acc: 0.7963 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 51/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6698 - acc: 0.7950 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 52/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6689 - acc: 0.7978 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 53/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6696 - acc: 0.7973 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 54/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6678 - acc: 0.7975 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 55/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6694 - acc: 0.7969 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 56/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6688 - acc: 0.7981 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 57/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6674 - acc: 0.7988 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 58/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6685 - acc: 0.7970 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 59/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6702 - acc: 0.7953 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 60/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6701 - acc: 0.7965 - val_loss: 0.6074 - val_acc: 0.8252 In [33]: # check on the variables that can show me the learning rate decay exponential_decay_model_history . history . keys () Out[33]: dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr']) In [34]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( exponential_decay_model_history . history [ 'lr' ] , 'r' ) #, label='learn rate') ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Learning Rate' , fontsize = 20 ) #ax.legend() ax . tick_params ( labelsize = 20 ) In [35]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( exponential_decay_model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( exponential_decay_model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Step 3 - Choosing an optimizer and a loss function When constructing a model and using it to make our predictions, for example to assign label scores to images (\"cat\", \"plane\", etc), we want to measure our success or failure by defining a \"loss\" function (or objective function). The goal of optimization is to efficiently calculate the parameters/weights that minimize this loss function. keras provides various types of loss functions . Sometimes the \"loss\" function measures the \"distance\". We can define this \"distance\" between two data points in various ways suitable to the problem or dataset. Distance Euclidean Manhattan others such as Hamming which measures distances between strings, for example. The Hamming distance of \"carolin\" and \"cathrin\" is 3. Loss functions MSE (for regression) categorical cross-entropy (for classification) binary cross entropy (for classification) In [40]: # build the model input_dim = x_train . shape [ 1 ] model = Sequential () model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) # fully-connected layer with 64 hidden units model . add ( Dropout ( 0.1 )) model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) In [41]: # defining the parameters for RMSprop (I used the keras defaults here) rms = RMSprop ( lr = 0.001 , rho = 0.9 , epsilon = None , decay = 0.0 ) model . compile ( loss = 'categorical_crossentropy' , optimizer = rms , metrics = [ 'acc' ]) Step 4 - Deciding on the batch size and number of epochs In [42]: %%time batch_size = input_dim epochs = 60 model_history = model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 1s 14us/step - loss: 1.1320 - acc: 0.7067 - val_loss: 0.5628 - val_acc: 0.8237 Epoch 2/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.4831 - acc: 0.8570 - val_loss: 0.3674 - val_acc: 0.8934 Epoch 3/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.3665 - acc: 0.8931 - val_loss: 0.3199 - val_acc: 0.9061 Epoch 4/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.3100 - acc: 0.9092 - val_loss: 0.2664 - val_acc: 0.9233 Epoch 5/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.2699 - acc: 0.9206 - val_loss: 0.2295 - val_acc: 0.9326 Epoch 6/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.2391 - acc: 0.9305 - val_loss: 0.2104 - val_acc: 0.9362 Epoch 7/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.2115 - acc: 0.9383 - val_loss: 0.1864 - val_acc: 0.9459 Epoch 8/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.1900 - acc: 0.9451 - val_loss: 0.1658 - val_acc: 0.9493 Epoch 9/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.1714 - acc: 0.9492 - val_loss: 0.1497 - val_acc: 0.9538 Epoch 10/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1565 - acc: 0.9539 - val_loss: 0.1404 - val_acc: 0.9591 Epoch 11/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1443 - acc: 0.9569 - val_loss: 0.1305 - val_acc: 0.9616 Epoch 12/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1334 - acc: 0.9596 - val_loss: 0.1224 - val_acc: 0.9628 Epoch 13/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1257 - acc: 0.9627 - val_loss: 0.1133 - val_acc: 0.9660 Epoch 14/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1169 - acc: 0.9652 - val_loss: 0.1116 - val_acc: 0.9674 Epoch 15/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1091 - acc: 0.9675 - val_loss: 0.1104 - val_acc: 0.9670 Epoch 16/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1051 - acc: 0.9689 - val_loss: 0.1030 - val_acc: 0.9692 Epoch 17/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0978 - acc: 0.9697 - val_loss: 0.1044 - val_acc: 0.9686 Epoch 18/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0929 - acc: 0.9718 - val_loss: 0.0996 - val_acc: 0.9689 Epoch 19/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0882 - acc: 0.9738 - val_loss: 0.1035 - val_acc: 0.9695 Epoch 20/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0850 - acc: 0.9737 - val_loss: 0.0941 - val_acc: 0.9717 Epoch 21/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0803 - acc: 0.9751 - val_loss: 0.0953 - val_acc: 0.9715 Epoch 22/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0793 - acc: 0.9762 - val_loss: 0.0898 - val_acc: 0.9729 Epoch 23/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0747 - acc: 0.9775 - val_loss: 0.0901 - val_acc: 0.9732 Epoch 24/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0718 - acc: 0.9778 - val_loss: 0.0948 - val_acc: 0.9720 Epoch 25/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0697 - acc: 0.9781 - val_loss: 0.0908 - val_acc: 0.9727 Epoch 26/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0668 - acc: 0.9794 - val_loss: 0.0917 - val_acc: 0.9726 Epoch 27/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0648 - acc: 0.9800 - val_loss: 0.0895 - val_acc: 0.9737 Epoch 28/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0637 - acc: 0.9798 - val_loss: 0.0868 - val_acc: 0.9728 Epoch 29/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0598 - acc: 0.9813 - val_loss: 0.0883 - val_acc: 0.9736 Epoch 30/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0570 - acc: 0.9820 - val_loss: 0.0869 - val_acc: 0.9741 Epoch 31/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0555 - acc: 0.9825 - val_loss: 0.0896 - val_acc: 0.9732 Epoch 32/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0554 - acc: 0.9827 - val_loss: 0.0843 - val_acc: 0.9743 Epoch 33/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0512 - acc: 0.9836 - val_loss: 0.0843 - val_acc: 0.9746 Epoch 34/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0509 - acc: 0.9835 - val_loss: 0.0868 - val_acc: 0.9753 Epoch 35/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0491 - acc: 0.9842 - val_loss: 0.0841 - val_acc: 0.9755 Epoch 36/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0471 - acc: 0.9848 - val_loss: 0.0887 - val_acc: 0.9728 Epoch 37/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0466 - acc: 0.9850 - val_loss: 0.0876 - val_acc: 0.9756 Epoch 38/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0456 - acc: 0.9856 - val_loss: 0.0833 - val_acc: 0.9769 Epoch 39/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0431 - acc: 0.9866 - val_loss: 0.0869 - val_acc: 0.9759 Epoch 40/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0413 - acc: 0.9869 - val_loss: 0.0926 - val_acc: 0.9743 Epoch 41/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0401 - acc: 0.9872 - val_loss: 0.0851 - val_acc: 0.9756 Epoch 42/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0401 - acc: 0.9876 - val_loss: 0.0856 - val_acc: 0.9764 Epoch 43/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0392 - acc: 0.9870 - val_loss: 0.0861 - val_acc: 0.9771 Epoch 44/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0396 - acc: 0.9870 - val_loss: 0.0918 - val_acc: 0.9756 Epoch 45/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0371 - acc: 0.9883 - val_loss: 0.0866 - val_acc: 0.9766 Epoch 46/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0374 - acc: 0.9883 - val_loss: 0.0888 - val_acc: 0.9748 Epoch 47/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0376 - acc: 0.9878 - val_loss: 0.0850 - val_acc: 0.9761 Epoch 48/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0351 - acc: 0.9890 - val_loss: 0.0848 - val_acc: 0.9777 Epoch 49/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0361 - acc: 0.9884 - val_loss: 0.0850 - val_acc: 0.9771 Epoch 50/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0341 - acc: 0.9887 - val_loss: 0.0889 - val_acc: 0.9769 Epoch 51/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0322 - acc: 0.9897 - val_loss: 0.0882 - val_acc: 0.9771 Epoch 52/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0322 - acc: 0.9895 - val_loss: 0.0892 - val_acc: 0.9762 Epoch 53/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0313 - acc: 0.9892 - val_loss: 0.0916 - val_acc: 0.9771 Epoch 54/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0300 - acc: 0.9897 - val_loss: 0.0913 - val_acc: 0.9772 Epoch 55/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0306 - acc: 0.9902 - val_loss: 0.0904 - val_acc: 0.9763 Epoch 56/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0307 - acc: 0.9900 - val_loss: 0.0910 - val_acc: 0.9777 Epoch 57/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0918 - val_acc: 0.9763 Epoch 58/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0914 - val_acc: 0.9778 Epoch 59/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0907 - val_acc: 0.9769 Epoch 60/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0283 - acc: 0.9908 - val_loss: 0.0962 - val_acc: 0.9761 CPU times: user 1min 17s, sys: 7.4 s, total: 1min 24s Wall time: 29.3 s In [43]: score = model . evaluate ( x_test , y_test , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) Test loss: 0.09620895183624088 Test accuracy: 0.9761 In [44]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'acc' ]), 'r' , label = 'train_acc' ) ax . plot ( np . sqrt ( model_history . history [ 'val_acc' ]), 'b' , label = 'val_acc' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [45]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Step 5 - Random restarts This method does not seem to have an implementation in keras . We will leave it as a home exercise! Hint: you can use keras.callbacks.LearningRateScheduler . See how we used it to set a custom learning rate. Tuning the Hyperparameters using Cross Validation Now instead of trying different values by hand, we will use GridSearchCV from Scikit-Learn to try out several values for our hyperparameters and compare the results. To do cross-validation with keras we will use the wrappers for the Scikit-Learn API. They provide a way to use Sequential Keras models (single-input only) as part of your Scikit-Learn workflow. There are two wrappers available: keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params) , which implements the Scikit-Learn classifier interface, keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params) , which implements the Scikit-Learn regressor interface. In [46]: import numpy from sklearn.model_selection import GridSearchCV from keras.wrappers.scikit_learn import KerasClassifier Trying different weight initializations In [47]: # let's create a function that creates the model (required for KerasClassifier) # while accepting the hyperparameters we want to tune # we also pass some default values such as optimizer='rmsprop' def create_model ( init_mode = 'uniform' ): # define model model = Sequential () model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu , input_dim = 784 )) model . add ( Dropout ( 0.1 )) model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu )) model . add ( Dense ( 10 , kernel_initializer = init_mode , activation = tf . nn . softmax )) # compile model model . compile ( loss = 'categorical_crossentropy' , optimizer = RMSprop (), metrics = [ 'accuracy' ]) return model In [49]: %%time seed = 7 numpy . random . seed ( seed ) batch_size = 128 epochs = 10 model_CV = KerasClassifier ( build_fn = create_model , epochs = epochs , batch_size = batch_size , verbose = 1 ) # define the grid search parameters init_mode = [ 'uniform' , 'lecun_uniform' , 'normal' , 'zero' , 'glorot_normal' , 'glorot_uniform' , 'he_normal' , 'he_uniform' ] param_grid = dict ( init_mode = init_mode ) grid = GridSearchCV ( estimator = model_CV , param_grid = param_grid , n_jobs =- 1 , cv = 3 ) grid_result = grid . fit ( x_train , y_train ) Epoch 1/10 60000/60000 [==============================] - 1s 21us/step - loss: 0.4118 - acc: 0.8824 Epoch 2/10 60000/60000 [==============================] - 1s 15us/step - loss: 0.1936 - acc: 0.9437 Epoch 3/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.1482 - acc: 0.9553 Epoch 4/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.1225 - acc: 0.9631 Epoch 5/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.1064 - acc: 0.9676 Epoch 6/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.0944 - acc: 0.9710 Epoch 7/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.0876 - acc: 0.9732 Epoch 8/10 60000/60000 [==============================] - 1s 15us/step - loss: 0.0809 - acc: 0.9745 Epoch 9/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.0741 - acc: 0.9775 Epoch 10/10 60000/60000 [==============================] - 1s 15us/step - loss: 0.0709 - acc: 0.9783 CPU times: user 21 s, sys: 3.56 s, total: 24.5 s Wall time: 1min 20s In [50]: # print results print ( f 'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_} ' ) means = grid_result . cv_results_ [ 'mean_test_score' ] stds = grid_result . cv_results_ [ 'std_test_score' ] params = grid_result . cv_results_ [ 'params' ] for mean , stdev , param in zip ( means , stds , params ): print ( f ' mean= {mean:.4} , std= {stdev:.4} using {param} ' ) Best Accuracy for 0.9689333333333333 using {'init_mode': 'lecun_uniform'} mean=0.9647, std=0.001438 using {'init_mode': 'uniform'} mean=0.9689, std=0.001044 using {'init_mode': 'lecun_uniform'} mean=0.9651, std=0.001515 using {'init_mode': 'normal'} mean=0.1124, std=0.002416 using {'init_mode': 'zero'} mean=0.9657, std=0.0005104 using {'init_mode': 'glorot_normal'} mean=0.9687, std=0.0008436 using {'init_mode': 'glorot_uniform'} mean=0.9681, std=0.002145 using {'init_mode': 'he_normal'} mean=0.9685, std=0.001952 using {'init_mode': 'he_uniform'} Save Your Neural Network Model to JSON The Hierarchical Data Format (HDF5) is a data storage format for storing large arrays of data including values for the weights in a neural network. You can install HDF5 Python module: pip install h5py Keras gives you the ability to describe and save any model using the JSON format. In [51]: from keras.models import model_from_json # serialize model to JSON model_json = model . to_json () with open ( \"model.json\" , \"w\" ) as json_file : json_file . write ( model_json ) # save weights to HDF5 model . save_weights ( \"model.h5\" ) print ( \"Model saved\" ) # when you want to retrieve the model: load json and create model json_file = open ( 'model.json' , 'r' ) saved_model = json_file . read () # close the file as good practice json_file . close () model_from_json = model_from_json ( saved_model ) # load weights into new model model_from_json . load_weights ( \"model.h5\" ) print ( \"Model loaded\" ) Model saved Model loaded Exercise 2: Cross-validation with more than one hyperparameters We can do cross-validation with more than one parameters simultaneously, effectively trying out combinations of them. Note: Cross-validation in neural networks is computationally expensive . Think before you experiment! Multiply the number of features you are validating on to see how many combinations there are. Each combination is evaluated using the cv-fold cross-validation (cv is a parameter we choose). For example, we can choose to search for different values of: batch size, number of epochs and initialization mode. The choises are specifed into a dictionary and passed to GridSearchCV. Perform a GridSearch for batch size , number of epochs and initializer combined. In [52]: #your code here In [53]: # solutions # repeat some of the initial values here so we make sure they were not changed input_dim = x_train . shape [ 1 ] num_classes = 10 # let's create a function that creates the model (required for KerasClassifier) # while accepting the hyperparameters we want to tune # we also pass some default values such as optimizer='rmsprop' def create_model_2 ( optimizer = 'rmsprop' , init = 'glorot_uniform' ): model = Sequential () model . add ( Dense ( 64 , input_dim = input_dim , kernel_initializer = init , activation = 'relu' )) model . add ( Dropout ( 0.1 )) model . add ( Dense ( 64 , kernel_initializer = init , activation = tf . nn . relu )) model . add ( Dense ( num_classes , kernel_initializer = init , activation = tf . nn . softmax )) # compile model model . compile ( loss = 'categorical_crossentropy' , optimizer = optimizer , metrics = [ 'accuracy' ]) return model In [54]: %%time # fix random seed for reproducibility (this might work or might not work # depending on each library's implenentation) seed = 7 numpy . random . seed ( seed ) # create the sklearn model for the network model_init_batch_epoch_CV = KerasClassifier ( build_fn = create_model_2 , verbose = 1 ) # we choose the initializers that came at the top in our previous cross-validation!! init_mode = [ 'glorot_uniform' , 'uniform' ] batches = [ 128 , 512 ] epochs = [ 10 , 20 ] # grid search for initializer, batch size and number of epochs param_grid = dict ( epochs = epochs , batch_size = batches , init = init_mode ) grid = GridSearchCV ( estimator = model_init_batch_epoch_CV , param_grid = param_grid , cv = 3 ) grid_result = grid . fit ( x_train , y_train ) Epoch 1/10 40000/40000 [==============================] - 1s 21us/step - loss: 0.4801 - acc: 0.8601 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2309 - acc: 0.9310 Epoch 3/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.1744 - acc: 0.9479 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1422 - acc: 0.9575 Epoch 5/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.1214 - acc: 0.9625 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1081 - acc: 0.9675 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0974 - acc: 0.9693 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0874 - acc: 0.9730 Epoch 9/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0800 - acc: 0.9750 Epoch 10/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0750 - acc: 0.9765 20000/20000 [==============================] - 0s 10us/step 40000/40000 [==============================] - 0s 6us/step Epoch 1/10 40000/40000 [==============================] - 1s 22us/step - loss: 0.4746 - acc: 0.8656 Epoch 2/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.2264 - acc: 0.9336 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1734 - acc: 0.9487 Epoch 4/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.1436 - acc: 0.9568 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1256 - acc: 0.9614 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1104 - acc: 0.9660 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0973 - acc: 0.9707 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0870 - acc: 0.9733 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0818 - acc: 0.9748 Epoch 10/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0730 - acc: 0.9770 20000/20000 [==============================] - 0s 10us/step 40000/40000 [==============================] - 0s 6us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 0.4639 - acc: 0.8671 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2208 - acc: 0.9344 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1693 - acc: 0.9491 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1388 - acc: 0.9580 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1206 - acc: 0.9634 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1062 - acc: 0.9678 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0956 - acc: 0.9711 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0870 - acc: 0.9728 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0794 - acc: 0.9750 Epoch 10/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0748 - acc: 0.9774 20000/20000 [==============================] - 0s 11us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 0.7144 - acc: 0.7894 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.3246 - acc: 0.9045 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2482 - acc: 0.9268 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2005 - acc: 0.9407 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1673 - acc: 0.9485 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1462 - acc: 0.9559 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1305 - acc: 0.9604 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1166 - acc: 0.9643 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1079 - acc: 0.9675 Epoch 10/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0983 - acc: 0.9695 20000/20000 [==============================] - 0s 12us/step 40000/40000 [==============================] - 0s 6us/step Epoch 1/10 40000/40000 [==============================] - 1s 24us/step - loss: 0.6894 - acc: 0.7944 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.3171 - acc: 0.9061 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2358 - acc: 0.9312 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1911 - acc: 0.9422 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1595 - acc: 0.9526 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1401 - acc: 0.9579 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1230 - acc: 0.9636 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1096 - acc: 0.9672 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1027 - acc: 0.9692 Epoch 10/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0936 - acc: 0.9718 20000/20000 [==============================] - 0s 12us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/10 40000/40000 [==============================] - 1s 24us/step - loss: 0.7028 - acc: 0.7976 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.3189 - acc: 0.9055 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2390 - acc: 0.9307 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1910 - acc: 0.9435 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1595 - acc: 0.9528 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1376 - acc: 0.9583 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1213 - acc: 0.9629 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1100 - acc: 0.9664 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0987 - acc: 0.9697 Epoch 10/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0932 - acc: 0.9714 20000/20000 [==============================] - 0s 13us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 25us/step - loss: 0.4938 - acc: 0.8589 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2286 - acc: 0.9324 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1751 - acc: 0.9470 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1458 - acc: 0.9553 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1237 - acc: 0.9620 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1106 - acc: 0.9669 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0998 - acc: 0.9696 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0898 - acc: 0.9729 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0799 - acc: 0.9749 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0746 - acc: 0.9769 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0688 - acc: 0.9783 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0655 - acc: 0.9792 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0619 - acc: 0.9801 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0574 - acc: 0.9814 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0549 - acc: 0.9836 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0512 - acc: 0.9837 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0464 - acc: 0.9855 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0466 - acc: 0.9850 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0431 - acc: 0.9863 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0430 - acc: 0.9861 20000/20000 [==============================] - 0s 13us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 25us/step - loss: 0.4956 - acc: 0.8584 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2286 - acc: 0.9321 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1746 - acc: 0.9474 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1438 - acc: 0.9574 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1232 - acc: 0.9634 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1104 - acc: 0.9665 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0986 - acc: 0.9696 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0886 - acc: 0.9723 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0828 - acc: 0.9741 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0763 - acc: 0.9768 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0679 - acc: 0.9781 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0656 - acc: 0.9788 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0601 - acc: 0.9810 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0571 - acc: 0.9817 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0517 - acc: 0.9832 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0509 - acc: 0.9834 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0478 - acc: 0.9850 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0461 - acc: 0.9852 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0442 - acc: 0.9854 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0427 - acc: 0.9866 20000/20000 [==============================] - 0s 14us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.4694 - acc: 0.8670 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2196 - acc: 0.9336 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1681 - acc: 0.9495 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1391 - acc: 0.9589 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1200 - acc: 0.9630 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1067 - acc: 0.9671 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0968 - acc: 0.9713 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0880 - acc: 0.9730 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0815 - acc: 0.9754 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0742 - acc: 0.9771 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0711 - acc: 0.9778 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0643 - acc: 0.9806 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9815 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0561 - acc: 0.9818 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0534 - acc: 0.9832 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0528 - acc: 0.9832 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0479 - acc: 0.9848 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0486 - acc: 0.9844 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0438 - acc: 0.9861 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0427 - acc: 0.9861 20000/20000 [==============================] - 0s 14us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.6830 - acc: 0.8003 Epoch 2/20 40000/40000 [==============================] - 1s 16us/step - loss: 0.3234 - acc: 0.9044 Epoch 3/20 40000/40000 [==============================] - 1s 16us/step - loss: 0.2456 - acc: 0.9269 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1982 - acc: 0.9407 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1627 - acc: 0.9506 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1422 - acc: 0.9561 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1251 - acc: 0.9618 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1134 - acc: 0.9650 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1037 - acc: 0.9677 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0957 - acc: 0.9705 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0891 - acc: 0.9730 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0832 - acc: 0.9745 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0760 - acc: 0.9768 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0727 - acc: 0.9778 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9782 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0628 - acc: 0.9803 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9801 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0572 - acc: 0.9824 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0549 - acc: 0.9821 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0521 - acc: 0.9834 20000/20000 [==============================] - 0s 15us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 28us/step - loss: 0.6742 - acc: 0.8034 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.3142 - acc: 0.9081 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2365 - acc: 0.9306 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1873 - acc: 0.9453 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1563 - acc: 0.9531 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1373 - acc: 0.9580 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1212 - acc: 0.9640 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1084 - acc: 0.9665 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1014 - acc: 0.9695 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0917 - acc: 0.9732 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0838 - acc: 0.9739 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0788 - acc: 0.9749 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0720 - acc: 0.9779 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0685 - acc: 0.9793 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0666 - acc: 0.9797 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0618 - acc: 0.9807 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0578 - acc: 0.9819 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0557 - acc: 0.9825 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0535 - acc: 0.9831 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0482 - acc: 0.9848 20000/20000 [==============================] - 0s 15us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 29us/step - loss: 0.6865 - acc: 0.8001 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.3089 - acc: 0.9106 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2292 - acc: 0.9304 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1845 - acc: 0.9435 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1562 - acc: 0.9527 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1371 - acc: 0.9584 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1206 - acc: 0.9629 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1098 - acc: 0.9667 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0990 - acc: 0.9699 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0912 - acc: 0.9718 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0863 - acc: 0.9740 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0792 - acc: 0.9757 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0721 - acc: 0.9782 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0696 - acc: 0.9782 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0661 - acc: 0.9796 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0621 - acc: 0.9810 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0588 - acc: 0.9813 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0541 - acc: 0.9831 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0513 - acc: 0.9834 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0514 - acc: 0.9835 20000/20000 [==============================] - 0s 16us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/10 40000/40000 [==============================] - 1s 22us/step - loss: 0.7656 - acc: 0.7926 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3345 - acc: 0.9021 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2633 - acc: 0.9225 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2207 - acc: 0.9357 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1877 - acc: 0.9450 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1684 - acc: 0.9500 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1517 - acc: 0.9552 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1358 - acc: 0.9587 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1236 - acc: 0.9627 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1153 - acc: 0.9661 20000/20000 [==============================] - 0s 14us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 22us/step - loss: 0.7640 - acc: 0.7905 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3207 - acc: 0.9055 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2455 - acc: 0.9276 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2050 - acc: 0.9392 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1755 - acc: 0.9484 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1573 - acc: 0.9524 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1385 - acc: 0.9594 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1247 - acc: 0.9634 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1181 - acc: 0.9644 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1074 - acc: 0.9679 20000/20000 [==============================] - 0s 15us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 0.7858 - acc: 0.7867 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3358 - acc: 0.9017 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2603 - acc: 0.9250 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2160 - acc: 0.9367 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1879 - acc: 0.9435 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1663 - acc: 0.9513 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1493 - acc: 0.9552 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1363 - acc: 0.9591 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1262 - acc: 0.9609 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1147 - acc: 0.9653 20000/20000 [==============================] - 0s 16us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 1.1193 - acc: 0.6932 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.4829 - acc: 0.8573 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3785 - acc: 0.8885 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3208 - acc: 0.9062 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2811 - acc: 0.9167 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2472 - acc: 0.9263 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2200 - acc: 0.9362 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1963 - acc: 0.9422 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1772 - acc: 0.9475 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1611 - acc: 0.9519 20000/20000 [==============================] - 0s 16us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 24us/step - loss: 1.1189 - acc: 0.6828 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.4867 - acc: 0.8556 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3713 - acc: 0.8919 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3125 - acc: 0.9090 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2748 - acc: 0.9214 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2443 - acc: 0.9285 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2141 - acc: 0.9383 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1919 - acc: 0.9445 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1767 - acc: 0.9485 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1617 - acc: 0.9528 20000/20000 [==============================] - 0s 17us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 25us/step - loss: 1.0997 - acc: 0.7128 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.4652 - acc: 0.8638 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3716 - acc: 0.8919 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3165 - acc: 0.9072 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2735 - acc: 0.9199 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2381 - acc: 0.9299 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2094 - acc: 0.9380 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1863 - acc: 0.9442 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1693 - acc: 0.9491 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1549 - acc: 0.9538 20000/20000 [==============================] - 0s 17us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 26us/step - loss: 0.7406 - acc: 0.7936 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3331 - acc: 0.9019 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2623 - acc: 0.9229 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2174 - acc: 0.9372 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1876 - acc: 0.9436 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1659 - acc: 0.9498 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1493 - acc: 0.9559 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1358 - acc: 0.9602 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1244 - acc: 0.9624 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1135 - acc: 0.9655 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1063 - acc: 0.9683 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0963 - acc: 0.9711 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0924 - acc: 0.9720 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0897 - acc: 0.9732 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0811 - acc: 0.9752 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0798 - acc: 0.9750 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0733 - acc: 0.9770 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0695 - acc: 0.9789 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0652 - acc: 0.9798 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0622 - acc: 0.9815 20000/20000 [==============================] - 0s 18us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.7349 - acc: 0.8012 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3201 - acc: 0.9060 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2541 - acc: 0.9257 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2149 - acc: 0.9375 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1894 - acc: 0.9443 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1694 - acc: 0.9496 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1552 - acc: 0.9541 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1421 - acc: 0.9580 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1307 - acc: 0.9605 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1200 - acc: 0.9642 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1110 - acc: 0.9663 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1041 - acc: 0.9681 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0971 - acc: 0.9698 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0943 - acc: 0.9713 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0864 - acc: 0.9733 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0809 - acc: 0.9748 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0776 - acc: 0.9762 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0745 - acc: 0.9762 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0712 - acc: 0.9777 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0654 - acc: 0.9793 20000/20000 [==============================] - 0s 18us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.7435 - acc: 0.8001 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3335 - acc: 0.9029 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2555 - acc: 0.9254 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2168 - acc: 0.9359 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1872 - acc: 0.9458 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1640 - acc: 0.9514 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1452 - acc: 0.9578 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1313 - acc: 0.9607 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1193 - acc: 0.9644 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1104 - acc: 0.9670 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1024 - acc: 0.9691 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0955 - acc: 0.9715 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0881 - acc: 0.9734 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0815 - acc: 0.9756 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0772 - acc: 0.9764 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0745 - acc: 0.9780 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0681 - acc: 0.9788 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0649 - acc: 0.9806 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0640 - acc: 0.9800 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0604 - acc: 0.9813 20000/20000 [==============================] - 0s 19us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 28us/step - loss: 1.1126 - acc: 0.6943 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.4792 - acc: 0.8568 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3712 - acc: 0.8910 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3155 - acc: 0.9068 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2746 - acc: 0.9196 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2392 - acc: 0.9293 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2126 - acc: 0.9363 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1923 - acc: 0.9437 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1706 - acc: 0.9489 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1591 - acc: 0.9530 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1462 - acc: 0.9560 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1342 - acc: 0.9593 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1272 - acc: 0.9609 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1188 - acc: 0.9639 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1126 - acc: 0.9660 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1072 - acc: 0.9673 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1016 - acc: 0.9692 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0971 - acc: 0.9697 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0901 - acc: 0.9719 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0869 - acc: 0.9729 20000/20000 [==============================] - 0s 19us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 28us/step - loss: 1.0906 - acc: 0.7216 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.4527 - acc: 0.8658 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3559 - acc: 0.8956 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3055 - acc: 0.9109 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2642 - acc: 0.9219 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2333 - acc: 0.9317 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2057 - acc: 0.9386 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1858 - acc: 0.9462 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1674 - acc: 0.9501 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1514 - acc: 0.9548 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1410 - acc: 0.9571 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1303 - acc: 0.9607 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1193 - acc: 0.9643 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1131 - acc: 0.9649 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1054 - acc: 0.9680 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0999 - acc: 0.9696 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0937 - acc: 0.9712 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0895 - acc: 0.9731 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0830 - acc: 0.9758 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0790 - acc: 0.9760 20000/20000 [==============================] - 0s 20us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 29us/step - loss: 1.1233 - acc: 0.6955 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.4793 - acc: 0.8588 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3751 - acc: 0.8898 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3203 - acc: 0.9069 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2760 - acc: 0.9196 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2422 - acc: 0.9286 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2155 - acc: 0.9363 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1910 - acc: 0.9437 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1718 - acc: 0.9489 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1584 - acc: 0.9530 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1435 - acc: 0.9570 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1326 - acc: 0.9603 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1244 - acc: 0.9615 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1171 - acc: 0.9644 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1093 - acc: 0.9670 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1047 - acc: 0.9692 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0984 - acc: 0.9698 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0910 - acc: 0.9720 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0860 - acc: 0.9734 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0827 - acc: 0.9748 20000/20000 [==============================] - 0s 21us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 60000/60000 [==============================] - 2s 31us/step - loss: 0.4007 - acc: 0.8851 Epoch 2/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1892 - acc: 0.9439 Epoch 3/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1432 - acc: 0.9567 Epoch 4/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1185 - acc: 0.9643 Epoch 5/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1050 - acc: 0.9678 Epoch 6/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0929 - acc: 0.9715 Epoch 7/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0848 - acc: 0.9737 Epoch 8/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0775 - acc: 0.9764 Epoch 9/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0723 - acc: 0.9780 Epoch 10/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0693 - acc: 0.9785 Epoch 11/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0637 - acc: 0.9802 Epoch 12/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0602 - acc: 0.9814 Epoch 13/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0585 - acc: 0.9816 Epoch 14/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0546 - acc: 0.9827 Epoch 15/20 60000/60000 [==============================] - 1s 18us/step - loss: 0.0512 - acc: 0.9834 Epoch 16/20 60000/60000 [==============================] - 1s 18us/step - loss: 0.0501 - acc: 0.9841 Epoch 17/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0481 - acc: 0.9844 Epoch 18/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0456 - acc: 0.9860 Epoch 19/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0444 - acc: 0.9857 Epoch 20/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0439 - acc: 0.9861 CPU times: user 7min 56s, sys: 1min 6s, total: 9min 3s Wall time: 3min 43s In [55]: # print results print ( f 'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_} ' ) means = grid_result . cv_results_ [ 'mean_test_score' ] stds = grid_result . cv_results_ [ 'std_test_score' ] params = grid_result . cv_results_ [ 'params' ] for mean , stdev , param in zip ( means , stds , params ): print ( f 'mean= {mean:.4} , std= {stdev:.4} using {param} ' ) Best Accuracy for 0.9712 using {'batch_size': 128, 'epochs': 20, 'init': 'glorot_uniform'} mean=0.9687, std=0.002174 using {'batch_size': 128, 'epochs': 10, 'init': 'glorot_uniform'} mean=0.966, std=0.000827 using {'batch_size': 128, 'epochs': 10, 'init': 'uniform'} mean=0.9712, std=0.0006276 using {'batch_size': 128, 'epochs': 20, 'init': 'glorot_uniform'} mean=0.97, std=0.001214 using {'batch_size': 128, 'epochs': 20, 'init': 'uniform'} mean=0.9594, std=0.001476 using {'batch_size': 512, 'epochs': 10, 'init': 'glorot_uniform'} mean=0.9516, std=0.003239 using {'batch_size': 512, 'epochs': 10, 'init': 'uniform'} mean=0.9684, std=0.003607 using {'batch_size': 512, 'epochs': 20, 'init': 'glorot_uniform'} mean=0.9633, std=0.0007962 using {'batch_size': 512, 'epochs': 20, 'init': 'uniform'} if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"pages","url":"pages/lab3/solutions/"},{"title":"Lab 3: Optimization of Neural Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 3: Optimization in Artificial Neural Networks Harvard University Spring 2019 Lab instructor Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab, we'll explore ways to optimize the loss function of a Multilayer Learning Perceptor (MLP) by tuning the model hyperparameters. We'll also explore the use of cross-validation as a technique for checking potential values for these hyperparameters. By the end of this lab, you should: Be familiar with the use of sklearn 's optimize function. Be able to identify the hyperparameters that go into the training of a MLP. Be familiar with the implementation in keras of various optimization techniques. Apply cross-validation to check for multiple values of hyperparameters. In [2]: import matplotlib.pyplot as plt import numpy as np from scipy.optimize import minimize % matplotlib inline Part 1: Beale's function First let's look at function optimization in scipy.optimize , using Beale's function as an example Optimizing a function $f: A\\rightarrow R$, from some set A to the real numbers is finding an element $x_0\\,\\epsilon\\, A$ such that $f(x_0)\\leq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the minimum) or such that $f(x_0)\\geq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the maximum). To illustrate our point we will use a function of two parameters. Our goal is to optimize over these 2 parameters. We can extend to higher dimensions by plotting pairs of parameters against each other. The Wikipedia article on Test functions for optimization has a few functions that are useful for evaluating optimization algorithms. Here is Beale's function: $f(x,y)$ = $(1.5−x+xy)&#94;2+(2.25−x+xy&#94;2)&#94;2+(2.625−x+xy&#94;3)&#94;2$ [source: Wikipedia ] We already know that this function has a minimum at [3.0, 0.5]. Let's see if scipy will find it. In [3]: # define Beale's function which we want to minimize def objective ( X ): x = X [ 0 ]; y = X [ 1 ] return ( 1.5 - x + x * y ) ** 2 + ( 2.25 - x + x * y ** 2 ) ** 2 + ( 2.625 - x + x * y ** 3 ) ** 2 In [4]: # function boundaries xmin , xmax , xstep = - 4.5 , 4.5 , . 9 ymin , ymax , ystep = - 4.5 , 4.5 , . 9 In [5]: # Let's create some points x1 , y1 = np . meshgrid ( np . arange ( xmin , xmax + xstep , xstep ), np . arange ( ymin , ymax + ystep , ystep )) Let's make an initial guess In [6]: # initial guess x0 = [ 4. , 4. ] f0 = objective ( x0 ) print ( f0 ) 68891.203125 In [7]: bnds = (( xmin , xmax ), ( ymin , ymax )) minimum = minimize ( objective , x0 , bounds = bnds ) In [8]: print ( minimum ) fun: 2.068025638865627e-12 hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64> jac: array([-1.55969780e-06, 9.89837957e-06]) message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL' nfev: 60 nit: 14 status: 0 success: True x: array([3.00000257, 0.50000085]) In [9]: real_min = [ 3.0 , 0.5 ] print ( f 'The answer, {minimum.x} , is very close to the optimum as we know it, which is {real_min} ' ) print ( f 'The value of the objective for {real_min} is {objective(real_min)}' ) The answer, [3.00000257 0.50000085], is very close to the optimum as we know it, which is [3.0, 0.5] The value of the objective for [3.0, 0.5] is 0.0 Part 2: Optimization in neural networks In general: Learning Representation --> Objective function --> Optimization algorithm A neural network can be defined as a framework that combines inputs and tries to guess the output. If we are lucky enough to have some results, called \"the ground truth\", to compare the outputs produced by the network, we can calculate the error . So the network guesses, calculates some error function, guesses again, trying to minimize this error, guesses again, until the error does not go down any more. This is optimization. In neural networks the most common used optimization algorithms, are flavors of GD (gradient descent) . The objective function used in gradient descent is the loss function which we want to minimize . A keras Refresher Keras is a Python library for deep learning that can run on top of both Theano or TensorFlow, two powerful Python libraries for fast numerical computing created and released by Facebook and Google, respectevely. Keras was developed to make developing deep learning models as fast and easy as possible for research and practical applications. It runs on Python 2.7 or 3.5 and can seamlessly execute on GPUs and CPUs. Keras is built on the idea of a model. At its core we have a sequence of layers called the Sequential model which is a linear stack of layers. Keras also provides the functional API , a way to define complex models, such as multi-output models, directed acyclic graphs, or models with shared layers. We can summarize the construction of deep learning models in Keras using the Sequential model as follows: Define your model : create a Sequential model and add layers. Compile your model : specify loss function and optimizers and call the .compile() function. Fit your model : train the model on data by calling the .fit() function. Make predictions : use the model to generate predictions on new data by calling functions such as .evaluate() or .predict() . Callbacks: taking a peek into our model while it's training You can look at what is happening in various stages of your model by using callbacks . A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training. A callback function you are already familiar with is keras.callbacks.History() . This is automatically included in .fit() . Another very useful one is keras.callbacks.ModelCheckpoint which saves the model with its weights at a certain point in the training. This can prove useful if your model is running for a long time and a system failure happens. Not all is lost then. It's a good practice to save the model weights only when an improvement is observed as measured by the acc , for example. keras.callbacks.EarlyStopping stops the training when a monitored quantity has stopped improving. keras.callbacks.LearningRateScheduler will change the learning rate during training. We will apply some callbacks later. For full documentation on callbacks see https://keras.io/callbacks/ What are the steps to optimizing our network? In [10]: import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras import losses from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) # fix random seed for reproducibility np . random . seed ( 5 ) 1.12.0 2.1.6-tf Using TensorFlow backend. Step 1 - Deciding on the network topology (not really considered optimization but is obviously very important) We will use the MNIST dataset which consists of grayscale images of handwritten digits (0-9) whose dimension is 28x28 pixels. Each pixel is 8 bits so its value ranges from 0 to 255. In [11]: #mnist = tf.keras.datasets.mnist mnist = keras . datasets . mnist ( x_train , y_train ),( x_test , y_test ) = mnist . load_data () x_train . shape , y_train . shape Out[11]: ((60000, 28, 28), (60000,)) Each label is a number between 0 and 9 In [12]: print ( y_train ) [5 0 4 ... 5 6 8] Let's look at some 10 of the images In [13]: plt . figure ( figsize = ( 10 , 10 )) for i in range ( 10 ): plt . subplot ( 5 , 5 , i + 1 ) plt . xticks ([]) plt . yticks ([]) plt . grid ( False ) plt . imshow ( x_train [ i ], cmap = plt . cm . binary ) plt . xlabel ( y_train [ i ]) In [14]: x_train [ 45 ] . shape x_train [ 45 , 15 : 20 , 15 : 20 ] Out[14]: array([[ 11, 198, 231, 41, 0], [ 82, 252, 204, 0, 0], [253, 253, 141, 0, 0], [252, 220, 36, 0, 0], [252, 96, 0, 0, 0]], dtype=uint8) In [15]: print ( f 'We have {x_train.shape[0]} train samples' ) print ( f 'We have {x_test.shape[0]} test samples' ) We have 60000 train samples We have 10000 test samples Preprocessing the data To run our NN we need to pre-process the data First we need to make the 2D image arrays into 1D (flatten them). We can either perform this by using array reshaping with numpy.reshape() or the keras ' method for this: a layer called tf.keras.layers.Flatten which transforms the format of the images from a 2d-array (of 28 by 28 pixels), to a 1D-array of 28 * 28 = 784 pixels. Then we need to normalize the pixel values (give them values between 0 and 1) using the following transformation: \\begin{align} x := \\dfrac{x - x_{min}}{x_{max} - x_{min}} \\textrm{} \\end{align} In our case $x_{min} = 0$ and $x_{max} = 255$ so the formula becomes simply $x := {x}/255$ In [16]: # normalize the data x_train , x_test = x_train / 255.0 , x_test / 255.0 In [17]: # reshape the data into 1D vectors x_train = x_train . reshape ( 60000 , 784 ) x_test = x_test . reshape ( 10000 , 784 ) num_classes = 10 In [18]: x_train . shape [ 1 ] Out[18]: 784 Now let's prepare our class vector (y) to a binary class matrix, e.g. for use with categorical_crossentropy. In [19]: # Convert class vectors to binary class matrices y_train = keras . utils . to_categorical ( y_train , num_classes ) y_test = keras . utils . to_categorical ( y_test , num_classes ) In [20]: y_train [ 0 ] Out[20]: array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32) Now we are ready to build the model! Step 2 - Adjusting the learning rate One of the most common optimization algorithm is Stochastic Gradient Descent (SGD). The hyperparameters that can be optimized in SGD are learning rate , momentum , decay and nesterov . Learning rate controls the weight at the end of each batch, and momentum controls how much to let the previous update influence the current weight update. Decay indicates the learning rate decay over each update, and nesterov takes the value True or False depending on if we want to apply Nesterov momentum. Typical values for those hyperparameters are lr=0.01, decay=1e-6, momentum=0.9, and nesterov=True. The learning rate hyperparameter goes into the optimizer function which we will see below. Let's implement a learning rate adaptation schedule in Keras . We'll start with SGD and a learning rate value of 0.1. We will then train the model for 40 epochs and set the decay argument to 0.002 (0.1/50). We also include a momentum value of 0.8 since that seems to work well when using an adaptive learning rate. In [21]: epochs = 60 learning_rate = 0.1 decay_rate = learning_rate / epochs momentum = 0.8 sgd = SGD ( lr = learning_rate , momentum = momentum , decay = decay_rate , nesterov = False ) In [22]: # build the model input_dim = x_train . shape [ 1 ] lr_model = Sequential () lr_model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) # fully-connected layer with 64 hidden units lr_model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) lr_model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) # compile the model lr_model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'acc' ]) In [23]: %%time # Fit the model batch_size = 28 lr_model_history = lr_model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 3s 43us/step - loss: 0.2856 - acc: 0.9072 - val_loss: 0.1419 - val_acc: 0.9559 Epoch 2/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.1043 - acc: 0.9684 - val_loss: 0.1052 - val_acc: 0.9663 Epoch 3/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0778 - acc: 0.9759 - val_loss: 0.0948 - val_acc: 0.9715 Epoch 4/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0652 - acc: 0.9798 - val_loss: 0.0866 - val_acc: 0.9728 Epoch 5/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0571 - acc: 0.9828 - val_loss: 0.0861 - val_acc: 0.9729 Epoch 6/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0516 - acc: 0.9843 - val_loss: 0.0837 - val_acc: 0.9741 Epoch 7/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0473 - acc: 0.9857 - val_loss: 0.0842 - val_acc: 0.9745 Epoch 8/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0439 - acc: 0.9870 - val_loss: 0.0858 - val_acc: 0.9725 Epoch 9/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0414 - acc: 0.9879 - val_loss: 0.0824 - val_acc: 0.9748 Epoch 10/60 60000/60000 [==============================] - 3s 42us/step - loss: 0.0392 - acc: 0.9889 - val_loss: 0.0820 - val_acc: 0.9750 Epoch 11/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0373 - acc: 0.9895 - val_loss: 0.0824 - val_acc: 0.9745 Epoch 12/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0355 - acc: 0.9903 - val_loss: 0.0823 - val_acc: 0.9741 Epoch 13/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0343 - acc: 0.9907 - val_loss: 0.0817 - val_acc: 0.9750 Epoch 14/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0330 - acc: 0.9912 - val_loss: 0.0812 - val_acc: 0.9754 Epoch 15/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0320 - acc: 0.9912 - val_loss: 0.0809 - val_acc: 0.9757 Epoch 16/60 60000/60000 [==============================] - 3s 44us/step - loss: 0.0310 - acc: 0.9917 - val_loss: 0.0815 - val_acc: 0.9761 Epoch 17/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0302 - acc: 0.9919 - val_loss: 0.0814 - val_acc: 0.9759 Epoch 18/60 60000/60000 [==============================] - 3s 46us/step - loss: 0.0292 - acc: 0.9924 - val_loss: 0.0815 - val_acc: 0.9755 Epoch 19/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0286 - acc: 0.9928 - val_loss: 0.0811 - val_acc: 0.9759 Epoch 20/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0279 - acc: 0.9929 - val_loss: 0.0808 - val_acc: 0.9759 Epoch 21/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0272 - acc: 0.9931 - val_loss: 0.0819 - val_acc: 0.9767 Epoch 22/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0267 - acc: 0.9933 - val_loss: 0.0820 - val_acc: 0.9753 Epoch 23/60 60000/60000 [==============================] - 3s 42us/step - loss: 0.0261 - acc: 0.9936 - val_loss: 0.0812 - val_acc: 0.9765 Epoch 24/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0256 - acc: 0.9935 - val_loss: 0.0821 - val_acc: 0.9759 Epoch 25/60 60000/60000 [==============================] - 3s 50us/step - loss: 0.0250 - acc: 0.9939 - val_loss: 0.0821 - val_acc: 0.9760 Epoch 26/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0246 - acc: 0.9939 - val_loss: 0.0822 - val_acc: 0.9755 Epoch 27/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0242 - acc: 0.9941 - val_loss: 0.0820 - val_acc: 0.9768 Epoch 28/60 60000/60000 [==============================] - 3s 49us/step - loss: 0.0238 - acc: 0.9941 - val_loss: 0.0825 - val_acc: 0.9761 Epoch 29/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0233 - acc: 0.9944 - val_loss: 0.0824 - val_acc: 0.9761 Epoch 30/60 60000/60000 [==============================] - 3s 46us/step - loss: 0.0231 - acc: 0.9946 - val_loss: 0.0830 - val_acc: 0.9760 Epoch 31/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0228 - acc: 0.9947 - val_loss: 0.0829 - val_acc: 0.9755 Epoch 32/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0224 - acc: 0.9947 - val_loss: 0.0829 - val_acc: 0.9760 Epoch 33/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0220 - acc: 0.9948 - val_loss: 0.0831 - val_acc: 0.9758 Epoch 34/60 60000/60000 [==============================] - 3s 51us/step - loss: 0.0218 - acc: 0.9949 - val_loss: 0.0827 - val_acc: 0.9754 Epoch 35/60 60000/60000 [==============================] - 3s 44us/step - loss: 0.0215 - acc: 0.9951 - val_loss: 0.0832 - val_acc: 0.9762 Epoch 36/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0213 - acc: 0.9952 - val_loss: 0.0833 - val_acc: 0.9759 Epoch 37/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0210 - acc: 0.9953 - val_loss: 0.0836 - val_acc: 0.9764 Epoch 38/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0208 - acc: 0.9952 - val_loss: 0.0836 - val_acc: 0.9758 Epoch 39/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0205 - acc: 0.9954 - val_loss: 0.0835 - val_acc: 0.9760 Epoch 40/60 60000/60000 [==============================] - 2s 38us/step - loss: 0.0203 - acc: 0.9955 - val_loss: 0.0838 - val_acc: 0.9761 Epoch 41/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0201 - acc: 0.9956 - val_loss: 0.0840 - val_acc: 0.9764 Epoch 42/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0198 - acc: 0.9957 - val_loss: 0.0841 - val_acc: 0.9761 Epoch 43/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0196 - acc: 0.9957 - val_loss: 0.0842 - val_acc: 0.9761 Epoch 44/60 60000/60000 [==============================] - 3s 43us/step - loss: 0.0194 - acc: 0.9958 - val_loss: 0.0840 - val_acc: 0.9760 Epoch 45/60 60000/60000 [==============================] - 2s 42us/step - loss: 0.0193 - acc: 0.9959 - val_loss: 0.0841 - val_acc: 0.9757 Epoch 46/60 60000/60000 [==============================] - 3s 42us/step - loss: 0.0190 - acc: 0.9958 - val_loss: 0.0848 - val_acc: 0.9760 Epoch 47/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0189 - acc: 0.9959 - val_loss: 0.0846 - val_acc: 0.9760 Epoch 48/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0187 - acc: 0.9961 - val_loss: 0.0846 - val_acc: 0.9764 Epoch 49/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0185 - acc: 0.9961 - val_loss: 0.0845 - val_acc: 0.9763 Epoch 50/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0184 - acc: 0.9963 - val_loss: 0.0846 - val_acc: 0.9761 Epoch 51/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0182 - acc: 0.9962 - val_loss: 0.0846 - val_acc: 0.9762 Epoch 52/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0181 - acc: 0.9963 - val_loss: 0.0849 - val_acc: 0.9761 Epoch 53/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0179 - acc: 0.9962 - val_loss: 0.0851 - val_acc: 0.9764 Epoch 54/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0177 - acc: 0.9964 - val_loss: 0.0852 - val_acc: 0.9768 Epoch 55/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0176 - acc: 0.9963 - val_loss: 0.0852 - val_acc: 0.9763 Epoch 56/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0175 - acc: 0.9965 - val_loss: 0.0854 - val_acc: 0.9763 Epoch 57/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0174 - acc: 0.9965 - val_loss: 0.0854 - val_acc: 0.9763 Epoch 58/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0172 - acc: 0.9965 - val_loss: 0.0855 - val_acc: 0.9763 Epoch 59/60 60000/60000 [==============================] - 2s 38us/step - loss: 0.0171 - acc: 0.9966 - val_loss: 0.0855 - val_acc: 0.9763 Epoch 60/60 60000/60000 [==============================] - 2s 38us/step - loss: 0.0170 - acc: 0.9967 - val_loss: 0.0853 - val_acc: 0.9757 CPU times: user 4min 27s, sys: 1min 1s, total: 5min 28s Wall time: 2min 32s In [24]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [26]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Exercise: Write a function that performs exponential learning rate decay using LearningRateScheduler $lr = lr0*e&#94;{(-kt)}$ t is the iteration number Step 3 - Choosing an optimizer and a loss function When constructing a model and using it to make our predictions, for example to assign label scores to images (\"cat\", \"plane\", etc), we want to measure our success or failure by defining a \"loss\" function (or objective function). The goal of optimization is to efficiently calculate the parameters/weights that minimize this loss function. keras provides various types of loss functions . Sometimes the \"loss\" function measures the \"distance\". We can define this \"distance\" between two data points in various ways suitable to the problem or dataset. Distance Euclidean Manhattan others such as Hamming which measures distances between strings, for example. The Hamming distance of \"carolin\" and \"cathrin\" is 3. Loss functions MSE (for regression) categorical cross-entropy (for classification) binary cross entropy (for classification) In [33]: # build the model input_dim = x_train . shape [ 1 ] model = Sequential () model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) # fully-connected layer with 64 hidden units #model.add(Dropout(0.5)) model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) #model.add(Dropout(0.5)) model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) In [34]: # defining the parameters for RMSprop (I used the keras defaults here) rms = RMSprop ( lr = 0.001 , rho = 0.9 , epsilon = None , decay = 0.0 ) model . compile ( loss = 'categorical_crossentropy' , optimizer = rms , metrics = [ 'acc' ]) Step 4 - Deciding on the batch size and number of epochs In [35]: %%time batch_size = 32 epochs = 20 model_history = model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/20 60000/60000 [==============================] - 3s 46us/step - loss: 0.3931 - acc: 0.8850 - val_loss: 0.2082 - val_acc: 0.9400 Epoch 2/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.1696 - acc: 0.9502 - val_loss: 0.1334 - val_acc: 0.9595 Epoch 3/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.1208 - acc: 0.9641 - val_loss: 0.1162 - val_acc: 0.9677 Epoch 4/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0995 - acc: 0.9710 - val_loss: 0.1068 - val_acc: 0.9712 Epoch 5/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0846 - acc: 0.9751 - val_loss: 0.1035 - val_acc: 0.9728 Epoch 6/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.0733 - acc: 0.9784 - val_loss: 0.1203 - val_acc: 0.9713 Epoch 7/20 60000/60000 [==============================] - 2s 42us/step - loss: 0.0660 - acc: 0.9807 - val_loss: 0.0993 - val_acc: 0.9735 Epoch 8/20 60000/60000 [==============================] - 3s 43us/step - loss: 0.0599 - acc: 0.9834 - val_loss: 0.1143 - val_acc: 0.9713 Epoch 9/20 60000/60000 [==============================] - 3s 46us/step - loss: 0.0533 - acc: 0.9851 - val_loss: 0.1217 - val_acc: 0.9695 Epoch 10/20 60000/60000 [==============================] - 3s 47us/step - loss: 0.0493 - acc: 0.9866 - val_loss: 0.1109 - val_acc: 0.9735 Epoch 11/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.0441 - acc: 0.9875 - val_loss: 0.1186 - val_acc: 0.9742 Epoch 12/20 60000/60000 [==============================] - 2s 41us/step - loss: 0.0422 - acc: 0.9883 - val_loss: 0.1222 - val_acc: 0.9725 Epoch 13/20 60000/60000 [==============================] - 2s 41us/step - loss: 0.0397 - acc: 0.9897 - val_loss: 0.1327 - val_acc: 0.9725 Epoch 14/20 60000/60000 [==============================] - 3s 43us/step - loss: 0.0359 - acc: 0.9905 - val_loss: 0.1365 - val_acc: 0.9724 Epoch 15/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.0342 - acc: 0.9910 - val_loss: 0.1445 - val_acc: 0.9748 Epoch 16/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0317 - acc: 0.9915 - val_loss: 0.1420 - val_acc: 0.9758 Epoch 17/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0303 - acc: 0.9920 - val_loss: 0.1534 - val_acc: 0.9740 Epoch 18/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0280 - acc: 0.9928 - val_loss: 0.1549 - val_acc: 0.9727 Epoch 19/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0263 - acc: 0.9938 - val_loss: 0.1691 - val_acc: 0.9731 Epoch 20/20 60000/60000 [==============================] - 3s 43us/step - loss: 0.0266 - acc: 0.9934 - val_loss: 0.1504 - val_acc: 0.9759 CPU times: user 1min 32s, sys: 20.9 s, total: 1min 53s Wall time: 50.7 s In [36]: from sklearn.metrics import r2_score as r2 score = model . evaluate ( x_test , y_test , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) print ( 'Test R2:' , r2 ( y_test , model . predict ( x_test ))) Test loss: 0.1503745241531124 Test accuracy: 0.9759 Test R2: 0.9542278387249276 In [37]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'acc' ]), 'r' , label = 'train_acc' ) ax . plot ( np . sqrt ( model_history . history [ 'val_acc' ]), 'b' , label = 'val_acc' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [38]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [39]: print ( model_history . history . keys ()) dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) Step 5 - Random restarts This method does not seem to have an implementation in keras . We will leave it as a home exercise! Hint: you can use keras.callbacks.LearningRateScheduler . Tuning the Hyperparameters using Cross Validation Now instead of trying different values by hand, we will use GridSearchCV from Scikit-Learn to try out several values for our hyperparameters and compare the results. To do cross-validation with keras we will use the wrappers for the Scikit-Learn API. They provide a way to use Sequential Keras models (single-input only) as part of your Scikit-Learn workflow. There are two wrappers available: keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params) , which implements the Scikit-Learn classifier interface, keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params) , which implements the Scikit-Learn regressor interface. In [41]: import numpy from sklearn.model_selection import GridSearchCV from keras.wrappers.scikit_learn import KerasClassifier Trying different weight initializations In [42]: # Function to create model, required for KerasClassifier def create_model ( init_mode = 'uniform' ): # define model model = Sequential () model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu , input_dim = 784 )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 10 , kernel_initializer = init_mode , activation = tf . nn . softmax )) # compile model model . compile ( loss = 'categorical_crossentropy' , optimizer = RMSprop (), metrics = [ 'accuracy' ]) return model In [43]: %%time seed = 7 numpy . random . seed ( seed ) batch_size = 128 epochs = 10 model_CV = KerasClassifier ( build_fn = create_model , epochs = epochs , batch_size = batch_size , verbose = 0 ) # define the grid search parameters init_mode = [ 'uniform' , 'lecun_uniform' , 'normal' , 'zero' , 'glorot_normal' , 'glorot_uniform' , 'he_normal' , 'he_uniform' ] param_grid = dict ( init_mode = init_mode ) grid = GridSearchCV ( estimator = model_CV , param_grid = param_grid , n_jobs =- 1 , cv = 3 ) grid_result = grid . fit ( x_train , y_train ) # summarize results print ( \"Best: %f using %s \" % ( grid_result . best_score_ , grid_result . best_params_ )) means = grid_result . cv_results_ [ 'mean_test_score' ] stds = grid_result . cv_results_ [ 'std_test_score' ] params = grid_result . cv_results_ [ 'params' ] for mean , stdev , param in zip ( means , stds , params ): print ( \" %f ( %f ) with: %r \" % ( mean , stdev , param )) Best: 0.948967 using {'init_mode': 'glorot_uniform'} 0.946117 (0.002852) with: {'init_mode': 'uniform'} 0.948400 (0.001192) with: {'init_mode': 'lecun_uniform'} 0.948117 (0.001310) with: {'init_mode': 'normal'} 0.112367 (0.002416) with: {'init_mode': 'zero'} 0.948367 (0.002593) with: {'init_mode': 'glorot_normal'} 0.948967 (0.002210) with: {'init_mode': 'glorot_uniform'} 0.947400 (0.002060) with: {'init_mode': 'he_normal'} 0.946983 (0.002908) with: {'init_mode': 'he_uniform'} CPU times: user 21 s, sys: 3.6 s, total: 24.6 s Wall time: 1min 36s Save Your Neural Network Model to JSON The Hierarchical Data Format (HDF5) is a data storage format for storing large arrays of data including values for the weights in a neural network. You can install HDF5 Python module: pip install h5py Keras gives you the ability to describe and save any model using the JSON format. In [ ]: from keras.models import model_from_json # serialize model to JSON model_json = model . to_json () with open ( \"model.json\" , \"w\" ) as json_file : json_file . write ( model_json ) # save weights to HDF5 model . save_weights ( \"model.h5\" ) print ( \"Model saved\" ) # when you want to retrieve the model: load json and create model json_file = open ( 'model.json' , 'r' ) saved_model = json_file . read () # close the file as good practice json_file . close () model_from_json = model_from_json ( saved_model ) # load weights into new model model_from_json . load_weights ( \"model.h5\" ) print ( \"Model loaded\" ) Exercise 1: Perform a GridSearch for Learning rate and number of epochs combined We will try various small standard learning rates, and momentum values from 0.1 to 0.9 in steps of 0.2. We want to include the number of epochs in an optimization as there is a dependency between the learning rate, the batch size, and the number of epochs. In [ ]: #your code here if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"pages","url":"pages/lab3/students/"},{"title":"Lab 5:","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 5: Convolutional Neural Networks Harvard University Spring 2019 Lab instructor: Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman Authors: Eleni Kaxiras, Pavlos Protopapas, Patrick Ohiomoba, and Davis Sontag In [ ]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Learning Goals In this lab we will look at Convolutional Neural Networks (CNNs), and their building blocks. By the end of this lab, you should: know how to put together the building blocks used in CNNs - such as convolutional layers and pooling layers - in keras with an example. have a good undertanding on how images, a common type of data for a CNN, are represented in the computer and how to think of them as arrays of numbers. be familiar with preprocessing images with keras and sckit-learn . use keras-viz to produce Saliency maps. learn best practices for configuring the hyperparameters of a CNN. run your first CNN and see the error rate. In [ ]: import matplotlib.pyplot as plt plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) import numpy as np from scipy.optimize import minimize import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras.preprocessing.image import ImageDataGenerator from keras.callbacks import LearningRateScheduler from keras.callbacks import History from keras import losses from keras.datasets import mnist from keras.utils import to_categorical from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) % matplotlib inline Prologue: keras-viz Visualization Toolkit keras-vis is a high-level toolkit for visualizing and debugging your trained keras neural net models. Currently supported visualizations include: Activation maximization Saliency maps Class activation maps All visualizations by default support N-dimensional image inputs. i.e., it generalizes to N-dim image inputs to your model. Compatible with both theano and tensorflow backends with 'channels_first', 'channels_last' data format. Read the documentation at https://raghakot.github.io/keras-vis.https://github.com/raghakot/keras-vis To install use pip install git+https://github.com/raghakot/keras-vis.git --upgrade SEAS JupyterHub Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class (accessible from the 'Jupyter' menu link in Canvas). These are AWS p2 instances with a GPU, 10GB of disk space, and 61 GB of RAM, for faster training for your networks. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE : The AWS platform is funded by SEAS and FAS for the purposes of the class. It is not running against your individual credit. You are not allowed to use it for purposes not related to this course. Help us keep this service: Make sure you stop your instance as soon as you do not need it. Part 1: Parts of a Convolutional Neural Net There are three types of layers in a Convolutional Neural Network: Convolutional Layers Pooling Layers. Dropout Layers. Fully Connected Layers. a. Convolutional Layers. Convolutional layers are comprised of filters and feature maps . The filters are essentially the neurons of the layer. They have the weights and produce the input for the next layer. The feature map is the output of one filter applied to the previous layer. The fundamental difference between a densely connected layer and a convolution layer is that dense layers learn global patterns in their input feature space (for example, for an MNIST digit, patterns involving all pixels), whereas convolution layers learn local patterns: in the case of images, patterns found in small 2D windows of the inputs called receptive fields . This key characteristic gives convnets two interesting properties: The patterns they learn are translation invariant . After learning a certain pattern in the lower-right corner of a picture, a convnet can recognize it anywhere: for example, in the upper-left corner. A densely connected network would have to learn the pattern anew if it appeared at a new location. This makes convnets data efficient when processing images (because the visual world is fundamentally translation invariant): they need fewer training samples to learn representations that have generalization power. They can learn spatial hierarchies of patterns . A first convolution layer will learn small local patterns such as edges, a second convolution layer will learn larger patterns made of the features of the first layers, and so on. This allows convnets to efficiently learn increasingly complex and abstract visual concepts (because the visual world is fundamentally spatially hierarchical). Convolutions operate over 3D tensors, called feature maps, with two spatial axes (height and width) as well as a depth axis (also called the channels axis). For an RGB image, the dimension of the depth axis is 3, because the image has three color channels: red, green, and blue. For a black-and-white picture, like the MNIST digits, the depth is 1 (levels of gray). The convolution operation extracts patches from its input feature map and applies the same transformation to all of these patches, producing an output feature map. This output feature map is still a 3D tensor: it has a width and a height. Its depth can be arbitrary, because the output depth is a parameter of the layer, and the different channels in that depth axis no longer stand for specific colors as in RGB input; rather, they stand for filters. Filters encode specific aspects of the input data: at a high level, a single filter could encode the concept \"presence of a face in the input,\" for instance. In the MNIST example that we will see, the first convolution layer takes a feature map of size (28, 28, 1) and outputs a feature map of size (26, 26, 32): it computes 32 filters over its input. Each of these 32 output channels contains a 26×26 grid of values, which is a response map of the filter over the input, indicating the response of that filter pattern at different locations in the input. Convolutions are defined by two key parameters: Size of the patches extracted from the inputs. These are typically 3×3 or 5×5 The number of filters computed by the convolution. Padding : One of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, In keras see convolutional layers keras.layers.Conv2D (filters, kernel_size, strides=(1, 1), padding='valid', activation=None, use_bias=True, kernel_initializer='glorot_uniform', data_format='channels_last', bias_initializer='zeros') How are the values in feature maps calculated? Exercise 1: Compute the operations by hand (assuming zero padding and same arrays for all channels) to produce the first element of the 4x4 feature map. How did we get the 4x4 output size? Write this Conv layer in keras -- your answer here b. Pooling Layers. Pooling layers are also comprised of filters and feature maps. Let's say the pooling layer has a 2x2 receptive field and a stride of 2. This stride results in feature maps that are one half the size of the input feature maps. We can use a max() operation for each receptive field. In keras see pooling layers keras.layers.MaxPooling2D (pool_size=(2, 2), strides=None, padding='valid', data_format=None) c. Dropout Layers. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. In keras see Dropout layers keras.layers.Dropout(rate, seed=None) rate: float between 0 and 1. Fraction of the input units to drop. seed: A Python integer to use as random seed. References Dropout: A Simple Way to Prevent Neural Networks from Overfitting d. Fully Connected Layers. A fully connected layer flattens the square feature map into a vector. Then we can use a sigmoid or softmax activation function to output probabilities of classes. In keras see FC layers keras.layers.Dense (units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros') IT'S ALL ABOUT THE HYPERPARAMETERS! stride size of filter number of filters poolsize Part 2: Preprocessing the data Taking a look at how images are represented in a computer using a photo of a Picasso sculpture In [ ]: img = plt . imread ( 'data/picasso.png' ) img . shape In [ ]: img [ 1 ,:, 1 ] In [ ]: print ( type ( img [ 50 ][ 0 ][ 0 ])) In [ ]: # let's see the image imgplot = plt . imshow ( img ) Visualizing the channels In [ ]: R_img = img [:,:, 0 ] G_img = img [:,:, 1 ] B_img = img [:,:, 2 ] plt . subplot ( 221 ) plt . imshow ( R_img , cmap = plt . cm . Reds ) plt . subplot ( 222 ) plt . imshow ( G_img , cmap = plt . cm . Greens ) plt . subplot ( 223 ) plt . imshow ( B_img , cmap = plt . cm . Blues ) plt . subplot ( 224 ) plt . imshow ( img ) plt . show () More on preprocessing data below! If you want to learn more: Image Processing with Python and Scipy Part 3: Putting the Parts together to make a small ConvNet Model Let's put all the parts together to make a convnet for classifying our good old MNIST digits. In [ ]: # Load data and preprocess ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # load MNIST data train_images . shape In [ ]: train_images . max (), train_images . min () In [ ]: train_images = train_images . reshape (( 60000 , 28 , 28 , 1 )) # Reshape to get third dimension train_images = train_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 test_images = test_images . reshape (( 10000 , 28 , 28 , 1 )) # Reshape to get third dimension test_images = test_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 # Convert labels to categorical data train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) In [ ]: mnist_cnn_model = models . Sequential () # Create sequential model # Add network layers mnist_cnn_model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 28 , 28 , 1 ))) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely connected classifier network like those you're already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers on top. In [ ]: mnist_cnn_model . add ( layers . Flatten ()) mnist_cnn_model . add ( layers . Dense ( 64 , activation = 'relu' )) mnist_cnn_model . add ( layers . Dense ( 10 , activation = 'softmax' )) mnist_cnn_model . summary () In [ ]: # Compile model mnist_cnn_model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # Fit the model mnist_cnn_model . fit ( train_images , train_labels , epochs = 5 , batch_size = 64 ) # Evaluate the model on the test data: test_loss , test_acc = mnist_cnn_model . evaluate ( test_images , test_labels ) test_acc A densely connected network (MLP) running MNIST usually has a test accuracy of 97.8%, whereas our basic convnet has a test accuracy of 99.03%: we decreased the error rate by 68% (relative) with only 5 epochs. Not bad! But why does this simple convnet work so well, compared to a densely connected model? The answer is above on how convolutional layers work! Data Preprocessing : Meet the ImageDataGenerator class in keras (docs) The MNIST and other pre-loaded dataset are formatted in a way that is almost ready for feeding into the model. What about plain images? They should be formatted into appropriately preprocessed floating-point tensors before being fed into the network. The Dogs vs. Cats dataset that you'll use isn't packaged with Keras. It was made available by Kaggle as part of a computer-vision competition in late 2013, back when convnets weren't mainstream. The data has been downloaded for you from https://www.kaggle.com/c/dogs-vs-cats/data The pictures are medium-resolution color JPEGs. In [ ]: # TODO: set your base dir to your correct local location base_dir = 'data/cats_and_dogs_small' import os , shutil # Set up directory information train_dir = os . path . join ( base_dir , 'train' ) validation_dir = os . path . join ( base_dir , 'validation' ) test_dir = os . path . join ( base_dir , 'test' ) train_cats_dir = os . path . join ( train_dir , 'cats' ) train_dogs_dir = os . path . join ( train_dir , 'dogs' ) validation_cats_dir = os . path . join ( validation_dir , 'cats' ) validation_dogs_dir = os . path . join ( validation_dir , 'dogs' ) test_cats_dir = os . path . join ( test_dir , 'cats' ) test_dogs_dir = os . path . join ( test_dir , 'dogs' ) print ( 'total training cat images:' , len ( os . listdir ( train_cats_dir ))) print ( 'total training dog images:' , len ( os . listdir ( train_dogs_dir ))) print ( 'total validation cat images:' , len ( os . listdir ( validation_cats_dir ))) print ( 'total validation dog images:' , len ( os . listdir ( validation_dogs_dir ))) print ( 'total test cat images:' , len ( os . listdir ( test_cats_dir ))) print ( 'total test dog images:' , len ( os . listdir ( test_dogs_dir ))) So you do indeed have 2,000 training images, 1,000 validation images, and 1,000 test images. Each split contains the same number of samples from each class: this is a balanced binary-classification problem, which means classification accuracy will be an appropriate measure of success. Building the network In [ ]: from keras import layers from keras import models model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () For the compilation step, you'll go with the RMSprop optimizer. Because you ended the network with a single sigmoid unit, you'll use binary crossentropy as the loss. In [ ]: from keras import optimizers model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) The steps for getting it into the network are roughly as follows: Read the picture files. Decode the JPEG content to RGB grids of pixels. Convert these into floating-point tensors. Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values). It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically with the class ImageDataGenerator , which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors. This is what you'll use here. In [ ]: from keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator ( rescale = 1. / 255 ) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) Let's look at the output of one of these generators: it yields batches of 150×150 RGB images (shape (20, 150, 150, 3)) and binary labels (shape (20,)). There are 20 samples in each batch (the batch size). Note that the generator yields these batches indefinitely: it loops endlessly over the images in the target folder. For this reason, you need to break the iteration loop at some point: In [ ]: for data_batch , labels_batch in train_generator : print ( 'data batch shape:' , data_batch . shape ) print ( 'labels batch shape:' , labels_batch . shape ) break Let's fit the model to the data using the generator. You do so using the .fit_generator method, the equivalent of .fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely, like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring an epoch over. This is the role of the steps_per_epoch argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps - the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples. When using fit_generator, you can pass a validation_data argument, much as with the fit method. It's important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation In [ ]: history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 30 validation_data = validation_generator , validation_steps = 50 ) # It's good practice to always save your models after training. model . save ( 'cats_and_dogs_small_1.h5' ) Let's plot the accuracy of the model over the training and validation data during training: In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Let's try data augmentation In [ ]: datagen = ImageDataGenerator ( rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True , fill_mode = 'nearest' ) These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over this code: rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures. width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally. shear_range is for randomly applying shearing transformations. zoom_range is for randomly zooming inside pictures. horizontal_flip is for randomly flipping half the images horizontally—relevant when there are no assumptions of - horizontal asymmetry (for example, real-world pictures). fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift. Let's look at the augmented images In [ ]: from keras.preprocessing import image fnames = [ os . path . join ( train_dogs_dir , fname ) for fname in os . listdir ( train_dogs_dir )] img_path = fnames [ 3 ] # Chooses one image to augment img = image . load_img ( img_path , target_size = ( 150 , 150 )) # Reads the image and resizes it x = image . img_to_array ( img ) # Converts it to a Numpy array with shape (150, 150, 3) x = x . reshape (( 1 ,) + x . shape ) # Reshapes it to (1, 150, 150, 3) i = 0 for batch in datagen . flow ( x , batch_size = 1 ): plt . figure ( i ) imgplot = plt . imshow ( image . array_to_img ( batch [ 0 ])) i += 1 if i % 4 == 0 : break plt . show () If you train a new network using this data-augmentation configuration, the network will never see the same input twice. But the inputs it sees are still heavily intercorrelated, because they come from a small number of original images—you can't produce new information, you can only remix existing information. As such, this may not be enough to completely get rid of overfitting. To further fight overfitting, you'll also add a Dropout layer to your model right before the densely connected classifier. In [ ]: model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) In [ ]: # Let's train the network using data augmentation and dropout. train_datagen = ImageDataGenerator ( rescale = 1. / 255 , rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ,) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) # Note that the validation data shouldn't be augmented! train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 100 validation_data = validation_generator , validation_steps = 50 ) model . save ( 'cats_and_dogs_small_2.h5' ) And let's plot the results again. Thanks to data augmentation and dropout, you're no longer overfitting: the training curves are closely tracking the validation curves. You now reach an accuracy of 82%, a 15% relative improvement over the non-regularized model. (Note: these numbers are for 100 epochs..) In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) By using regularization techniques even further, and by tuning the network's parameters (such as the number of filters per convolution layer, or the number of layers in the network), you may be able to get an even better accuracy, likely up to 86% or 87%. But it would prove difficult to go any higher just by training your own convnet from scratch, because you have so little data to work with. As a next step to improve your accuracy on this problem, you'll have to use a pretrained model. Part 4: keras viz toolkit https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb In [ ]: class_idx = 0 indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] # pick some random input from here. idx = indices [ 0 ] # Lets sanity check the picked image. from matplotlib import pyplot as plt % matplotlib inline plt . rcParams [ 'figure.figsize' ] = ( 18 , 6 ) plt . imshow ( test_images [ idx ][ ... , 0 ]) In [ ]: input_shape = ( 28 , 28 , 1 ) num_classes = 10 batch_size = 128 epochs = 5 model = Sequential () model . add ( layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ), activation = 'relu' , input_shape = input_shape )) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D ( pool_size = ( 2 , 2 ))) model . add ( layers . Dropout ( 0.25 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 128 , activation = 'relu' )) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( num_classes , activation = 'softmax' , name = 'preds' )) model . compile ( loss = keras . losses . categorical_crossentropy , optimizer = keras . optimizers . Adam (), metrics = [ 'accuracy' ]) model . fit ( train_images , train_labels , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( test_images , test_labels )) score = model . evaluate ( test_images , test_labels , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) In [ ]: from vis.visualization import visualize_saliency from vis.utils import utils from keras import activations # Utility to search for layer index by name. # Alternatively we can specify this as -1 since it corresponds to the last layer. layer_idx = utils . find_layer_idx ( model , 'preds' ) In [ ]: plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) from vis.visualization import visualize_cam import warnings warnings . filterwarnings ( 'ignore' ) # This corresponds to the Dense linear layer. for class_idx in np . arange ( 10 ): indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] idx = indices [ 0 ] f , ax = plt . subplots ( 1 , 4 ) ax [ 0 ] . imshow ( test_images [ idx ][ ... , 0 ]) for i , modifier in enumerate ([ None , 'guided' , 'relu' ]): grads = visualize_cam ( model , layer_idx , filter_indices = class_idx , seed_input = test_images [ idx ], backprop_modifier = modifier ) if modifier is None : modifier = 'vanilla' ax [ i + 1 ] . set_title ( modifier ) ax [ i + 1 ] . imshow ( grads , cmap = 'jet' ) References and Acknowledgements The cats and dogs part of this lab is based on the book Deep Learning with Python, Chapter 5 written by the Francois Chollet, the author of Keras. It is a very practical introduction to Deep Learning. It is appropriate for those with some Python knowledge who want to start with machine learning. The saliency maps are from https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab5/student/"},{"title":"Advanced Section 1: Optimization/Dropout","text":"Slides PDF Lecture notes PDF","tags":"A-sections","url":"a-sections/a-section1/"},{"title":"Lecture 6: NN Optimization","text":"Slides Lecture 6 PDF Lecture 6 PPTX Associated Materials Labs Lab3 Notebook Advanced Sections Advanced Section 1 Slides PDF Advanced Section 1 Notes PDF Advanced Section 2 Optimal Transport notes slides PDF Advanced Section 2 Optimal Transport notes PDF Advanced Section 2 Intro to optimization Notes PDF","tags":"lectures","url":"lectures/lecture6/"},{"title":"Lecture 5: Review of NN from 109A","text":"Slides Lecture 5 PDF Lecture 5 PPTX Associated Materials Labs Lab3 Notebook","tags":"lectures","url":"lectures/lecture5/"},{"title":"Lab 2: Smooths and GAMs","text":"Lab 2 Notebooks Lab2 Smooths and GAMs Lab2 Smooths and GAMs with solutions","tags":"labs","url":"labs/lab2/"},{"title":"Lab 2: Smooths and GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models Harvard University Spring 2019 Instructors: Mark Glickman and Pavlos Protopapas Lab Instructors: Will Claybaugh Contributors: Paul Tyklin and Will Claybaugh In [ ]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Learning Goals The main goal of this lab is to get familiar with calling R functions within Python. Along the way, we'll learn about the \"formula\" interface to statsmodels, which gives an intuitive way of specifying regression models, and we'll review the different approaches to fitting curves. Key Skills: Importing (base) R functions Importing R library functions Populating vectors R understands Populating dataframes R understands Populating formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation In [ ]: import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Linear/Polynomial Regression (Python, Review) Hopefully, you remember working with Statsmodels during 109a Reading data and (some) exploring in Pandas: In [ ]: diab = pd . read_csv ( \"data/diabetes.csv\" ) print ( \"\"\" # Variables are: # subject: subject ID number # age: age diagnosed with diabetes # acidity: a measure of acidity called base deficit # y: natural log of serum C-peptide concentration # # Original source is Sockett et al. (1987) # mentioned in Hastie and Tibshirani's book # \"Generalized Additive Models\". \"\"\" ) display ( diab . head ()) display ( diab . dtypes ) display ( diab . describe ()) Plotting with matplotlib: In [ ]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear regression with statsmodels. Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. from PolynomialFeatures). Now, Statsmodels' formula interface can help build the target value and design matrix for you. In [ ]: #Using statsmodels import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Build a data frame to predict values on (sometimes this is just the test or validation set) Very useful for making pretty plots of the model predcitions -- predict for TONS of values, not just whatever's in the training set In [ ]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [ ]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Plot the model and error bars In [ ]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Discussion What are the dark error bars? What are the light error bars? Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars Route1: Build a design df with a column for each of age , age**2 , age**3 Route2: Just edit the formula Answers : 1. In [ ]: # your code here In [ ]: fit2_lm = sm . ols ( formula = \"y ~ age + np.power(age, 2) + np.power(age, 3)\" , data = diab ) . fit () poly_predictions = fit2_lm . get_prediction ( predict_df ) . summary_frame () poly_predictions . head () 2. In [ ]: # your code here In [ ]: ax2 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares cubic fit\" ) ax2 . set_xlabel ( \"Age at Diagnosis\" ) ax2 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean' ], color = \"green\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax2 . plot ( predict_df . age , poly_predictions [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Linear/Polynomial Regression, but make it R This is the meat of the lab. After this section we'll know everything we need to in order to work with R models. The rest of the lab is just applying these concepts to run particular models. This section therefore is your 'cheat sheet' for working in R. What we need to know: Importing (base) R functions Importing R Library functions Populating vectors R understands Populating DataFrames R understands Populating Formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation Importing R functions In [ ]: # if you're on JupyterHub you may need to specify the path to R #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2.robjects as robjects In [ ]: r_lm = robjects . r [ \"lm\" ] r_predict = robjects . r [ \"predict\" ] #r_plot = robjects.r[\"plot\"] # more on plotting later #lm() and predict() are two of the most common functions we'll use Importing R libraries In [ ]: from rpy2.robjects.packages import importr #r_cluster = importr('cluster') #r_cluster.pam; Populating vectors R understands In [ ]: r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) # What happens if we pass the wrong type? # How does r_age display? # How does r_age print? Populating Data Frames R understands In [ ]: diab_r = robjects . DataFrame ({ \"y\" : r_y , \"age\" : r_age }) # How does diab_r display? # How does diab_r print? Populating formulas R understands In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) simple_formula . environment [ \"y\" ] = r_y #populate the formula's .environment, so it knows what 'y' and 'age' refer to simple_formula . environment [ \"age\" ] = r_age Running Models in R In [ ]: diab_lm = r_lm ( formula = simple_formula ) # the formula object is storing all the needed variables In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) # reset the formula diab_lm = r_lm ( formula = simple_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe Getting results back to Python In [ ]: diab_lm #the result is already 'in' python, but it's a special object In [ ]: print ( diab_lm . names ) # view all names In [ ]: diab_lm [ 0 ] #grab the first element In [ ]: diab_lm . rx2 ( \"coefficients\" ) #use rx2 to get elements by name! In [ ]: np . array ( diab_lm . rx2 ( \"coefficients\" )) #r vectors can be converted to numpy (but rarely needed) Getting Predictions In [ ]: # make a df to predict on (might just be the validation or test dataframe) predict_df = robjects . DataFrame ({ \"age\" : robjects . FloatVector ( np . linspace ( 0 , 16 , 100 ))}) # call R's predict() function, passing the model and the data predictions = r_predict ( diab_lm , predict_df ) In [ ]: x_vals = predict_df . rx2 ( \"age\" ) In [ ]: ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); #plt still works with r vectors as input! Plotting in R In [ ]: % load_ext rpy2.ipython The above turns on the %R \"magic\" R's plot() command responds differently based on what you hand to it; Different models get different plots! For any specific model search for plot.modelname. E.g. for a GAM model, search plot.gam for any details of plotting a GAM model The %R \"magic\" runs R code in 'notebook' mode, so figures display nicely Ahead of the plot( ) code we pass in the variables R needs to know about ( -i is for \"input\") In [ ]: % R -i diab_lm plot(diab_lm); Reading R's documentation The documentation for the lm() funciton is here , and a prettier version (same content) is here . When googling, perfer rdocumentation.org when possible. Sections: Usage : gives the function signature, including all optional arguments Arguments : What each function input controls Details : additional info on what the funciton does and how arguments interact. Often the right place to start reading Value : the structure of the object returned by the function Refferences : The relevant academic papers See Also : other functions of interest Exercise 2 Add confidence intervals calculated in R to the linear regression plot above. Use the interval= argument to r_predict() (documentation here ). You will have to work with a matrix returned by R. Fit a 5th degree polynomial to the diabetes data in R. Search the web for an easier method than writing out a formula with all 5 polynomial terms. Answers 1. In [ ]: # your code here In [ ]: CI_matrix = np . array ( r_predict ( diab_lm , predict_df , interval = \"confidence\" )) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , CI_matrix [:, 0 ], label = \"prediction\" ) ax . plot ( x_vals , CI_matrix [:, 1 ], label = \"95% CI\" , c = 'g' ) ax . plot ( x_vals , CI_matrix [:, 2 ], label = \"95% CI\" , c = 'g' ) plt . legend (); 2. In [ ]: # your code here In [ ]: ploy5_formula = robjects . Formula ( \"y~poly(age,5)\" ) # reset the formula diab5_lm = r_lm ( formula = ploy5_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe predictions = r_predict ( diab5_lm , predict_df , interval = \"confidence\" ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); Lowess Smoothing Lowess Smoothing is implemented in both Python and R. We'll use it as another example as we transition languages. Discussion What is lowess smoothing? Which 109a models is it related to? How explainable is lowess? What are the tunable parameters? In Python In [ ]: from statsmodels.nonparametric.smoothers_lowess import lowess as lowess ss1 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.15 ) ss2 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.25 ) ss3 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.7 ) ss4 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 1 ) In [ ]: ss1 [: 10 ,:] # we get back simple a smoothed y value for each x value in the data Notice the clean code to plot different models. We'll see even cleaner code in a minute In [ ]: for cur_model , cur_frac in zip ([ ss1 , ss2 , ss3 , ss4 ],[ 0.15 , 0.25 , 0.7 , 1 ]): ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model [:, 0 ], cur_model [:, 1 ], color = \"blue\" ) plt . show () Discussion Which model has high variance, which has high bias? What makes a model high variance or high bias? In R We need to: Import the loess function Send data over to R Call the function and get results In [ ]: r_loess = robjects . r [ 'loess.smooth' ] #extract R function r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) ss1_r = r_loess ( r_age , r_y , span = 0.15 , degree = 1 ) In [ ]: ss1_r #again, a smoothed y value for each x value in the data Exercise 3 Predict the output of ss1_r[0] ss1_r.rx2(\"y\") 1. your answer here 2. your answer here Varying span Next, some extremely clean code to fit and plot models with various parameter settings. (Though the zip() method seen earlier is great when e.g. the label and the parameter differ) In [ ]: for cur_frac in [ 0.15 , 0.25 , 0.7 , 1 ]: cur_smooth = r_loess ( r_age , r_y , span = cur_frac ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_smooth [ 0 ], cur_smooth [ 1 ], color = \"blue\" ) plt . show () Discussion Mark wasn't kidding; the Python and R results differ for frac=.15. Thoughts? Why isn't the bottom plot a straight line? We're using 100% of the data in each window... Smoothing Splines From this point forward, we're working with R functions; these models aren't (well) supported in Python. For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point Discussion Any idea why the winner is cubic? How interpretable is this model? What are the tunable parameters? In [ ]: r_smooth_spline = robjects . r [ 'smooth.spline' ] #extract R function # run smoothing function spline1 = r_smooth_spline ( r_age , r_y , spar = 0 ) Exercise 4 We actually set the spar parameter, a scale-free value that translates to a $\\lambda$ through a complex expression. Inspect the 'spline1' result and extract the implied value of $\\lambda$ Working from the fitting/plotting loop examples above, produce a plot like the one below for spar = [0,.5,.9,2], including axes labels and title. 1. In [ ]: # your answer here In [ ]: lambda1 = spline1 . rx2 ( \"lambda\" ) 2. In [ ]: # your answer here In [ ]: for cur_spar in [ 0 , 0.5 , 0.9 , 2 ]: cur_model = r_smooth_spline ( r_age , r_y , spar = cur_spar ) cur_lambda = cur_model . rx2 ( \"lambda\" )[ 0 ] ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"$\\lambda=$\" + str ( cur_lambda )) #can use TeX style in labels ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model . rx2 ( \"x\" ), cur_model . rx2 ( \"y\" ), color = \"darkgreen\" ) plt . show () CV R's smooth_spline funciton has built-in CV to find a good lambda. See package docs . In [ ]: spline_cv = r_smooth_spline ( r_age , r_y , cv = True ) lambda_cv = spline_cv . rx2 ( \"lambda\" )[ 0 ] ax19 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"smoothing spline with $\\lambda=$\" + str ( np . round ( lambda_cv , 4 )) + \", chosen by cross-validation\" ) ax19 . set_xlabel ( \"Age at Diagnosis\" ) ax19 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax19 . plot ( spline_cv . rx2 ( \"x\" ), spline_cv . rx2 ( \"y\" ), color = \"darkgreen\" ); Discussion Does the selected model look reasonable? How would you describe the effect of age at diagnosis on C_peptide concentration? What are the costs/benefits of the (fancy) spline model, relative to the linear regression we fit above? Natural & Basis Splines Here, we take a step backward on model complexity, but a step forward in coding complexity. We'll be working with R's formula interface again, so we will need to populate Formulas and DataFrames. Discussion In what way are Natural and Basis splines less complex than the splines we were just working with? What makes a spline 'natural'? What makes a spline 'basis'? What are the tuning parameters? In [ ]: #We will now work with a new dataset, called GAGurine. #The dataset description (from the R package MASS) is below: #Data were collected on the concentration of a chemical GAG # in the urine of 314 children aged from zero to seventeen years. # The aim of the study was to produce a chart to help a paediatrican # to assess if a child's GAG concentration is ‘normal'. #The variables are: # Age: age of child in years. # GAG: concentration of GAG (the units have been lost). In [ ]: GAGurine = pd . read_csv ( \"data/GAGurine.csv\" ) display ( GAGurine . head ()) ax31 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'black' , title = \"GAG in urine of children\" ) ax31 . set_xlabel ( \"Age\" ); ax31 . set_ylabel ( \"GAG\" ); Standard stuff: import function, convert variables to R format, call function In [ ]: from rpy2.robjects.packages import importr r_splines = importr ( 'splines' ) # populate R variables r_gag = robjects . FloatVector ( GAGurine [ 'GAG' ] . values ) r_age = robjects . FloatVector ( GAGurine [ 'Age' ] . values ) r_quarts = robjects . FloatVector ( np . quantile ( r_age ,[ . 25 , . 5 , . 75 ])) #woah, numpy functions run on R objects! What happens when we call the ns or bs functions from r_splines? In [ ]: ns_design = r_splines . ns ( r_age , knots = r_quarts ) bs_design = r_splines . bs ( r_age , knots = r_quarts ) In [ ]: print ( ns_design ) ns and bs return design matrices, not model objects! That's because they're meant to work with lm 's formula interface. To get a model object we populate a formula including ns( , ) and fit to data In [ ]: r_lm = robjects . r [ 'lm' ] r_predict = robjects . r [ 'predict' ] # populate the formula ns_formula = robjects . Formula ( \"Gag ~ ns(Age, knots=r_quarts)\" ) ns_formula . environment [ 'Gag' ] = r_gag ns_formula . environment [ 'Age' ] = r_age ns_formula . environment [ 'r_quarts' ] = r_quarts # fit the model ns_model = r_lm ( ns_formula ) Predict like usual: build a dataframe to predict on and call predict() In [ ]: # predict predict_frame = robjects . DataFrame ({ \"Age\" : robjects . FloatVector ( np . linspace ( 0 , 20 , 100 ))}) ns_out = r_predict ( ns_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" ]); Exercise 5 Fit a basis spline model with the same knots, and add it to the plot above Fit a basis spline with 8 knots placed at [2,4,6...14,16] and add it to the plot above Answers: 1. In [ ]: # your answer here In [ ]: bs_formula = robjects . Formula ( \"Gag ~ bs(Age, knots=r_quarts)\" ) bs_formula . environment [ 'Gag' ] = r_gag bs_formula . environment [ 'Age' ] = r_age bs_formula . environment [ 'r_quarts' ] = r_quarts bs_model = r_lm ( bs_formula ) bs_out = r_predict ( bs_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), bs_out , color = 'blue' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" , \"B-spline, knots at quartiles\" ]); 2. In [ ]: # your answer here In [ ]: overfit_formula = robjects . Formula ( \"Gag ~ bs(Age, knots=r_quarts)\" ) overfit_formula . environment [ 'Gag' ] = r_gag overfit_formula . environment [ 'Age' ] = r_age overfit_formula . environment [ 'r_quarts' ] = robjects . FloatVector ( np . array ([ 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 ])) overfit_model = r_lm ( overfit_formula ) overfit_out = r_predict ( overfit_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), bs_out , color = 'blue' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), overfit_out , color = 'green' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" , \"B-spline, knots at quartiles\" , \"B-spline, lots of knots\" ]); In [ ]: #%R -i overfit_model plot(overfit_model) # we'd get the same diagnostic plot we get from an lm model GAMs We come, at last, to our most advanced model. The coding here isn't any more complex than we've done before, though the behind-the-scenes is awesome. First, let's get our (multivariate!) data In [ ]: kyphosis = pd . read_csv ( \"data/kyphosis.csv\" ) print ( \"\"\" # kyphosis - wherther a particular deformation was present post-operation # age - patient's age in months # number - the number of vertebrae involved in the operation # start - the number of the topmost vertebrae operated on \"\"\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) In [ ]: #If there are errors about missing R packages, run the code below: #r_utils = importr('utils') #r_utils.install_packages('codetools') #r_utils.install_packages('gam') To fit a GAM, we Import the gam library Populate a formula including s( ) on variables we want to fit smooths for Call gam(formula, family= ) where family is a string naming a probability distribution, chosen based on how the response variable is thought to occur. Rough family guidelines: Response is binary or \"N occurances out of M tries\", e.g. number of lab rats (out of 10) developing disease: chooose \"binomial\" Response is a count with no logical upper bound, e.g. number of ice creams sold: choose \"poisson\" Response is real, with normally-distributed noise, e.g. person's height: choose \"gaussian\" (the default) In [ ]: #There is a Python library in development for using GAMs (https://github.com/dswah/pyGAM) # but it is not yet as comprehensive as the R GAM library, which we will use here instead. # R also has the mgcv library, which implements some more advanced/flexible fitting methods r_gam_lib = importr ( 'gam' ) r_gam = r_gam_lib . gam r_kyph = robjects . FactorVector ( kyphosis [[ \"Kyphosis\" ]] . values ) r_Age = robjects . FloatVector ( kyphosis [[ \"Age\" ]] . values ) r_Number = robjects . FloatVector ( kyphosis [[ \"Number\" ]] . values ) r_Start = robjects . FloatVector ( kyphosis [[ \"Start\" ]] . values ) kyph1_fmla = robjects . Formula ( \"Kyphosis ~ s(Age) + s(Number) + s(Start)\" ) kyph1_fmla . environment [ 'Kyphosis' ] = r_kyph kyph1_fmla . environment [ 'Age' ] = r_Age kyph1_fmla . environment [ 'Number' ] = r_Number kyph1_fmla . environment [ 'Start' ] = r_Start kyph1_gam = r_gam ( kyph1_fmla , family = \"binomial\" ) The fitted gam model has a lot of interesting data within it In [ ]: print ( kyph1_gam . names ) Remember plotting? Calling R's plot() on a gam model is the easiest way to view the fitted splines In [ ]: % R -i kyph1_gam plot(kyph1_gam, residuals=TRUE,se=TRUE, scale=20); Prediction works like normal (build a data frame to predict on, if you don't already have one, and call predict() ). However, predict always reports the sum of the individual variable effects. If family is non-default this can be different from the actual prediction for that point. For instance, we're doing a 'logistic regression' so the raw prediction is log odds, but we can get probability by using in predict(..., type=\"response\") In [ ]: kyph_new = robjects . DataFrame ({ 'Age' : robjects . IntVector (( 84 , 85 , 86 )), 'Start' : robjects . IntVector (( 5 , 3 , 1 )), 'Number' : robjects . IntVector (( 1 , 6 , 10 ))}) print ( \"Raw response (so, Log odds):\" ) display ( r_predict ( kyph1_gam , kyph_new )) print ( \"Scaled response (so, probabilty of kyphosis):\" ) display ( r_predict ( kyph1_gam , kyph_new , type = \"response\" )) Discussion Exercise 6 What lambda did we use? What is the model telling us about the effects of age, starting vertebrae, and number of vertebae operated on If we fit a logistic regression instead, which variables might want quadratic terms. What is the cost and benefit of a logistic regression model versus a GAM? Critique the model: What is it assuming? Are the assumptions reasonable Are we using the right data? Does the model's story about the world make sense? Appendix GAMs and smoothing splines support hypothesis tets to compare models. (We can always compare models via out-of-sample prediction quality (i.e. performance on a validation set), but statistical ideas like hypothesis tests yet information criteria allow us to use all data for training and still compare the quality of model A to model B) In [ ]: r_anova = robjects . r [ \"anova\" ] kyph0_fmla = robjects . Formula ( \"Kyphosis~1\" ) kyph0_fmla . environment [ 'Kyphosis' ] = r_kyph kyph0_gam = r_gam ( kyph0_fmla , family = \"binomial\" ) print ( r_anova ( kyph0_gam , kyph1_gam , test = \"Chi\" )) Explicitly joining spline functions In [ ]: def h ( x , xi , pow_arg ): #pow is a reserved keyword in Python if ( x > xi ): return pow (( x - xi ), pow_arg ) else : return 0 h = np . vectorize ( h , otypes = [ np . float ]) #default behavior is to return ints, which gives incorrect answer #also, vectorize does not play nicely with default arguments, so better to set directly (e.g., pow_arg=1) In [ ]: xvals = np . arange ( 0 , 10.1 , 0.1 ) ax20 = plt . plot ( xvals , h ( xvals , 4 , 1 ), color = \"red\" ) _ = plt . title ( \"Truncated linear basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+$\" ) #note the use of TeX in the label In [ ]: ax21 = plt . plot ( xvals , h ( xvals , 4 , 3 ), color = \"red\" ) _ = plt . title ( \"Truncated cubic basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+&#94;3$\" ) In [ ]: ax22 = plt . plot ( xvals , 2 + xvals + 3 * h ( xvals , 2 , 1 ) - 4 * h ( xvals , 5 , 1 ) + 0.5 * h ( xvals , 8 , 1 ), color = \"red\" ) _ = plt . title ( \"Piecewise linear spline with knots at x=2, 5, and 8\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) Comparing splines to the (noisy) model that generated them. In [ ]: x = np . arange ( 0.1 , 10 , 9.9 / 100 ) from scipy.stats import norm #ppf (percent point function) is the rather unusual name for #the quantile or inverse CDF function in SciPy y = norm . ppf ( x / 10 ) + np . random . normal ( 0 , 0.4 , 100 ) ax23 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,2,1)+h(x,5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax24 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3.5,1)+h(x,5,1)+h(x,6.5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax25 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3,1)+h(x,4,1)+h(x,5,1)+h(x,6,1)+h(x,7,1)+h(x,8,1)+h(x,9,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr = 'y~x+' for i in range ( 1 , 26 ): regstr += 'h(x,' + str ( i / 26 * 10 ) + ',1)+' regstr = regstr [: - 1 ] #drop last + ax26 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) Exercise: Try generating random data from different distributions and fitting polynomials of different degrees to it. What do you observe? In [ ]: # try it here In [ ]: #So, we see that increasing the number of knots results in a more polynomial-like fit In [ ]: #Next, we look at cubic splines with increasing numbers of knots ax27 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,2,3)+h(x,5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax28 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3.5,3)+h(x,5,3)+h(x,6.5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax29 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3,3)+h(x,4,3)+h(x,5,3)+h(x,6,3)+h(x,7,3)+h(x,8,3)+h(x,9,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr2 = 'y~x+np.power(x,2)+np.power(x,3)+' for i in range ( 1 , 26 ): regstr2 += 'h(x,' + str ( i / 26 * 10 ) + ',3)+' regstr2 = regstr2 [: - 1 ] #drop last + ax30 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr2 , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab2/solutions/"},{"title":"Lab 2: Smooths and GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models Harvard University Spring 2019 Instructors: Mark Glickman and Pavlos Protopapas Lab Instructors: Will Claybaugh Contributors: Paul Tyklin and Will Claybaugh In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals The main goal of this lab is to get familiar with calling R functions within Python. Along the way, we'll learn about the \"formula\" interface to statsmodels, which gives an intuitive way of specifying regression models, and we'll review the different approaches to fitting curves. Key Skills: Importing (base) R functions Importing R library functions Populating vectors R understands Populating dataframes R understands Populating formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation In [ ]: import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Linear/Polynomial Regression (Python, Review) Hopefully, you remember working with Statsmodels during 109a Reading data and (some) exploring in Pandas: In [ ]: diab = pd . read_csv ( \"data/diabetes.csv\" ) print ( \"\"\" # Variables are: # subject: subject ID number # age: age diagnosed with diabetes # acidity: a measure of acidity called base deficit # y: natural log of serum C-peptide concentration # # Original source is Sockett et al. (1987) # mentioned in Hastie and Tibshirani's book # \"Generalized Additive Models\". \"\"\" ) display ( diab . head ()) display ( diab . dtypes ) display ( diab . describe ()) Plotting with matplotlib: In [ ]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear regression with statsmodels. Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. from PolynomialFeatures). Now, Statsmodels' formula interface can help build the target value and design matrix for you. In [ ]: #Using statsmodels import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Build a data frame to predict values on (sometimes this is just the test or validation set) Very useful for making pretty plots of the model predcitions -- predict for TONS of values, not just whatever's in the training set In [ ]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [ ]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Plot the model and error bars In [ ]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Discussion What are the dark error bars? What are the light error bars? Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars Route1: Build a design df with a column for each of age , age**2 , age**3 Route2: Just edit the formula Answers : 1. In [ ]: # your code here 2. In [ ]: # your code here Linear/Polynomial Regression, but make it R This is the meat of the lab. After this section we'll know everything we need to in order to work with R models. The rest of the lab is just applying these concepts to run particular models. This section therefore is your 'cheat sheet' for working in R. What we need to know: Importing (base) R functions Importing R Library functions Populating vectors R understands Populating DataFrames R understands Populating Formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation Importing R functions In [ ]: # if you're on JupyterHub you may need to specify the path to R #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2.robjects as robjects In [ ]: r_lm = robjects . r [ \"lm\" ] r_predict = robjects . r [ \"predict\" ] #r_plot = robjects.r[\"plot\"] # more on plotting later #lm() and predict() are two of the most common functions we'll use Importing R libraries In [ ]: from rpy2.robjects.packages import importr #r_cluster = importr('cluster') #r_cluster.pam; Populating vectors R understands In [ ]: r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) # What happens if we pass the wrong type? # How does r_age display? # How does r_age print? Populating Data Frames R understands In [ ]: diab_r = robjects . DataFrame ({ \"y\" : r_y , \"age\" : r_age }) # How does diab_r display? # How does diab_r print? Populating formulas R understands In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) simple_formula . environment [ \"y\" ] = r_y #populate the formula's .environment, so it knows what 'y' and 'age' refer to simple_formula . environment [ \"age\" ] = r_age Running Models in R In [ ]: diab_lm = r_lm ( formula = simple_formula ) # the formula object is storing all the needed variables In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) # reset the formula diab_lm = r_lm ( formula = simple_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe Getting results back to Python In [ ]: diab_lm #the result is already 'in' python, but it's a special object In [ ]: print ( diab_lm . names ) # view all names In [ ]: diab_lm [ 0 ] #grab the first element In [ ]: diab_lm . rx2 ( \"coefficients\" ) #use rx2 to get elements by name! In [ ]: np . array ( diab_lm . rx2 ( \"coefficients\" )) #r vectors can be converted to numpy (but rarely needed) Getting Predictions In [ ]: # make a df to predict on (might just be the validation or test dataframe) predict_df = robjects . DataFrame ({ \"age\" : robjects . FloatVector ( np . linspace ( 0 , 16 , 100 ))}) # call R's predict() function, passing the model and the data predictions = r_predict ( diab_lm , predict_df ) In [ ]: x_vals = predict_df . rx2 ( \"age\" ) In [ ]: ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); #plt still works with r vectors as input! Plotting in R In [ ]: % load_ext rpy2.ipython The above turns on the %R \"magic\" R's plot() command responds differently based on what you hand to it; Different models get different plots! For any specific model search for plot.modelname. E.g. for a GAM model, search plot.gam for any details of plotting a GAM model The %R \"magic\" runs R code in 'notebook' mode, so figures display nicely Ahead of the plot( ) code we pass in the variables R needs to know about ( -i is for \"input\") In [ ]: % R -i diab_lm plot(diab_lm); Reading R's documentation The documentation for the lm() funciton is here , and a prettier version (same content) is here . When googling, perfer rdocumentation.org when possible. Sections: Usage : gives the function signature, including all optional arguments Arguments : What each function input controls Details : additional info on what the funciton does and how arguments interact. Often the right place to start reading Value : the structure of the object returned by the function Refferences : The relevant academic papers See Also : other functions of interest Exercise 2 Add confidence intervals calculated in R to the linear regression plot above. Use the interval= argument to r_predict() (documentation here ). You will have to work with a matrix returned by R. Fit a 5th degree polynomial to the diabetes data in R. Search the web for an easier method than writing out a formula with all 5 polynomial terms. Answers 1. In [ ]: # your code here 2. In [ ]: # your code here Lowess Smoothing Lowess Smoothing is implemented in both Python and R. We'll use it as another example as we transition languages. Discussion What is lowess smoothing? Which 109a models is it related to? How explainable is lowess? What are the tunable parameters? In Python In [ ]: from statsmodels.nonparametric.smoothers_lowess import lowess as lowess ss1 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.15 ) ss2 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.25 ) ss3 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.7 ) ss4 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 1 ) In [ ]: ss1 [: 10 ,:] # we get back simple a smoothed y value for each x value in the data Notice the clean code to plot different models. We'll see even cleaner code in a minute In [ ]: for cur_model , cur_frac in zip ([ ss1 , ss2 , ss3 , ss4 ],[ 0.15 , 0.25 , 0.7 , 1 ]): ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model [:, 0 ], cur_model [:, 1 ], color = \"blue\" ) plt . show () Discussion Which model has high variance, which has high bias? What makes a model high variance or high bias? In R We need to: Import the loess function Send data over to R Call the function and get results In [ ]: r_loess = robjects . r [ 'loess.smooth' ] #extract R function r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) ss1_r = r_loess ( r_age , r_y , span = 0.15 , degree = 1 ) In [ ]: ss1_r #again, a smoothed y value for each x value in the data Exercise 3 Predict the output of ss1_r[0] ss1_r.rx2(\"y\") 1. your answer here 2. your answer here Varying span Next, some extremely clean code to fit and plot models with various parameter settings. (Though the zip() method seen earlier is great when e.g. the label and the parameter differ) In [ ]: for cur_frac in [ 0.15 , 0.25 , 0.7 , 1 ]: cur_smooth = r_loess ( r_age , r_y , span = cur_frac ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_smooth [ 0 ], cur_smooth [ 1 ], color = \"blue\" ) plt . show () Discussion Mark wasn't kidding; the Python and R results differ for frac=.15. Thoughts? Why isn't the bottom plot a straight line? We're using 100% of the data in each window... Smoothing Splines From this point forward, we're working with R functions; these models aren't (well) supported in Python. For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point Discussion Any idea why the winner is cubic? How interpretable is this model? What are the tunable parameters? In [ ]: r_smooth_spline = robjects . r [ 'smooth.spline' ] #extract R function # run smoothing function spline1 = r_smooth_spline ( r_age , r_y , spar = 0 ) Exercise 4 We actually set the spar parameter, a scale-free value that translates to a $\\lambda$ through a complex expression. Inspect the 'spline1' result and extract the implied value of $\\lambda$ Working from the fitting/plotting loop examples above, produce a plot like the one below for spar = [0,.5,.9,2], including axes labels and title. 1. In [ ]: # your answer here 2. In [ ]: # your answer here CV R's smooth_spline funciton has built-in CV to find a good lambda. See package docs . In [ ]: spline_cv = r_smooth_spline ( r_age , r_y , cv = True ) lambda_cv = spline_cv . rx2 ( \"lambda\" )[ 0 ] ax19 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"smoothing spline with $\\lambda=$\" + str ( np . round ( lambda_cv , 4 )) + \", chosen by cross-validation\" ) ax19 . set_xlabel ( \"Age at Diagnosis\" ) ax19 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax19 . plot ( spline_cv . rx2 ( \"x\" ), spline_cv . rx2 ( \"y\" ), color = \"darkgreen\" ); Discussion Does the selected model look reasonable? How would you describe the effect of age at diagnosis on C_peptide concentration? What are the costs/benefits of the (fancy) spline model, relative to the linear regression we fit above? Natural & Basis Splines Here, we take a step backward on model complexity, but a step forward in coding complexity. We'll be working with R's formula interface again, so we will need to populate Formulas and DataFrames. Discussion In what way are Natural and Basis splines less complex than the splines we were just working with? What makes a spline 'natural'? What makes a spline 'basis'? What are the tuning parameters? In [ ]: #We will now work with a new dataset, called GAGurine. #The dataset description (from the R package MASS) is below: #Data were collected on the concentration of a chemical GAG # in the urine of 314 children aged from zero to seventeen years. # The aim of the study was to produce a chart to help a paediatrican # to assess if a child's GAG concentration is ‘normal'. #The variables are: # Age: age of child in years. # GAG: concentration of GAG (the units have been lost). In [ ]: GAGurine = pd . read_csv ( \"data/GAGurine.csv\" ) display ( GAGurine . head ()) ax31 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'black' , title = \"GAG in urine of children\" ) ax31 . set_xlabel ( \"Age\" ); ax31 . set_ylabel ( \"GAG\" ); Standard stuff: import function, convert variables to R format, call function In [ ]: from rpy2.robjects.packages import importr r_splines = importr ( 'splines' ) # populate R variables r_gag = robjects . FloatVector ( GAGurine [ 'GAG' ] . values ) r_age = robjects . FloatVector ( GAGurine [ 'Age' ] . values ) r_quarts = robjects . FloatVector ( np . quantile ( r_age ,[ . 25 , . 5 , . 75 ])) #woah, numpy functions run on R objects! What happens when we call the ns or bs functions from r_splines? In [ ]: ns_design = r_splines . ns ( r_age , knots = r_quarts ) bs_design = r_splines . bs ( r_age , knots = r_quarts ) In [ ]: print ( ns_design ) ns and bs return design matrices, not model objects! That's because they're meant to work with lm 's formula interface. To get a model object we populate a formula including ns( , ) and fit to data In [ ]: r_lm = robjects . r [ 'lm' ] r_predict = robjects . r [ 'predict' ] # populate the formula ns_formula = robjects . Formula ( \"Gag ~ ns(Age, knots=r_quarts)\" ) ns_formula . environment [ 'Gag' ] = r_gag ns_formula . environment [ 'Age' ] = r_age ns_formula . environment [ 'r_quarts' ] = r_quarts # fit the model ns_model = r_lm ( ns_formula ) Predict like usual: build a dataframe to predict on and call predict() In [ ]: # predict predict_frame = robjects . DataFrame ({ \"Age\" : robjects . FloatVector ( np . linspace ( 0 , 20 , 100 ))}) ns_out = r_predict ( ns_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" ]); Exercise 5 Fit a basis spline model with the same knots, and add it to the plot above Fit a basis spline with 8 knots placed at [2,4,6...14,16] and add it to the plot above Answers: 1. In [ ]: # your answer here 2. In [ ]: # your answer here In [ ]: #%R -i overfit_model plot(overfit_model) # we'd get the same diagnostic plot we get from an lm model GAMs We come, at last, to our most advanced model. The coding here isn't any more complex than we've done before, though the behind-the-scenes is awesome. First, let's get our (multivariate!) data In [ ]: kyphosis = pd . read_csv ( \"data/kyphosis.csv\" ) print ( \"\"\" # kyphosis - wherther a particular deformation was present post-operation # age - patient's age in months # number - the number of vertebrae involved in the operation # start - the number of the topmost vertebrae operated on \"\"\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) In [ ]: #If there are errors about missing R packages, run the code below: #r_utils = importr('utils') #r_utils.install_packages('codetools') #r_utils.install_packages('gam') To fit a GAM, we Import the gam library Populate a formula including s( ) on variables we want to fit smooths for Call gam(formula, family= ) where family is a string naming a probability distribution, chosen based on how the response variable is thought to occur. Rough family guidelines: Response is binary or \"N occurances out of M tries\", e.g. number of lab rats (out of 10) developing disease: chooose \"binomial\" Response is a count with no logical upper bound, e.g. number of ice creams sold: choose \"poisson\" Response is real, with normally-distributed noise, e.g. person's height: choose \"gaussian\" (the default) In [ ]: #There is a Python library in development for using GAMs (https://github.com/dswah/pyGAM) # but it is not yet as comprehensive as the R GAM library, which we will use here instead. # R also has the mgcv library, which implements some more advanced/flexible fitting methods r_gam_lib = importr ( 'gam' ) r_gam = r_gam_lib . gam r_kyph = robjects . FactorVector ( kyphosis [[ \"Kyphosis\" ]] . values ) r_Age = robjects . FloatVector ( kyphosis [[ \"Age\" ]] . values ) r_Number = robjects . FloatVector ( kyphosis [[ \"Number\" ]] . values ) r_Start = robjects . FloatVector ( kyphosis [[ \"Start\" ]] . values ) kyph1_fmla = robjects . Formula ( \"Kyphosis ~ s(Age) + s(Number) + s(Start)\" ) kyph1_fmla . environment [ 'Kyphosis' ] = r_kyph kyph1_fmla . environment [ 'Age' ] = r_Age kyph1_fmla . environment [ 'Number' ] = r_Number kyph1_fmla . environment [ 'Start' ] = r_Start kyph1_gam = r_gam ( kyph1_fmla , family = \"binomial\" ) The fitted gam model has a lot of interesting data within it In [ ]: print ( kyph1_gam . names ) Remember plotting? Calling R's plot() on a gam model is the easiest way to view the fitted splines In [ ]: % R -i kyph1_gam plot(kyph1_gam, residuals=TRUE,se=TRUE, scale=20); Prediction works like normal (build a data frame to predict on, if you don't already have one, and call predict() ). However, predict always reports the sum of the individual variable effects. If family is non-default this can be different from the actual prediction for that point. For instance, we're doing a 'logistic regression' so the raw prediction is log odds, but we can get probability by using in predict(..., type=\"response\") In [ ]: kyph_new = robjects . DataFrame ({ 'Age' : robjects . IntVector (( 84 , 85 , 86 )), 'Start' : robjects . IntVector (( 5 , 3 , 1 )), 'Number' : robjects . IntVector (( 1 , 6 , 10 ))}) print ( \"Raw response (so, Log odds):\" ) display ( r_predict ( kyph1_gam , kyph_new )) print ( \"Scaled response (so, probabilty of kyphosis):\" ) display ( r_predict ( kyph1_gam , kyph_new , type = \"response\" )) Discussion Exercise 6 What lambda did we use? What is the model telling us about the effects of age, starting vertebrae, and number of vertebae operated on If we fit a logistic regression instead, which variables might want quadratic terms. What is the cost and benefit of a logistic regression model versus a GAM? Critique the model: What is it assuming? Are the assumptions reasonable Are we using the right data? Does the model's story about the world make sense? Appendix GAMs and smoothing splines support hypothesis tets to compare models. (We can always compare models via out-of-sample prediction quality (i.e. performance on a validation set), but statistical ideas like hypothesis tests yet information criteria allow us to use all data for training and still compare the quality of model A to model B) In [ ]: r_anova = robjects . r [ \"anova\" ] kyph0_fmla = robjects . Formula ( \"Kyphosis~1\" ) kyph0_fmla . environment [ 'Kyphosis' ] = r_kyph kyph0_gam = r_gam ( kyph0_fmla , family = \"binomial\" ) print ( r_anova ( kyph0_gam , kyph1_gam , test = \"Chi\" )) Explicitly joining spline functions In [ ]: def h ( x , xi , pow_arg ): #pow is a reserved keyword in Python if ( x > xi ): return pow (( x - xi ), pow_arg ) else : return 0 h = np . vectorize ( h , otypes = [ np . float ]) #default behavior is to return ints, which gives incorrect answer #also, vectorize does not play nicely with default arguments, so better to set directly (e.g., pow_arg=1) In [ ]: xvals = np . arange ( 0 , 10.1 , 0.1 ) ax20 = plt . plot ( xvals , h ( xvals , 4 , 1 ), color = \"red\" ) _ = plt . title ( \"Truncated linear basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+$\" ) #note the use of TeX in the label In [ ]: ax21 = plt . plot ( xvals , h ( xvals , 4 , 3 ), color = \"red\" ) _ = plt . title ( \"Truncated cubic basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+&#94;3$\" ) In [ ]: ax22 = plt . plot ( xvals , 2 + xvals + 3 * h ( xvals , 2 , 1 ) - 4 * h ( xvals , 5 , 1 ) + 0.5 * h ( xvals , 8 , 1 ), color = \"red\" ) _ = plt . title ( \"Piecewise linear spline with knots at x=2, 5, and 8\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) Comparing splines to the (noisy) model that generated them. In [ ]: x = np . arange ( 0.1 , 10 , 9.9 / 100 ) from scipy.stats import norm #ppf (percent point function) is the rather unusual name for #the quantile or inverse CDF function in SciPy y = norm . ppf ( x / 10 ) + np . random . normal ( 0 , 0.4 , 100 ) ax23 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,2,1)+h(x,5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax24 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3.5,1)+h(x,5,1)+h(x,6.5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax25 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3,1)+h(x,4,1)+h(x,5,1)+h(x,6,1)+h(x,7,1)+h(x,8,1)+h(x,9,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr = 'y~x+' for i in range ( 1 , 26 ): regstr += 'h(x,' + str ( i / 26 * 10 ) + ',1)+' regstr = regstr [: - 1 ] #drop last + ax26 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) Exercise: Try generating random data from different distributions and fitting polynomials of different degrees to it. What do you observe? In [ ]: # try it here In [ ]: #So, we see that increasing the number of knots results in a more polynomial-like fit In [ ]: #Next, we look at cubic splines with increasing numbers of knots ax27 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,2,3)+h(x,5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax28 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3.5,3)+h(x,5,3)+h(x,6.5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax29 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3,3)+h(x,4,3)+h(x,5,3)+h(x,6,3)+h(x,7,3)+h(x,8,3)+h(x,9,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr2 = 'y~x+np.power(x,2)+np.power(x,3)+' for i in range ( 1 , 26 ): regstr2 += 'h(x,' + str ( i / 26 * 10 ) + ',3)+' regstr2 = regstr2 [: - 1 ] #drop last + ax30 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr2 , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab2/students/"},{"title":"Lecture 4: Smoothing and Additive 3/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture4/"},{"title":"Lecture 2: Smoothing and Additive 1/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture2/"},{"title":"Lecture 3: Smoothing and Additive 2/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture3/"},{"title":"Lab 1: Setting up environment","text":"Slides PDF PPTX Notebooks R_setup Notes Installation Instructions for JupyterHub","tags":"labs","url":"labs/lab1/"},{"title":"Lab 1: R set up","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } In [ ]: #---------Test Imports------------- import numpy as np import keras import gensim import nltk keras . layers . Dense ( 20 ) In [ ]: #-------Download R packages--------- ## these two lines for JupyterHub only #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2 from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) package_list = [ 'aplpack' , 'cluster' , 'codetools' , 'dbscan' , 'factoextra' , 'gam' , 'ggplot2' , 'splines' , 'TeachingDemos' ] for name in package_list : r_utils . install_packages ( name ) import rpy2 from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) package_list = [ 'aplpack' , 'cluster' , 'codetools' , 'dbscan' , 'factoextra' , 'gam' , 'ggplot2' , 'splines' , 'TeachingDemos' ] for name in package_list : r_utils . install_packages ( name ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab1/Rset/"},{"title":"Lecture 1:  Introduction, Review of 109A and preview of 109B","text":"Slides PDF PPTX","tags":"lectures","url":"lectures/lecture1/"},{"title":"Advanced Section 5: Neural Style Transfer","text":"Slides PDF Lecture Notes PDF DeepDream Blog DeepDream Generator","tags":"A-sections","url":"a-sections/a-section5/"},{"title":"Lab 7","text":"Lab 7","tags":"pages","url":"pages/lab7/"},{"title":"Advance Sections 6","text":"Advance Sections 6","tags":"pages","url":"pages/a-section6/"},{"title":"Advance Sections 7","text":"Advance Sections 7","tags":"pages","url":"pages/a-section7/"},{"title":"Lecture 24","text":"Lecture 24","tags":"pages","url":"pages/lecture24/"},{"title":"Lecture 25","text":"Lecture 25","tags":"pages","url":"pages/lecture25/"},{"title":"CS 109B: Advanced Topics in Data","text":"Spring 2019 Pavlos Protopapas and Mark Glickman pavlos@seas.harvard.edu glickman@fas.harvard.edu Pavlos: Mondays 3-4pm at MD G108 Mark: By appointment Head TFs: Eleni Kaxiras eleni@seas.harvard.edu Head TF for DCE: Sol Girouard solgirouard@g.harvard.edu Lectures: Mon and Wed 1:30‐2:45pm in Maxwell-Dworkin G-115 Labs: Thur 4:30-6:00pm in Pierce 301 Advanced Sections: Wed. 3:00pm-4:15pm, location TBD (starting 2/13) Prerequisites: CS 109a, AC 209a, Stat 121a, CSCI E-109a or equivalent. Data Science 2 is the second half of a one-year introduction to data science. Building upon the material in Data Science 1, the course introduces advanced methods for data wrangling, data visualization, and deep neural networks, statistical modeling, and prediction. Topics include big data and database management, multiple deep learning subjects such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models and unsupervised learning. Announcements: Video-recorded Lectures from CS109A Fall '18 Advanced Sections take place in NW B-103 Pierce Hall is at 29 Oxford St in Cambridge. Maxwell Dworkin (MD) is at 33 Oxford St, Cambridge. Northwest Building (NW) is at 52 Oxford St, Cambridge. HELPLINE: cs109b2019@gmail.com Office Hours : Weekly Schedule For enrollment issues including cross-registration: contact the FAS Registrar's Office either in person at the Smith Campus Center (1350 Massachusetts Avenue, Suite 450) or by sending an email to registrar@fas.harvard.ed Previous Material: 2018 pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } .contentA { flex: 1; flex-direction:column; } .contentB { flex: 3; }","tags":"pages","url":"pages/cs-109b-advanced-topics-in-data/"}]}